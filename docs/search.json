[
  {
    "objectID": "pages/8.@robdnavarro.html",
    "href": "pages/8.@robdnavarro.html",
    "title": "Análisis de tweets atacando a @robdnavarro",
    "section": "",
    "text": "Datos\n\n\nCode\ndf_attacks = attacks.loc[attacks['to_journalist'].isin([USERNAME])]\nprint(f'Número de ataques: {len(df_attacks)}')\n\n\nNúmero de ataques: 159\n\n\n\n\nCode\njournalist_mentions = len(df.loc[df['to_journalist'].isin([USERNAME])])\njournalist_attacks = len(df_attacks)\n\npercentage_attacks = (journalist_attacks / journalist_mentions) * 100\n\nproportion = (percentage_attacks / 100) * 10\nproportion_rounded = round(proportion)\n\n\nprint(f'Aproximadamente {proportion_rounded} de cada 10 publicaciones que mencionan a {USERNAME} son ataques')\n\n\nAproximadamente 1 de cada 10 publicaciones que mencionan a @robdnavarro son ataques\n\n\n\n\nRanking the tipos de ataques\n\n\nCode\nconditions = ['women', 'politics', 'appearance', 'racism', 'class', 'lgbti', 'criminal', 'calls']\nattacks_count = df_attacks[conditions].sum()\nattacks_count = attacks_count.sort_values(ascending=False)\nattacks_count\n\n\npolitics      71\nappearance    41\nwomen         26\nracism        12\nclass          9\nlgbti          4\ncalls          4\ncriminal       2\ndtype: int64\n\n\n\n\nNúmero de ataques por tipo de evento\n\n\nCode\ndf_attacks['event'].value_counts()\n\n\nevent\nelecciones    69\n1er debate    48\n2do debate    42\nName: count, dtype: int64\n\n\n\n\nPublicaciones por evento\n\n\nCode\njournalist_posts = df.loc[df['from_journalist'].isin([USERNAME])]\njournalist_posts = journalist_posts.dropna(subset=['from_journalist'])\n\neventos = ['1er debate', '2do debate', 'elecciones']\ncolors = ['green', 'purple', 'orange']\neventos_count = {}\n\nfig = px.line()\n\nfor i, evento in enumerate(eventos):\n    evento_data = journalist_posts.loc[journalist_posts['event'].isin([evento])]\n    evento_count = evento_data.groupby('dt_date').size().reset_index(name='count')\n    eventos_count[evento] = evento_count\n    fig.add_scatter(x=evento_count['dt_date'], y=evento_count['count'], name=evento, line=dict(color=colors[i]), hovertemplate='posts: %{y}')\n\nfig.update_layout(title=f'Publicaciones de {USERNAME}', width=600)\nfig.update_xaxes(type='category')\nfig.update_yaxes(range=[0, 100]) \nfig.show()\n\n\n\n                                                \n\n\n\n\nHashtags\n\n\nCode\ndf_attacks['hashtags'] = df_attacks['text'].apply(lambda x: np.nan if pd.isnull(x) or not isinstance(x, str) or len(re.findall(r'#\\w+', x)) == 0 else re.findall(r'#\\w+', x))\n\ndf_attacks['hashtags'] = df_attacks['hashtags'].apply(lambda x: ', '.join(x) if isinstance(x, list) else x)\n\n# convert dataframe column to list\nhashtags = df_attacks['hashtags'].unique()\n\n# remove nan items from list\nhashtags = [x for x in hashtags if not pd.isna(x)]\n\n# split items into a list based on a delimiter\nhashtags = [x.split(',') for x in hashtags]\n\n# flatten list of lists\nhashtags = [item for sublist in hashtags for item in sublist]\n\n# remove whitespaces\nhashtags = list(map(lambda x: x.replace(' ', ''), hashtags))\n\n# count items on list\nhashtags_count = pd.Series(hashtags).value_counts()\n\nhashtags_count\n\n\n#Paliza                      1\n#SeVan                       1\n#BastaDeMafiaKirchnerista    1\n#TeatroColon                 1\nName: count, dtype: int64\n\n\n\n\nMenciones\n\n\nCode\ndf_attacks['mentions'] = df_attacks['text'].apply(lambda x: np.nan if pd.isnull(x) or not isinstance(x, str) or len(re.findall(r'@(\\w+)', x)) == 0 else re.findall(r'@(\\w+)', x))\n\ndf_attacks['mentions'] = df_attacks['mentions'].apply(lambda x: ', '.join(x) if isinstance(x, list) else x)\n\n# convert dataframe column to list\nmentions = df_attacks['mentions'].unique()\n\n# remove nan items from list\nmentions = [x for x in mentions if not pd.isna(x)]\n\n# split items into a list based on a delimiter\nmentions = [x.split(',') for x in mentions]\n\n# flatten list of lists\nmentions = [item for sublist in mentions for item in sublist]\n\n# remove whitespaces\nmentions = list(map(lambda x: x.replace(' ', ''), mentions))\n\n# count items on list\nmentions_count = pd.Series(mentions).value_counts()\n\nmentions_count\n\n\nrobdnavarro      1\nrobnavarro       1\nJMilei           1\nChimi89606580    1\nedugbonorino     1\nName: count, dtype: int64\n\n\n\n\nTokens\n\n\nCode\n# load the spacy model for Spanish\nnlp = spacy.load(\"es_core_news_sm\")\n\n# load stop words for Spanish\nSTOP_WORDS = nlp.Defaults.stop_words\n\n# Function to filter stop words\ndef filter_stopwords(text):\n    # lower text\n    doc = nlp(text.lower())\n    # filter tokens\n    tokens = [token.text for token in doc if not token.is_stop and token.text not in STOP_WORDS and token.is_alpha]\n    return ' '.join(tokens)\n\n# apply function to dataframe column\ndf_attacks['text_pre'] = df_attacks['text'].apply(filter_stopwords)\n\n# count items on column\ntoken_counts = df_attacks[\"text_pre\"].str.split(expand=True).stack().value_counts()[:20]\n\ntoken_counts\n\n\nvos            17\nsos            13\nviejo          13\nperonchos      10\nk               9\nasco            8\nmilei           8\nscioli          8\novacionado      7\nkk              7\nculo            6\nmierda          6\nensobrado       6\npueblo          5\nq               5\ngordo           5\nnavarro         5\nanda            5\nkukas           5\ninsaurralde     5\nName: count, dtype: int64"
  },
  {
    "objectID": "pages/7.@rialjorge.html",
    "href": "pages/7.@rialjorge.html",
    "title": "Análisis de tweets atacando a @rialjorge",
    "section": "",
    "text": "Datos\n\n\nCode\ndf_attacks = attacks.loc[attacks['to_journalist'].isin([USERNAME])]\nprint(f'Número de ataques: {len(df_attacks)}')\n\n\nNúmero de ataques: 175\n\n\n\n\nCode\njournalist_mentions = len(df.loc[df['to_journalist'].isin([USERNAME])])\njournalist_attacks = len(df_attacks)\n\npercentage_attacks = (journalist_attacks / journalist_mentions) * 100\n\nproportion = (percentage_attacks / 100) * 10\nproportion_rounded = round(proportion)\n\n\nprint(f'Aproximadamente {proportion_rounded} de cada 10 publicaciones que mencionan a {USERNAME} son ataques')\n\n\nAproximadamente 1 de cada 10 publicaciones que mencionan a @rialjorge son ataques\n\n\n\n\nRanking the tipos de ataques\n\n\nCode\nconditions = ['women', 'politics', 'appearance', 'racism', 'class', 'lgbti', 'criminal', 'calls']\nattacks_count = df_attacks[conditions].sum()\nattacks_count = attacks_count.sort_values(ascending=False)\nattacks_count\n\n\nappearance    57\npolitics      52\nwomen         51\nracism         9\nclass          6\nlgbti          4\ncalls          1\ncriminal       0\ndtype: int64\n\n\n\n\nNúmero de ataques por tipo de evento\n\n\nCode\ndf_attacks['event'].value_counts()\n\n\nevent\nelecciones    108\n2do debate     39\n1er debate     28\nName: count, dtype: int64\n\n\n\n\nPublicaciones por evento\n\n\nCode\njournalist_posts = df.loc[df['from_journalist'].isin([USERNAME])]\njournalist_posts = journalist_posts.dropna(subset=['from_journalist'])\n\neventos = ['1er debate', '2do debate', 'elecciones']\ncolors = ['green', 'purple', 'orange']\neventos_count = {}\n\nfig = px.line()\n\nfor i, evento in enumerate(eventos):\n    evento_data = journalist_posts.loc[journalist_posts['event'].isin([evento])]\n    evento_count = evento_data.groupby('dt_date').size().reset_index(name='count')\n    eventos_count[evento] = evento_count\n    fig.add_scatter(x=evento_count['dt_date'], y=evento_count['count'], name=evento, line=dict(color=colors[i]), hovertemplate='posts: %{y}')\n\nfig.update_layout(title=f'Publicaciones de {USERNAME}', width=600)\nfig.update_xaxes(type='category')\nfig.update_yaxes(range=[0, 100]) \nfig.show()\n\n\n\n                                                \n\n\n\n\nHashtags\n\n\nCode\ndf_attacks['hashtags'] = df_attacks['text'].apply(lambda x: np.nan if pd.isnull(x) or not isinstance(x, str) or len(re.findall(r'#\\w+', x)) == 0 else re.findall(r'#\\w+', x))\n\ndf_attacks['hashtags'] = df_attacks['hashtags'].apply(lambda x: ', '.join(x) if isinstance(x, list) else x)\n\n# convert dataframe column to list\nhashtags = df_attacks['hashtags'].unique()\n\n# remove nan items from list\nhashtags = [x for x in hashtags if not pd.isna(x)]\n\n# split items into a list based on a delimiter\nhashtags = [x.split(',') for x in hashtags]\n\n# flatten list of lists\nhashtags = [item for sublist in hashtags for item in sublist]\n\n# remove whitespaces\nhashtags = list(map(lambda x: x.replace(' ', ''), hashtags))\n\n# count items on list\nhashtags_count = pd.Series(hashtags).value_counts()\n\nhashtags_count\n\n\n#BrancatelliPelotudo    1\n#MileiPresidente        1\nName: count, dtype: int64\n\n\n\n\nMenciones\n\n\nCode\ndf_attacks['mentions'] = df_attacks['text'].apply(lambda x: np.nan if pd.isnull(x) or not isinstance(x, str) or len(re.findall(r'@(\\w+)', x)) == 0 else re.findall(r'@(\\w+)', x))\n\ndf_attacks['mentions'] = df_attacks['mentions'].apply(lambda x: ', '.join(x) if isinstance(x, list) else x)\n\n# convert dataframe column to list\nmentions = df_attacks['mentions'].unique()\n\n# remove nan items from list\nmentions = [x for x in mentions if not pd.isna(x)]\n\n# split items into a list based on a delimiter\nmentions = [x.split(',') for x in mentions]\n\n# flatten list of lists\nmentions = [item for sublist in mentions for item in sublist]\n\n# remove whitespaces\nmentions = list(map(lambda x: x.replace(' ', ''), mentions))\n\n# count items on list\nmentions_count = pd.Series(mentions).value_counts()\n\nmentions_count\n\n\nrialjorge         2\nSergioMassa       1\nJMilei            1\nJonatanViale      1\nPRossiOficial     1\nLuisNovaresio1    1\nName: count, dtype: int64\n\n\n\n\nTokens\n\n\nCode\n# load the spacy model for Spanish\nnlp = spacy.load(\"es_core_news_sm\")\n\n# load stop words for Spanish\nSTOP_WORDS = nlp.Defaults.stop_words\n\n# Function to filter stop words\ndef filter_stopwords(text):\n    # lower text\n    doc = nlp(text.lower())\n    # filter tokens\n    tokens = [token.text for token in doc if not token.is_stop and token.text not in STOP_WORDS and token.is_alpha]\n    return ' '.join(tokens)\n\n# apply function to dataframe column\ndf_attacks['text_pre'] = df_attacks['text'].apply(filter_stopwords)\n\n# count items on column\ntoken_counts = df_attacks[\"text_pre\"].str.split(expand=True).stack().value_counts()[:20]\n\ntoken_counts\n\n\nq            30\nvos          24\nviejo        24\nsos          17\nvas          10\ntenes         9\nhuevo         9\nbajate        8\nzurdos        8\nasco          7\nbájate        7\ncara          7\ngente         7\nhijas         6\nojalá         6\nmilei         6\nperonchos     6\nkuka          5\nhijo          5\nrial          5\nName: count, dtype: int64"
  },
  {
    "objectID": "pages/5.@odonnellmaria.html",
    "href": "pages/5.@odonnellmaria.html",
    "title": "Análisis de tweets atacando a @odonnellmaria",
    "section": "",
    "text": "Datos\n\n\nCode\ndf_attacks = attacks.loc[attacks['to_journalist'].isin([USERNAME])]\nprint(f'Número de ataques: {len(df_attacks)}')\n\n\nNúmero de ataques: 256\n\n\n\n\nCode\njournalist_mentions = len(df.loc[df['to_journalist'].isin([USERNAME])])\njournalist_attacks = len(df_attacks)\n\npercentage_attacks = (journalist_attacks / journalist_mentions) * 100\n\nproportion = (percentage_attacks / 100) * 10\nproportion_rounded = round(proportion)\n\n\nprint(f'Aproximadamente {proportion_rounded} de cada 10 publicaciones que mencionan a {USERNAME} son ataques')\n\n\nAproximadamente 1 de cada 10 publicaciones que mencionan a @odonnellmaria son ataques\n\n\n\n\nRanking the tipos de ataques\n\n\nCode\nconditions = ['women', 'politics', 'appearance', 'racism', 'class', 'lgbti', 'criminal', 'calls']\nattacks_count = df_attacks[conditions].sum()\nattacks_count = attacks_count.sort_values(ascending=False)\nattacks_count\n\n\npolitics      114\nwomen         107\nappearance     51\nclass          13\nracism          8\nlgbti           0\ncriminal        0\ncalls           0\ndtype: int64\n\n\n\n\nNúmero de ataques por tipo de evento\n\n\nCode\ndf_attacks['event'].value_counts()\n\n\nevent\n1er debate    113\n2do debate     90\nelecciones     53\nName: count, dtype: int64\n\n\n\n\nPublicaciones por evento\n\n\nCode\njournalist_posts = df.loc[df['from_journalist'].isin([USERNAME])]\njournalist_posts = journalist_posts.dropna(subset=['from_journalist'])\n\neventos = ['1er debate', '2do debate', 'elecciones']\ncolors = ['green', 'purple', 'orange']\neventos_count = {}\n\nfig = px.line()\n\nfor i, evento in enumerate(eventos):\n    evento_data = journalist_posts.loc[journalist_posts['event'].isin([evento])]\n    evento_count = evento_data.groupby('dt_date').size().reset_index(name='count')\n    eventos_count[evento] = evento_count\n    fig.add_scatter(x=evento_count['dt_date'], y=evento_count['count'], name=evento, line=dict(color=colors[i]), hovertemplate='posts: %{y}')\n\nfig.update_layout(title=f'Publicaciones de {USERNAME}', width=600)\nfig.update_xaxes(type='category')\nfig.update_yaxes(range=[0, 100]) \nfig.show()\n\n\n\n                                                \n\n\n\n\nHashtags\n\n\nCode\ndf_attacks['hashtags'] = df_attacks['text'].apply(lambda x: np.nan if pd.isnull(x) or not isinstance(x, str) or len(re.findall(r'#\\w+', x)) == 0 else re.findall(r'#\\w+', x))\n\ndf_attacks['hashtags'] = df_attacks['hashtags'].apply(lambda x: ', '.join(x) if isinstance(x, list) else x)\n\n# convert dataframe column to list\nhashtags = df_attacks['hashtags'].unique()\n\n# remove nan items from list\nhashtags = [x for x in hashtags if not pd.isna(x)]\n\n# split items into a list based on a delimiter\nhashtags = [x.split(',') for x in hashtags]\n\n# flatten list of lists\nhashtags = [item for sublist in hashtags for item in sublist]\n\n# remove whitespaces\nhashtags = list(map(lambda x: x.replace(' ', ''), hashtags))\n\n# count items on list\nhashtags_count = pd.Series(hashtags).value_counts()\n\nhashtags_count\n\n\n#Milei2023EnPrimeraVuelta    1\n#coreadelcentro              1\n#LameTujesK                  1\nName: count, dtype: int64\n\n\n\n\nMenciones\n\n\nCode\ndf_attacks['mentions'] = df_attacks['text'].apply(lambda x: np.nan if pd.isnull(x) or not isinstance(x, str) or len(re.findall(r'@(\\w+)', x)) == 0 else re.findall(r'@(\\w+)', x))\n\ndf_attacks['mentions'] = df_attacks['mentions'].apply(lambda x: ', '.join(x) if isinstance(x, list) else x)\n\n# convert dataframe column to list\nmentions = df_attacks['mentions'].unique()\n\n# remove nan items from list\nmentions = [x for x in mentions if not pd.isna(x)]\n\n# split items into a list based on a delimiter\nmentions = [x.split(',') for x in mentions]\n\n# flatten list of lists\nmentions = [item for sublist in mentions for item in sublist]\n\n# remove whitespaces\nmentions = list(map(lambda x: x.replace(' ', ''), mentions))\n\n# count items on list\nmentions_count = pd.Series(mentions).value_counts()\n\nmentions_count\n\n\nodonellmaria     1\nodonnellmaria    1\nSergioMassa      1\nertenembaum      1\nName: count, dtype: int64\n\n\n\n\nTokens\n\n\nCode\n# load the spacy model for Spanish\nnlp = spacy.load(\"es_core_news_sm\")\n\n# load stop words for Spanish\nSTOP_WORDS = nlp.Defaults.stop_words\n\n# Function to filter stop words\ndef filter_stopwords(text):\n    # lower text\n    doc = nlp(text.lower())\n    # filter tokens\n    tokens = [token.text for token in doc if not token.is_stop and token.text not in STOP_WORDS and token.is_alpha]\n    return ' '.join(tokens)\n\n# apply function to dataframe column\ndf_attacks['text_pre'] = df_attacks['text'].apply(filter_stopwords)\n\n# count items on column\ntoken_counts = df_attacks[\"text_pre\"].str.split(expand=True).stack().value_counts()[:20]\n\ntoken_counts\n\n\nvos          44\nsos          41\nzurda        39\nq            20\nmaría        13\nensobrada    11\nanda          9\nderecho       8\npauta         8\nmilei         8\nk             8\nvagos         7\nmujer         7\ngente         7\nkuka          7\nzurdos        7\nvieja         7\nputa          7\ntrabajo       6\ntenes         6\nName: count, dtype: int64"
  },
  {
    "objectID": "pages/1.@diegobranca.html",
    "href": "pages/1.@diegobranca.html",
    "title": "Análisis de tweets atacando a @diegobranca",
    "section": "",
    "text": "Datos\n\n\nCode\ndf_attacks = attacks.loc[attacks['to_journalist'].isin([USERNAME])]\nprint(f'Número de ataques: {len(df_attacks)}')\n\n\nNúmero de ataques: 418\n\n\n\n\nCode\njournalist_mentions = len(df.loc[df['to_journalist'].isin([USERNAME])])\njournalist_attacks = len(df_attacks)\n\npercentage_attacks = (journalist_attacks / journalist_mentions) * 100\n\nproportion = (percentage_attacks / 100) * 10\nproportion_rounded = round(proportion)\n\n\nprint(f'Aproximadamente {proportion_rounded} de cada 10 publicaciones que mencionan a {USERNAME} son ataques')\n\n\nAproximadamente 1 de cada 10 publicaciones que mencionan a @diegobranca son ataques\n\n\n\n\nRanking the tipos de ataques\n\n\nCode\nconditions = ['women', 'politics', 'appearance', 'racism', 'class', 'lgbti', 'criminal', 'calls']\nattacks_count = df_attacks[conditions].sum()\nattacks_count = attacks_count.sort_values(ascending=False)\nattacks_count\n\n\nappearance    199\npolitics      127\nwomen          62\nlgbti          25\nclass          22\nracism         18\ncriminal       14\ncalls           5\ndtype: int64\n\n\n\n\nNúmero de ataques por tipo de evento\n\n\nCode\ndf_attacks['event'].value_counts()\n\n\nevent\nelecciones    229\n1er debate    102\n2do debate     87\nName: count, dtype: int64\n\n\n\n\nPublicaciones por evento\n\n\nCode\njournalist_posts = df.loc[df['from_journalist'].isin([USERNAME])]\njournalist_posts = journalist_posts.dropna(subset=['from_journalist'])\n\neventos = ['1er debate', '2do debate', 'elecciones']\ncolors = ['green', 'purple', 'orange']\neventos_count = {}\n\nfig = px.line()\n\nfor i, evento in enumerate(eventos):\n    evento_data = journalist_posts.loc[journalist_posts['event'].isin([evento])]\n    evento_count = evento_data.groupby('dt_date').size().reset_index(name='count')\n    eventos_count[evento] = evento_count\n    fig.add_scatter(x=evento_count['dt_date'], y=evento_count['count'], name=evento, line=dict(color=colors[i]), hovertemplate='posts: %{y}')\n\nfig.update_layout(title=f'Publicaciones de {USERNAME}', width=600)\nfig.update_xaxes(type='category')\nfig.update_yaxes(range=[0, 100]) \nfig.show()\n\n\n\n                                                \n\n\n\n\nHashtags\n\n\nCode\ndf_attacks['hashtags'] = df_attacks['text'].apply(lambda x: np.nan if pd.isnull(x) or not isinstance(x, str) or len(re.findall(r'#\\w+', x)) == 0 else re.findall(r'#\\w+', x))\n\ndf_attacks['hashtags'] = df_attacks['hashtags'].apply(lambda x: ', '.join(x) if isinstance(x, list) else x)\n\n# convert dataframe column to list\nhashtags = df_attacks['hashtags'].unique()\n\n# remove nan items from list\nhashtags = [x for x in hashtags if not pd.isna(x)]\n\n# split items into a list based on a delimiter\nhashtags = [x.split(',') for x in hashtags]\n\n# flatten list of lists\nhashtags = [item for sublist in hashtags for item in sublist]\n\n# remove whitespaces\nhashtags = list(map(lambda x: x.replace(' ', ''), hashtags))\n\n# count items on list\nhashtags_count = pd.Series(hashtags).value_counts()\n\nhashtags_count\n\n\n#KirchnerismoNuncaMas          2\n#ElPeorGobiernoDeLaHistoria    1\n#SeVanParaSiempre              1\n#tugo                          1\n#Afip                          1\n#NoAl5toGobiernoK              1\n#NoVasASerPresidente           1\n#EsAhoraYParaSiempre           1\n#MileiPresidente               1\nName: count, dtype: int64\n\n\n\n\nMenciones\n\n\nCode\ndf_attacks['mentions'] = df_attacks['text'].apply(lambda x: np.nan if pd.isnull(x) or not isinstance(x, str) or len(re.findall(r'@(\\w+)', x)) == 0 else re.findall(r'@(\\w+)', x))\n\ndf_attacks['mentions'] = df_attacks['mentions'].apply(lambda x: ', '.join(x) if isinstance(x, list) else x)\n\n# convert dataframe column to list\nmentions = df_attacks['mentions'].unique()\n\n# remove nan items from list\nmentions = [x for x in mentions if not pd.isna(x)]\n\n# split items into a list based on a delimiter\nmentions = [x.split(',') for x in mentions]\n\n# flatten list of lists\nmentions = [item for sublist in mentions for item in sublist]\n\n# remove whitespaces\nmentions = list(map(lambda x: x.replace(' ', ''), mentions))\n\n# count items on list\nmentions_count = pd.Series(mentions).value_counts()\n\nmentions_count\n\n\nSergioMassa       2\nSergioChouza      1\nminsaurralde      1\nT                 1\nJMilei            1\nherlombardi       1\ns                 1\ndiegobranca       1\nMunicipioPilar    1\nName: count, dtype: int64\n\n\n\n\nTokens\n\n\nCode\n# load the spacy model for Spanish\nnlp = spacy.load(\"es_core_news_sm\")\n\n# load stop words for Spanish\nSTOP_WORDS = nlp.Defaults.stop_words\n\n# Function to filter stop words\ndef filter_stopwords(text):\n    # lower text\n    doc = nlp(text.lower())\n    # filter tokens\n    tokens = [token.text for token in doc if not token.is_stop and token.text not in STOP_WORDS and token.is_alpha]\n    return ' '.join(tokens)\n\n# apply function to dataframe column\ndf_attacks['text_pre'] = df_attacks['text'].apply(filter_stopwords)\n\n# count items on column\ntoken_counts = df_attacks[\"text_pre\"].str.split(expand=True).stack().value_counts()[:20]\n\ntoken_counts\n\n\ngordo        113\nvos           85\nsos           59\nq             35\ngordito       22\nk             20\nvas           19\nmierda        19\ntenes         18\nmassa         16\nlaburar       15\nperonchos     15\nbranca        15\nculo          15\nanda          14\nmilei         13\ngente         13\nmufa          13\npelotudo      13\nensobrado     12\nName: count, dtype: int64"
  },
  {
    "objectID": "pages/4.@Cris_noticias.html",
    "href": "pages/4.@Cris_noticias.html",
    "title": "Análisis de tweets atacando a @Cris_noticias",
    "section": "",
    "text": "Datos\n\n\nCode\ndf_attacks = attacks.loc[attacks['to_journalist'].isin([USERNAME])]\nprint(f'Número de ataques: {len(df_attacks)}')\n\n\nNúmero de ataques: 266\n\n\n\n\nCode\njournalist_mentions = len(df.loc[df['to_journalist'].isin([USERNAME])])\njournalist_attacks = len(df_attacks)\n\npercentage_attacks = (journalist_attacks / journalist_mentions) * 100\n\nproportion = (percentage_attacks / 100) * 10\nproportion_rounded = round(proportion)\n\n\nprint(f'Aproximadamente {proportion_rounded} de cada 10 publicaciones que mencionan a {USERNAME} son ataques')\n\n\nAproximadamente 1 de cada 10 publicaciones que mencionan a @Cris_noticias son ataques\n\n\n\n\nRanking the tipos de ataques\n\n\nCode\nconditions = ['women', 'politics', 'appearance', 'racism', 'class', 'lgbti', 'criminal', 'calls']\nattacks_count = df_attacks[conditions].sum()\nattacks_count = attacks_count.sort_values(ascending=False)\nattacks_count\n\n\nwomen         121\npolitics       91\nappearance     41\nracism         16\nclass          10\nlgbti           2\ncalls           1\ncriminal        0\ndtype: int64\n\n\n\n\nNúmero de ataques por tipo de evento\n\n\nCode\ndf_attacks['event'].value_counts()\n\n\nevent\nelecciones    214\n2do debate     52\nName: count, dtype: int64\n\n\n\n\nPublicaciones por evento\n\n\nCode\njournalist_posts = df.loc[df['from_journalist'].isin([USERNAME])]\njournalist_posts = journalist_posts.dropna(subset=['from_journalist'])\n\neventos = ['1er debate', '2do debate', 'elecciones']\ncolors = ['green', 'purple', 'orange']\neventos_count = {}\n\nfig = px.line()\n\nfor i, evento in enumerate(eventos):\n    evento_data = journalist_posts.loc[journalist_posts['event'].isin([evento])]\n    evento_count = evento_data.groupby('dt_date').size().reset_index(name='count')\n    eventos_count[evento] = evento_count\n    fig.add_scatter(x=evento_count['dt_date'], y=evento_count['count'], name=evento, line=dict(color=colors[i]), hovertemplate='posts: %{y}')\n\nfig.update_layout(title=f'Publicaciones de {USERNAME}', width=600)\nfig.update_xaxes(type='category')\nfig.update_yaxes(range=[0, 100]) \nfig.show()\n\n\n\n                                                \n\n\n\n\nHashtags\n\n\nCode\ndf_attacks['hashtags'] = df_attacks['text'].apply(lambda x: np.nan if pd.isnull(x) or not isinstance(x, str) or len(re.findall(r'#\\w+', x)) == 0 else re.findall(r'#\\w+', x))\n\ndf_attacks['hashtags'] = df_attacks['hashtags'].apply(lambda x: ', '.join(x) if isinstance(x, list) else x)\n\n# convert dataframe column to list\nhashtags = df_attacks['hashtags'].unique()\n\n# remove nan items from list\nhashtags = [x for x in hashtags if not pd.isna(x)]\n\n# split items into a list based on a delimiter\nhashtags = [x.split(',') for x in hashtags]\n\n# flatten list of lists\nhashtags = [item for sublist in hashtags for item in sublist]\n\n# remove whitespaces\nhashtags = list(map(lambda x: x.replace(' ', ''), hashtags))\n\n# count items on list\nhashtags_count = pd.Series(hashtags).value_counts()\n\nhashtags_count\n\n\n#nuncamas               1\n#PalestinaLibre         1\n#YoVotoAMassa           1\n#Milei                  1\n#NuncaMilei             1\n#MassaPresidente2023    1\n#NuncaMas               1\n#MileiNo                1\nName: count, dtype: int64\n\n\n\n\nMenciones\n\n\nCode\ndf_attacks['mentions'] = df_attacks['text'].apply(lambda x: np.nan if pd.isnull(x) or not isinstance(x, str) or len(re.findall(r'@(\\w+)', x)) == 0 else re.findall(r'@(\\w+)', x))\n\ndf_attacks['mentions'] = df_attacks['mentions'].apply(lambda x: ', '.join(x) if isinstance(x, list) else x)\n\n# convert dataframe column to list\nmentions = df_attacks['mentions'].unique()\n\n# remove nan items from list\nmentions = [x for x in mentions if not pd.isna(x)]\n\n# split items into a list based on a delimiter\nmentions = [x.split(',') for x in mentions]\n\n# flatten list of lists\nmentions = [item for sublist in mentions for item in sublist]\n\n# remove whitespaces\nmentions = list(map(lambda x: x.replace(' ', ''), mentions))\n\n# count items on list\nmentions_count = pd.Series(mentions).value_counts()\n\nmentions_count\n\n\nCris_noticias      2\nSergioMassa        1\nJMilei             1\nPatoBullrich       1\nluispetri          1\nJorgeTelerman      1\nhoraciorlarreta    1\nName: count, dtype: int64\n\n\n\n\nTokens\n\n\nCode\n# load the spacy model for Spanish\nnlp = spacy.load(\"es_core_news_sm\")\n\n# load stop words for Spanish\nSTOP_WORDS = nlp.Defaults.stop_words\n\n# Function to filter stop words\ndef filter_stopwords(text):\n    # lower text\n    doc = nlp(text.lower())\n    # filter tokens\n    tokens = [token.text for token in doc if not token.is_stop and token.text not in STOP_WORDS and token.is_alpha]\n    return ' '.join(tokens)\n\n# apply function to dataframe column\ndf_attacks['text_pre'] = df_attacks['text'].apply(filter_stopwords)\n\n# count items on column\ntoken_counts = df_attacks[\"text_pre\"].str.split(expand=True).stack().value_counts()[:20]\n\ntoken_counts\n\n\nvos          33\nq            30\nsos          29\ngorila       22\nmarido       21\nnovio        19\nmierda       17\nmilei        16\nzurdos       15\ngente        13\nx             9\ndictadura     9\nvas           9\nvieja         9\nmassa         8\nforra         8\norto          8\ncerra         8\ncasta         7\nconchuda      7\nName: count, dtype: int64"
  },
  {
    "objectID": "pages/10.@luisnovaresio.html",
    "href": "pages/10.@luisnovaresio.html",
    "title": "Análisis de tweets atacando a @luisnovaresio",
    "section": "",
    "text": "Datos\n\n\nCode\ndf_attacks = attacks.loc[attacks['to_journalist'].isin([USERNAME])]\nprint(f'Número de ataques: {len(df_attacks)}')\n\n\nNúmero de ataques: 99\n\n\n\n\nCode\njournalist_mentions = len(df.loc[df['to_journalist'].isin([USERNAME])])\njournalist_attacks = len(df_attacks)\n\npercentage_attacks = (journalist_attacks / journalist_mentions) * 100\n\nproportion = (percentage_attacks / 100) * 10\nproportion_rounded = round(proportion)\n\n\nprint(f'Aproximadamente {proportion_rounded} de cada 10 publicaciones que mencionan a {USERNAME} son ataques')\n\n\nAproximadamente 1 de cada 10 publicaciones que mencionan a @luisnovaresio son ataques\n\n\n\n\nRanking the tipos de ataques\n\n\nCode\nconditions = ['women', 'politics', 'appearance', 'racism', 'class', 'lgbti', 'criminal', 'calls']\nattacks_count = df_attacks[conditions].sum()\nattacks_count = attacks_count.sort_values(ascending=False)\nattacks_count\n\n\npolitics      49\nwomen         21\nappearance    14\nlgbti          8\nracism         6\nclass          5\ncriminal       1\ncalls          0\ndtype: int64\n\n\n\n\nNúmero de ataques por tipo de evento\n\n\nCode\ndf_attacks['event'].value_counts()\n\n\nevent\n1er debate    64\nelecciones    26\n2do debate     9\nName: count, dtype: int64\n\n\n\n\nPublicaciones por evento\n\n\nCode\njournalist_posts = df.loc[df['from_journalist'].isin([USERNAME])]\njournalist_posts = journalist_posts.dropna(subset=['from_journalist'])\n\neventos = ['1er debate', '2do debate', 'elecciones']\ncolors = ['green', 'purple', 'orange']\neventos_count = {}\n\nfig = px.line()\n\nfor i, evento in enumerate(eventos):\n    evento_data = journalist_posts.loc[journalist_posts['event'].isin([evento])]\n    evento_count = evento_data.groupby('dt_date').size().reset_index(name='count')\n    eventos_count[evento] = evento_count\n    fig.add_scatter(x=evento_count['dt_date'], y=evento_count['count'], name=evento, line=dict(color=colors[i]), hovertemplate='posts: %{y}')\n\nfig.update_layout(title=f'Publicaciones de {USERNAME}', width=600)\nfig.update_xaxes(type='category')\nfig.update_yaxes(range=[0, 100]) \nfig.show()\n\n\n\n                                                \n\n\n\n\nHashtags\n\n\nCode\ndf_attacks['hashtags'] = df_attacks['text'].apply(lambda x: np.nan if pd.isnull(x) or not isinstance(x, str) or len(re.findall(r'#\\w+', x)) == 0 else re.findall(r'#\\w+', x))\n\ndf_attacks['hashtags'] = df_attacks['hashtags'].apply(lambda x: ', '.join(x) if isinstance(x, list) else x)\n\n# convert dataframe column to list\nhashtags = df_attacks['hashtags'].unique()\n\n# remove nan items from list\nhashtags = [x for x in hashtags if not pd.isna(x)]\n\n# split items into a list based on a delimiter\nhashtags = [x.split(',') for x in hashtags]\n\n# flatten list of lists\nhashtags = [item for sublist in hashtags for item in sublist]\n\n# remove whitespaces\nhashtags = list(map(lambda x: x.replace(' ', ''), hashtags))\n\n# count items on list\nhashtags_count = pd.Series(hashtags).value_counts()\n\nhashtags_count\n\n\n#Pato2023    1\nName: count, dtype: int64\n\n\n\n\nMenciones\n\n\nCode\ndf_attacks['mentions'] = df_attacks['text'].apply(lambda x: np.nan if pd.isnull(x) or not isinstance(x, str) or len(re.findall(r'@(\\w+)', x)) == 0 else re.findall(r'@(\\w+)', x))\n\ndf_attacks['mentions'] = df_attacks['mentions'].apply(lambda x: ', '.join(x) if isinstance(x, list) else x)\n\n# convert dataframe column to list\nmentions = df_attacks['mentions'].unique()\n\n# remove nan items from list\nmentions = [x for x in mentions if not pd.isna(x)]\n\n# split items into a list based on a delimiter\nmentions = [x.split(',') for x in mentions]\n\n# flatten list of lists\nmentions = [item for sublist in mentions for item in sublist]\n\n# remove whitespaces\nmentions = list(map(lambda x: x.replace(' ', ''), mentions))\n\n# count items on list\nmentions_count = pd.Series(mentions).value_counts()\n\nmentions_count\n\n\nPatoBullrich     1\nJMilei           1\nluisnovaresio    1\nName: count, dtype: int64\n\n\n\n\nTokens\n\n\nCode\n# load the spacy model for Spanish\nnlp = spacy.load(\"es_core_news_sm\")\n\n# load stop words for Spanish\nSTOP_WORDS = nlp.Defaults.stop_words\n\n# Function to filter stop words\ndef filter_stopwords(text):\n    # lower text\n    doc = nlp(text.lower())\n    # filter tokens\n    tokens = [token.text for token in doc if not token.is_stop and token.text not in STOP_WORDS and token.is_alpha]\n    return ' '.join(tokens)\n\n# apply function to dataframe column\ndf_attacks['text_pre'] = df_attacks['text'].apply(filter_stopwords)\n\n# count items on column\ntoken_counts = df_attacks[\"text_pre\"].str.split(expand=True).stack().value_counts()[:20]\n\ntoken_counts\n\n\nsos           16\nvos           14\ngorila        10\nzurda          9\nq              7\nestás          6\nd              5\nvotar          4\ncara           4\naños           4\ntenes          4\ndiga           4\npaís           4\nmilei          4\nasco           4\nvivir          4\nduele          3\nperiodista     3\ncloset         3\nbla            3\nName: count, dtype: int64"
  },
  {
    "objectID": "pages/3.@Angelalerena.html",
    "href": "pages/3.@Angelalerena.html",
    "title": "Análisis de tweets atacando a @Angelalerena",
    "section": "",
    "text": "Datos\n\n\nCode\ndf_attacks = attacks.loc[attacks['to_journalist'].isin([USERNAME])]\nprint(f'Número de ataques: {len(df_attacks)}')\n\n\nNúmero de ataques: 326\n\n\n\n\nCode\njournalist_mentions = len(df.loc[df['to_journalist'].isin([USERNAME])])\njournalist_attacks = len(df_attacks)\n\npercentage_attacks = (journalist_attacks / journalist_mentions) * 100\n\nproportion = (percentage_attacks / 100) * 10\nproportion_rounded = round(proportion)\n\n\nprint(f'Aproximadamente {proportion_rounded} de cada 10 publicaciones que mencionan a {USERNAME} son ataques')\n\n\nAproximadamente 1 de cada 10 publicaciones que mencionan a @Angelalerena son ataques\n\n\n\n\nRanking the tipos de ataques\n\n\nCode\nconditions = ['women', 'politics', 'appearance', 'racism', 'class', 'lgbti', 'criminal', 'calls']\nattacks_count = df_attacks[conditions].sum()\nattacks_count = attacks_count.sort_values(ascending=False)\nattacks_count\n\n\nwomen         163\npolitics      110\nappearance     57\nclass          36\nracism         10\nlgbti           7\ncriminal        2\ncalls           2\ndtype: int64\n\n\n\n\nNúmero de ataques por tipo de evento\n\n\nCode\ndf_attacks['event'].value_counts()\n\n\nevent\nelecciones    308\n1er debate     10\n2do debate      8\nName: count, dtype: int64\n\n\n\n\nPublicaciones por evento\n\n\nCode\njournalist_posts = df.loc[df['from_journalist'].isin([USERNAME])]\njournalist_posts = journalist_posts.dropna(subset=['from_journalist'])\n\neventos = ['1er debate', '2do debate', 'elecciones']\ncolors = ['green', 'purple', 'orange']\neventos_count = {}\n\nfig = px.line()\n\nfor i, evento in enumerate(eventos):\n    evento_data = journalist_posts.loc[journalist_posts['event'].isin([evento])]\n    evento_count = evento_data.groupby('dt_date').size().reset_index(name='count')\n    eventos_count[evento] = evento_count\n    fig.add_scatter(x=evento_count['dt_date'], y=evento_count['count'], name=evento, line=dict(color=colors[i]), hovertemplate='posts: %{y}')\n\nfig.update_layout(title=f'Publicaciones de {USERNAME}', width=600)\nfig.update_xaxes(type='category')\nfig.update_yaxes(range=[0, 100]) \nfig.show()\n\n\n\n                                                \n\n\n\n\nHashtags\n\n\nCode\ndf_attacks['hashtags'] = df_attacks['text'].apply(lambda x: np.nan if pd.isnull(x) or not isinstance(x, str) or len(re.findall(r'#\\w+', x)) == 0 else re.findall(r'#\\w+', x))\n\ndf_attacks['hashtags'] = df_attacks['hashtags'].apply(lambda x: ', '.join(x) if isinstance(x, list) else x)\n\n# convert dataframe column to list\nhashtags = df_attacks['hashtags'].unique()\n\n# remove nan items from list\nhashtags = [x for x in hashtags if not pd.isna(x)]\n\n# split items into a list based on a delimiter\nhashtags = [x.split(',') for x in hashtags]\n\n# flatten list of lists\nhashtags = [item for sublist in hashtags for item in sublist]\n\n# remove whitespaces\nhashtags = list(map(lambda x: x.replace(' ', ''), hashtags))\n\n# count items on list\nhashtags_count = pd.Series(hashtags).value_counts()\n\nhashtags_count\n\n\n#viv    1\nName: count, dtype: int64\n\n\n\n\nMenciones\n\n\nCode\ndf_attacks['mentions'] = df_attacks['text'].apply(lambda x: np.nan if pd.isnull(x) or not isinstance(x, str) or len(re.findall(r'@(\\w+)', x)) == 0 else re.findall(r'@(\\w+)', x))\n\ndf_attacks['mentions'] = df_attacks['mentions'].apply(lambda x: ', '.join(x) if isinstance(x, list) else x)\n\n# convert dataframe column to list\nmentions = df_attacks['mentions'].unique()\n\n# remove nan items from list\nmentions = [x for x in mentions if not pd.isna(x)]\n\n# split items into a list based on a delimiter\nmentions = [x.split(',') for x in mentions]\n\n# flatten list of lists\nmentions = [item for sublist in mentions for item in sublist]\n\n# remove whitespaces\nmentions = list(map(lambda x: x.replace(' ', ''), mentions))\n\n# count items on list\nmentions_count = pd.Series(mentions).value_counts()\n\nmentions_count\n\n\ndiegobranca        1\nAngelalerena       1\nMalenaGalmarini    1\nJMilei             1\nName: count, dtype: int64\n\n\n\n\nTokens\n\n\nCode\n# load the spacy model for Spanish\nnlp = spacy.load(\"es_core_news_sm\")\n\n# load stop words for Spanish\nSTOP_WORDS = nlp.Defaults.stop_words\n\n# Function to filter stop words\ndef filter_stopwords(text):\n    # lower text\n    doc = nlp(text.lower())\n    # filter tokens\n    tokens = [token.text for token in doc if not token.is_stop and token.text not in STOP_WORDS and token.is_alpha]\n    return ' '.join(tokens)\n\n# apply function to dataframe column\ndf_attacks['text_pre'] = df_attacks['text'].apply(filter_stopwords)\n\n# count items on column\ntoken_counts = df_attacks[\"text_pre\"].str.split(expand=True).stack().value_counts()[:20]\n\ntoken_counts\n\n\nvos         32\nsos         31\nlaburo      30\nvas         24\nq           21\namor        20\nlaburar     18\nbuscar      18\norto        15\ncurro       15\nzurda       14\nanda        14\nmierda      14\nvoto        13\nkuka        13\ncara        13\nperoncha    11\nputa        10\ntenes       10\nculo        10\nName: count, dtype: int64"
  },
  {
    "objectID": "pages/6.@edufeiok.html",
    "href": "pages/6.@edufeiok.html",
    "title": "Análisis de tweets atacando a @edufeiok",
    "section": "",
    "text": "Datos\n\n\nCode\ndf_attacks = attacks.loc[attacks['to_journalist'].isin([USERNAME])]\nprint(f'Número de ataques: {len(df_attacks)}')\n\n\nNúmero de ataques: 244\n\n\n\n\nCode\njournalist_mentions = len(df.loc[df['to_journalist'].isin([USERNAME])])\njournalist_attacks = len(df_attacks)\n\npercentage_attacks = (journalist_attacks / journalist_mentions) * 100\n\nproportion = (percentage_attacks / 100) * 10\nproportion_rounded = round(proportion)\n\n\nprint(f'Aproximadamente {proportion_rounded} de cada 10 publicaciones que mencionan a {USERNAME} son ataques')\n\n\nAproximadamente 1 de cada 10 publicaciones que mencionan a @edufeiok son ataques\n\n\n\n\nRanking the tipos de ataques\n\n\nCode\nconditions = ['women', 'politics', 'appearance', 'racism', 'class', 'lgbti', 'criminal', 'calls']\nattacks_count = df_attacks[conditions].sum()\nattacks_count = attacks_count.sort_values(ascending=False)\nattacks_count\n\n\nwomen         76\nappearance    67\npolitics      65\nracism        20\nlgbti          6\ncriminal       6\ncalls          5\nclass          4\ndtype: int64\n\n\n\n\nNúmero de ataques por tipo de evento\n\n\nCode\ndf_attacks['event'].value_counts()\n\n\nevent\nelecciones    190\n2do debate     35\n1er debate     19\nName: count, dtype: int64\n\n\n\n\nPublicaciones por evento\n\n\nCode\njournalist_posts = df.loc[df['from_journalist'].isin([USERNAME])]\njournalist_posts = journalist_posts.dropna(subset=['from_journalist'])\n\neventos = ['1er debate', '2do debate', 'elecciones']\ncolors = ['green', 'purple', 'orange']\neventos_count = {}\n\nfig = px.line()\n\nfor i, evento in enumerate(eventos):\n    evento_data = journalist_posts.loc[journalist_posts['event'].isin([evento])]\n    evento_count = evento_data.groupby('dt_date').size().reset_index(name='count')\n    eventos_count[evento] = evento_count\n    fig.add_scatter(x=evento_count['dt_date'], y=evento_count['count'], name=evento, line=dict(color=colors[i]), hovertemplate='posts: %{y}')\n\nfig.update_layout(title=f'Publicaciones de {USERNAME}', width=600)\nfig.update_xaxes(type='category')\nfig.update_yaxes(range=[0, 100]) \nfig.show()\n\n\n\n                                                \n\n\n\n\nHashtags\n\n\nCode\ndf_attacks['hashtags'] = df_attacks['text'].apply(lambda x: np.nan if pd.isnull(x) or not isinstance(x, str) or len(re.findall(r'#\\w+', x)) == 0 else re.findall(r'#\\w+', x))\n\ndf_attacks['hashtags'] = df_attacks['hashtags'].apply(lambda x: ', '.join(x) if isinstance(x, list) else x)\n\n# convert dataframe column to list\nhashtags = df_attacks['hashtags'].unique()\n\n# remove nan items from list\nhashtags = [x for x in hashtags if not pd.isna(x)]\n\n# split items into a list based on a delimiter\nhashtags = [x.split(',') for x in hashtags]\n\n# flatten list of lists\nhashtags = [item for sublist in hashtags for item in sublist]\n\n# remove whitespaces\nhashtags = list(map(lambda x: x.replace(' ', ''), hashtags))\n\n# count items on list\nhashtags_count = pd.Series(hashtags).value_counts()\n\nhashtags_count\n\n\n#PatoBullrichPresidente2023    1\n#PatoPresidente                1\n#PatriciaBullrich              1\n#argentina                     1\n#Son30Mil                      1\n#fraude                        1\nName: count, dtype: int64\n\n\n\n\nMenciones\n\n\nCode\ndf_attacks['mentions'] = df_attacks['text'].apply(lambda x: np.nan if pd.isnull(x) or not isinstance(x, str) or len(re.findall(r'@(\\w+)', x)) == 0 else re.findall(r'@(\\w+)', x))\n\ndf_attacks['mentions'] = df_attacks['mentions'].apply(lambda x: ', '.join(x) if isinstance(x, list) else x)\n\n# convert dataframe column to list\nmentions = df_attacks['mentions'].unique()\n\n# remove nan items from list\nmentions = [x for x in mentions if not pd.isna(x)]\n\n# split items into a list based on a delimiter\nmentions = [x.split(',') for x in mentions]\n\n# flatten list of lists\nmentions = [item for sublist in mentions for item in sublist]\n\n# remove whitespaces\nmentions = list(map(lambda x: x.replace(' ', ''), mentions))\n\n# count items on list\nmentions_count = pd.Series(mentions).value_counts()\n\nmentions_count\n\n\nedufeiok           1\nCarlosMaslaton     1\nQuintelaRicardo    1\nursuvargues        1\nName: count, dtype: int64\n\n\n\n\nTokens\n\n\nCode\n# load the spacy model for Spanish\nnlp = spacy.load(\"es_core_news_sm\")\n\n# load stop words for Spanish\nSTOP_WORDS = nlp.Defaults.stop_words\n\n# Function to filter stop words\ndef filter_stopwords(text):\n    # lower text\n    doc = nlp(text.lower())\n    # filter tokens\n    tokens = [token.text for token in doc if not token.is_stop and token.text not in STOP_WORDS and token.is_alpha]\n    return ' '.join(tokens)\n\n# apply function to dataframe column\ndf_attacks['text_pre'] = df_attacks['text'].apply(filter_stopwords)\n\n# count items on column\ntoken_counts = df_attacks[\"text_pre\"].str.split(expand=True).stack().value_counts()[:20]\n\ntoken_counts\n\n\nvos          32\nq            27\ntrompas      20\nasco         18\nligó         17\nsos          16\nedu          15\nenano        14\ndas          11\nmassa         9\nfacho         9\npaís          9\nfalopa        8\nligo          8\nviejo         7\nperonista     7\nfalopio       6\nviejos        6\nvotar         6\nmeados        6\nName: count, dtype: int64"
  },
  {
    "objectID": "pages/0.analisis_general.html",
    "href": "pages/0.analisis_general.html",
    "title": "Análisis de tweets durante las elecciones generales 2023 en Argentina",
    "section": "",
    "text": "Datos\n\n\nCode\nprint(f'Número de tweets analizados: {len(df)}')\n\n\nNúmero de tweets analizados: 52476\n\n\n\n\nEventos monitoreados\nCantidad de tweets para cada uno de los eventos monitoreados:\n\n\nCode\ndf['event'].value_counts()\n\n\nevent\nelecciones    27448\n1er debate    12588\n2do debate    12440\nName: count, dtype: int64\n\n\n\n\nFechas de eventos\nPeriodo cubierto para cada evento\n\n\nCode\ndebate1 = df.loc[df['event'].isin(['1er debate'])]\ndebate1_min = debate1['dt_date'].min()\ndebate1_max = debate1['dt_date'].max()\nprint(f'El primer debate contempla tweets desde {debate1_min} hasta {debate1_max}')\n\ndebate2 = df.loc[df['event'].isin(['2do debate'])]\ndebate2_min = debate2['dt_date'].min()\ndebate2_max = debate2['dt_date'].max()\nprint(f'El segundo debate contempla tweets desde {debate2_min} hasta {debate2_max}')\n\nelecciones = df.loc[df['event'].isin(['elecciones'])]\nelecciones_min = elecciones['dt_date'].min()\nelecciones_max = elecciones['dt_date'].max()\nprint(f'Elecciones contempla tweets desde {elecciones_min} hasta {elecciones_max}')\n\n\nEl primer debate contempla tweets desde 2023-09-30 hasta 2023-10-02\nEl segundo debate contempla tweets desde 2023-11-11 hasta 2023-11-13\nElecciones contempla tweets desde 2023-11-16 hasta 2023-11-20\n\n\n\n\nAtaques identificados\n\nNOTA: Un tweet puede tener diversas etiquetas\n\n\n\nCode\nattacks = df.dropna(subset=['label', 'to_journalist'])\n\nprint(f'En los datos se identificaron {len(attacks)} publicaciones etiquetadas como ataques.')\n\n\nEn los datos se identificaron 2950 publicaciones etiquetadas como ataques.\n\n\n\n\nRanking the periodistas más atacados\n\n\nCode\nattacks['to_journalist'].value_counts()\n\n\nto_journalist\n@diegobranca       418\n@JonatanViale      373\n@Angelalerena      326\n@Cris_noticias     266\n@odonnellmaria     256\n@edufeiok          244\n@rialjorge         175\n@robdnavarro       159\n@guadavazquez      136\n@luisnovaresio      99\n@vivicanosaok       81\n@majulluis          78\n@mjolivan           62\n@rominamanguel      57\n@NANCYPAZOS         55\n@nbg__              44\n@Gatosylvestre      34\n@ischargro          26\n@anaecorrea         14\n@cyngarciaradio     11\n@hindelita           7\n@aleberco            7\n@juliamengo          6\n@ertenembaum         5\n@Sietecase           2\n@soyingridbeck       2\n@wwnicolas           2\n@MercedesFunes       2\n@Marcelitaojeda      1\n@negropolisok        1\n@maclorena           1\nName: count, dtype: int64\n\n\n\n\nRanking de periodistas atacados por género\n\nNOTA: Clasificación binaria\n\n\n\nCode\nattacks['journalist_genre'].value_counts()\n\n\njournalist_genre\nH    1622\nM    1328\nName: count, dtype: int64\n\n\n\n\nHombres periodistas más atacados\n\n\nCode\nattacks_men = attacks.loc[attacks['journalist_genre'].isin(['H'])]\nattacks_men['to_journalist'].value_counts()\n\n\nto_journalist\n@diegobranca      418\n@JonatanViale     373\n@edufeiok         244\n@rialjorge        175\n@robdnavarro      159\n@luisnovaresio     99\n@majulluis         78\n@Gatosylvestre     34\n@ischargro         26\n@aleberco           7\n@ertenembaum        5\n@wwnicolas          2\n@Sietecase          2\nName: count, dtype: int64\n\n\n\n\nMujeres periodistas más atacadas\n\n\nCode\nattacks_women = attacks.loc[attacks['journalist_genre'].isin(['M'])]\nattacks_women['to_journalist'].value_counts()\n\n\nto_journalist\n@Angelalerena      326\n@Cris_noticias     266\n@odonnellmaria     256\n@guadavazquez      136\n@vivicanosaok       81\n@mjolivan           62\n@rominamanguel      57\n@NANCYPAZOS         55\n@nbg__              44\n@anaecorrea         14\n@cyngarciaradio     11\n@hindelita           7\n@juliamengo          6\n@soyingridbeck       2\n@MercedesFunes       2\n@Marcelitaojeda      1\n@negropolisok        1\n@maclorena           1\nName: count, dtype: int64\n\n\n\n\nRanking the tipos de ataques para hombres\n\n\nCode\nconditions = ['women', 'politics', 'appearance', 'racism', 'class', 'lgbti', 'criminal', 'calls']\nattacks_men_count = attacks_men[conditions].sum()\nattacks_men_count\n\n\nwomen         370\npolitics      450\nappearance    646\nracism         83\nclass          57\nlgbti          57\ncriminal       31\ncalls          21\ndtype: int64\n\n\n\n\nRanking the tipos de ataques para mujeres\n\n\nCode\nconditions = ['women', 'politics', 'appearance', 'racism', 'class', 'lgbti', 'criminal', 'calls']\nattacks_women_count = attacks_women[conditions].sum()\nattacks_women_count\n\n\nwomen         607\npolitics      424\nappearance    226\nracism         63\nclass          69\nlgbti          19\ncriminal        8\ncalls          10\ndtype: int64\n\n\n\n\nNúmero de ataques por tipo de evento\n\n\nCode\nattacks['event'].value_counts()\n\n\nevent\nelecciones    1584\n1er debate     698\n2do debate     668\nName: count, dtype: int64\n\n\n\n\nActividad de los periodistas en Twitter por género\n\n\nCode\njournalist_posts = df.dropna(subset=['from_journalist'])\nmen_journalist_posts = journalist_posts.loc[journalist_posts['journalist_genre'].isin(['M'])]\nwomen_journalist_posts = journalist_posts.loc[journalist_posts['journalist_genre'].isin(['H'])]\n\nprint(f\"\"\"Tweets publicados por periodistas hombres: {len(men_journalist_posts)}\\nTweets publicados por periodistas mujeres: {len(women_journalist_posts)}\"\"\")\n\n\nTweets publicados por periodistas hombres: 640\nTweets publicados por periodistas mujeres: 292\n\n\n\n\nRanking de periodistas más activos\n\n\nCode\njournalist_activity = df['from_journalist'].value_counts()\njournalist_activity\n\n\nfrom_journalist\n@anaecorrea         105\n@rominamanguel       61\n@rialjorge           61\n@diegobranca         60\n@guadavazquez        55\n@odonnellmaria       45\n@Cris_noticias       42\n@SilvinaMolina       36\n@NANCYPAZOS          35\n@hindelita           35\n@majulluis           32\n@soyingridbeck       31\n@Marcelitaojeda      27\n@nbg__               25\n@Gatosylvestre       25\n@edufeiok            24\n@luisnovaresio       24\n@monigps             23\n@robdnavarro         23\n@Angelalerena        22\n@mjolivan            20\n@MercedesFunes       18\n@maclorena           13\n@vivicanosaok        12\n@aleberco            11\n@silviafbarrio        9\n@juliamengo           9\n@cyngarciaradio       9\n@JonatanViale         8\n@Sietecase            7\n@SANTIAGODELMORO      7\n@ischargro            7\n@mafito11             5\n@wwnicolas            2\n@FlorHalfon           2\n@ertenembaum          1\n@deboraplager         1\nName: count, dtype: int64\n\n\n\n\nPublicaciones de periodistas por evento\n\n\nCode\nmen_debate1 = men_journalist_posts.loc[men_journalist_posts['event'].isin(['1er debate'])]\nmen_count = men_debate1.groupby('dt_date').size().reset_index(name='count')\n\nwomen_debate1 = women_journalist_posts.loc[women_journalist_posts['event'].isin(['1er debate'])]\nwomen_count = women_debate1.groupby('dt_date').size().reset_index(name='count')\n\nfig = px.line()\nfig.add_scatter(x=men_count['dt_date'], y=men_count['count'], name='Hombres', line=dict(color='orange'), hovertemplate='posts: %{y}')\nfig.add_scatter(x=women_count['dt_date'], y=women_count['count'], name='Mujeres', line=dict(color='purple'), hovertemplate='posts: %{y}')\nfig.update_layout(title='Publicaciones de periodistas durante el 1er debate', width=600)\nfig.update_xaxes(type='category')\nfig.show()\n\n\n\n                                                \n\n\n\n\nCode\nmen_debate2 = men_journalist_posts.loc[men_journalist_posts['event'].isin(['2do debate'])]\nmen_count = men_debate2.groupby('dt_date').size().reset_index(name='count')\n\nwomen_debate2 = women_journalist_posts.loc[women_journalist_posts['event'].isin(['2do debate'])]\nwomen_count = women_debate2.groupby('dt_date').size().reset_index(name='count')\n\nfig = px.line()\nfig.add_scatter(x=men_count['dt_date'], y=men_count['count'], name='Hombres', line=dict(color='orange'), hovertemplate='posts: %{y}')\nfig.add_scatter(x=women_count['dt_date'], y=women_count['count'], name='Mujeres', line=dict(color='purple'), hovertemplate='posts: %{y}')\nfig.update_layout(title='Publicaciones de periodistas durante el 2do debate', width=600)\nfig.update_xaxes(type='category')\nfig.show()\n\n\n\n                                                \n\n\n\n\nCode\nmen_elecciones = men_journalist_posts.loc[men_journalist_posts['event'].isin(['elecciones'])]\nmen_count = men_elecciones.groupby('dt_date').size().reset_index(name='count')\n\nwomen_elecciones = women_journalist_posts.loc[women_journalist_posts['event'].isin(['elecciones'])]\nwomen_count = women_elecciones.groupby('dt_date').size().reset_index(name='count')\n\nfig = px.line()\nfig.add_scatter(x=men_count['dt_date'], y=men_count['count'], name='Hombres', line=dict(color='orange'), hovertemplate='posts: %{y}')\nfig.add_scatter(x=women_count['dt_date'], y=women_count['count'], name='Mujeres', line=dict(color='purple'), hovertemplate='posts: %{y}')\nfig.update_layout(title='Publicaciones de periodistas durante las eleciones', width=600)\nfig.update_xaxes(type='category')\nfig.show()\n\n\n\n                                                \n\n\n\n\nRanking de eventos con más ataques para hombres\n\n\nCode\nattacks_men['event'].value_counts()\n\n\nevent\nelecciones    806\n2do debate    435\n1er debate    381\nName: count, dtype: int64\n\n\n\n\nRanking de eventos con más ataques para mujeres\n\n\nCode\nattacks_women['event'].value_counts()\n\n\nevent\nelecciones    778\n1er debate    317\n2do debate    233\nName: count, dtype: int64\n\n\n\n\nHashtags\n20 hashtags más utilizados en los ataques:\n\n\nCode\nattacks['hashtags'] = attacks['text'].apply(lambda x: np.nan if pd.isnull(x) or not isinstance(x, str) or len(re.findall(r'#\\w+', x)) == 0 else re.findall(r'#\\w+', x))\n\nattacks['hashtags'] = attacks['hashtags'].apply(lambda x: ', '.join(x) if isinstance(x, list) else x)\n\n# convert dataframe column to list\nhashtags = attacks['hashtags'].unique()\n\n# remove nan items from list\nhashtags = [x for x in hashtags if not pd.isna(x)]\n\n# split items into a list based on a delimiter\nhashtags = [x.split(',') for x in hashtags]\n\n# flatten list of lists\nhashtags = [item for sublist in hashtags for item in sublist]\n\n# remove whitespaces\nhashtags = list(map(lambda x: x.replace(' ', ''), hashtags))\n\n# count items on list\nhashtags_count = pd.Series(hashtags).value_counts()\n\n# return first n rows in descending order\ntop_hashtags = hashtags_count.nlargest(20)\n\ntop_hashtags\n\n\n#SeVanParaSiempre                3\n#KirchnerismoNuncaMas            2\n#MassaPresidente2023             2\n#Milei2023EnPrimeraVuelta        1\n#Tenemos                         1\n#GORDITOLECHOSO                  1\n#NoAl5toGobiernoK                1\n#NoVasASerPresidente             1\n#nuncamas                        1\n#PalestinaLibre                  1\n#YoVotoAMassa                    1\n#NuncaMilei                      1\n#NuncaMas                        1\n#MileiNo                         1\n#LameTujesK                      1\n#MileiBasuraVosSosLaDictadura    1\n#ElPuebloEnDefensaPropia         1\n#viv                             1\n#BrancatelliPelotudo             1\n#MileiPresidente                 1\nName: count, dtype: int64\n\n\n\n\nMenciones\n20 usuarios más mencionados en los ataques:\n\n\nCode\nattacks['mentions'] = attacks['text'].apply(lambda x: np.nan if pd.isnull(x) or not isinstance(x, str) or len(re.findall(r'@(\\w+)', x)) == 0 else re.findall(r'@(\\w+)', x))\n\nattacks['mentions'] = attacks['mentions'].apply(lambda x: ', '.join(x) if isinstance(x, list) else x)\n\n# convert dataframe column to list\nmentions = attacks['mentions'].unique()\n\n# remove nan items from list\nmentions = [x for x in mentions if not pd.isna(x)]\n\n# split items into a list based on a delimiter\nmentions = [x.split(',') for x in mentions]\n\n# flatten list of lists\nmentions = [item for sublist in mentions for item in sublist]\n\n# remove whitespaces\nmentions = list(map(lambda x: x.replace(' ', ''), mentions))\n\n# count items on list\nmentions_count = pd.Series(mentions).value_counts()\n\n# return first n rows in descending order\ntop_mentions = mentions_count.nlargest(20)\n\ntop_mentions\n\n\nPatoBullrich       4\nSergioMassa        4\nJMilei             3\nminsaurralde       3\nvivicanosaok       2\nCris_noticias      2\nrialjorge          2\nKicillofok         2\nguadavazquez       1\nherlombardi        1\ndiegobranca        1\nluispetri          1\nJorgeTelerman      1\nhoraciorlarreta    1\nAngelalerena       1\nEsmeraldaMitre     1\nertenembaum        1\nmajulluis          1\nLuisNovaresio1     1\nQuintelaRicardo    1\nName: count, dtype: int64\n\n\n\n\nTokens\nLista del top 20 de palabras más comunes y su frecuencia:\n\n\nCode\n# load the spacy model for Spanish\nnlp = spacy.load(\"es_core_news_sm\")\n\n# load stop words for Spanish\nSTOP_WORDS = nlp.Defaults.stop_words\n\n# Function to filter stop words\ndef filter_stopwords(text):\n    # lower text\n    doc = nlp(text.lower())\n    # filter tokens\n    tokens = [token.text for token in doc if not token.is_stop and token.text not in STOP_WORDS and token.is_alpha]\n    return ' '.join(tokens)\n\n# apply function to dataframe column\nattacks['text_pre'] = attacks['text'].apply(filter_stopwords)\n\n# count items on column\ntoken_counts = attacks[\"text_pre\"].str.split(expand=True).stack().value_counts()[:20]\n\ntoken_counts\n\n\nvos        374\nsos        311\nq          244\ngordo      195\nvas        135\nlechoso    126\ngordito    114\nmierda     104\nmilei       99\nzurda       84\nasco        81\nmassa       78\ngente       77\ntenes       74\nviejo       71\nanda        66\ncara        66\nzurdos      64\ngato        62\norto        60\nName: count, dtype: int64\n\n\n\n\nTópicos\nTécnica de modelado de tópicos con transformers y TF-IDF:\n\n\nCode\n# remove urls, mentions, hashtags and numbers\np.set_options(p.OPT.URL, p.OPT.MENTION, p.OPT.NUMBER)\nattacks['text_pre'] = attacks['text_pre'].apply(lambda x: p.clean(x))\n\n\n# filter column\ndocs = attacks['text_pre']\n\n# calculate topics and probabilities\ntopic_model = BERTopic(language=\"multilingual\", calculate_probabilities=True, verbose=True)\n\n# training\ntopics, probs = topic_model.fit_transform(docs)\n\n# visualize topics\ntopic_model.visualize_topics()\n\n\n\n                                                \n\n\n\n\nReducción de tópicos\nMapa con 20 tópicos del contenido de los tweets:\n\n\nCode\n# reduce the number of topics\ntopic_model.reduce_topics(docs, nr_topics=20)\n\n# visualize topics\ntopic_model.visualize_topics()\n\n\n\n                                                \n\n\n\n\nTérminos por tópico\n\n\nCode\ntopic_model.visualize_barchart(top_n_topics=20)\n\n\n\n                                                \n\n\n\n\nTópicos en el tiempo\n\n\nCode\n# convert column to list\ntweets = attacks['text_pre'].to_list()\ntimestamps = attacks['dt_date'].to_list()\n\ntopics_over_time = topic_model.topics_over_time(docs=tweets, \n                                                timestamps=timestamps, \n                                                global_tuning=True, \n                                                evolution_tuning=True, \n                                                nr_bins=20)\n\ntopic_model.visualize_topics_over_time(topics_over_time, top_n_topics=20)"
  },
  {
    "objectID": "pages/9.@guadavazquez.html",
    "href": "pages/9.@guadavazquez.html",
    "title": "Análisis de tweets atacando a @guadavazquez",
    "section": "",
    "text": "Datos\n\n\nCode\ndf_attacks = attacks.loc[attacks['to_journalist'].isin([USERNAME])]\nprint(f'Número de ataques: {len(df_attacks)}')\n\n\nNúmero de ataques: 136\n\n\n\n\nCode\njournalist_mentions = len(df.loc[df['to_journalist'].isin([USERNAME])])\njournalist_attacks = len(df_attacks)\n\npercentage_attacks = (journalist_attacks / journalist_mentions) * 100\n\nproportion = (percentage_attacks / 100) * 10\nproportion_rounded = round(proportion)\n\n\nprint(f'Aproximadamente {proportion_rounded} de cada 10 publicaciones que mencionan a {USERNAME} son ataques')\n\n\nAproximadamente 1 de cada 10 publicaciones que mencionan a @guadavazquez son ataques\n\n\n\n\nRanking the tipos de ataques\n\n\nCode\nconditions = ['women', 'politics', 'appearance', 'racism', 'class', 'lgbti', 'criminal', 'calls']\nattacks_count = df_attacks[conditions].sum()\nattacks_count = attacks_count.sort_values(ascending=False)\nattacks_count\n\n\nwomen         60\npolitics      16\nappearance    12\nracism         4\nlgbti          4\nclass          3\ncalls          2\ncriminal       1\ndtype: int64\n\n\n\n\nNúmero de ataques por tipo de evento\n\n\nCode\ndf_attacks['event'].value_counts()\n\n\nevent\n1er debate    63\nelecciones    53\n2do debate    20\nName: count, dtype: int64\n\n\n\n\nPublicaciones por evento\n\n\nCode\njournalist_posts = df.loc[df['from_journalist'].isin([USERNAME])]\njournalist_posts = journalist_posts.dropna(subset=['from_journalist'])\n\neventos = ['1er debate', '2do debate', 'elecciones']\ncolors = ['green', 'purple', 'orange']\neventos_count = {}\n\nfig = px.line()\n\nfor i, evento in enumerate(eventos):\n    evento_data = journalist_posts.loc[journalist_posts['event'].isin([evento])]\n    evento_count = evento_data.groupby('dt_date').size().reset_index(name='count')\n    eventos_count[evento] = evento_count\n    fig.add_scatter(x=evento_count['dt_date'], y=evento_count['count'], name=evento, line=dict(color=colors[i]), hovertemplate='posts: %{y}')\n\nfig.update_layout(title=f'Publicaciones de {USERNAME}', width=600)\nfig.update_xaxes(type='category')\nfig.update_yaxes(range=[0, 100]) \nfig.show()\n\n\n\n                                                \n\n\n\n\nHashtags\n\n\nCode\ndf_attacks['hashtags'] = df_attacks['text'].apply(lambda x: np.nan if pd.isnull(x) or not isinstance(x, str) or len(re.findall(r'#\\w+', x)) == 0 else re.findall(r'#\\w+', x))\n\ndf_attacks['hashtags'] = df_attacks['hashtags'].apply(lambda x: ', '.join(x) if isinstance(x, list) else x)\n\n# convert dataframe column to list\nhashtags = df_attacks['hashtags'].unique()\n\n# remove nan items from list\nhashtags = [x for x in hashtags if not pd.isna(x)]\n\n# split items into a list based on a delimiter\nhashtags = [x.split(',') for x in hashtags]\n\n# flatten list of lists\nhashtags = [item for sublist in hashtags for item in sublist]\n\n# remove whitespaces\nhashtags = list(map(lambda x: x.replace(' ', ''), hashtags))\n\n# count items on list\nhashtags_count = pd.Series(hashtags).value_counts()\n\nhashtags_count\n\n\n#Tenemos    1\nName: count, dtype: int64\n\n\n\n\nMenciones\n\n\nCode\ndf_attacks['mentions'] = df_attacks['text'].apply(lambda x: np.nan if pd.isnull(x) or not isinstance(x, str) or len(re.findall(r'@(\\w+)', x)) == 0 else re.findall(r'@(\\w+)', x))\n\ndf_attacks['mentions'] = df_attacks['mentions'].apply(lambda x: ', '.join(x) if isinstance(x, list) else x)\n\n# convert dataframe column to list\nmentions = df_attacks['mentions'].unique()\n\n# remove nan items from list\nmentions = [x for x in mentions if not pd.isna(x)]\n\n# split items into a list based on a delimiter\nmentions = [x.split(',') for x in mentions]\n\n# flatten list of lists\nmentions = [item for sublist in mentions for item in sublist]\n\n# remove whitespaces\nmentions = list(map(lambda x: x.replace(' ', ''), mentions))\n\n# count items on list\nmentions_count = pd.Series(mentions).value_counts()\n\nmentions_count\n\n\nvivicanosaok      1\nguadavazquez      1\nedufeiok          1\nEsmeraldaMitre    1\nName: count, dtype: int64\n\n\n\n\nTokens\n\n\nCode\n# load the spacy model for Spanish\nnlp = spacy.load(\"es_core_news_sm\")\n\n# load stop words for Spanish\nSTOP_WORDS = nlp.Defaults.stop_words\n\n# Function to filter stop words\ndef filter_stopwords(text):\n    # lower text\n    doc = nlp(text.lower())\n    # filter tokens\n    tokens = [token.text for token in doc if not token.is_stop and token.text not in STOP_WORDS and token.is_alpha]\n    return ' '.join(tokens)\n\n# apply function to dataframe column\ndf_attacks['text_pre'] = df_attacks['text'].apply(filter_stopwords)\n\n# count items on column\ntoken_counts = df_attacks[\"text_pre\"].str.split(expand=True).stack().value_counts()[:20]\n\ntoken_counts\n\n\ngato              24\nq                  8\nguada              7\nsos                7\nabrazo             6\nmedicado           6\nperonchos          6\ncara               6\nentiendo           5\nfamilia            5\ngatos              5\nre                 5\nvos                5\nja                 4\nmedicación         4\nfalopeado          4\nrivotril           4\nmental             4\ncielo              3\ndesequilibrado     3\nName: count, dtype: int64"
  },
  {
    "objectID": "pages/2.@JonatanViale.html",
    "href": "pages/2.@JonatanViale.html",
    "title": "Análisis de tweets atacando a @JonatanViale",
    "section": "",
    "text": "Datos\n\n\nCode\ndf_attacks = attacks.loc[attacks['to_journalist'].isin([USERNAME])]\nprint(f'Número de ataques: {len(df_attacks)}')\n\n\nNúmero de ataques: 373\n\n\n\n\nCode\njournalist_mentions = len(df.loc[df['to_journalist'].isin([USERNAME])])\njournalist_attacks = len(df_attacks)\n\npercentage_attacks = (journalist_attacks / journalist_mentions) * 100\n\nproportion = (percentage_attacks / 100) * 10\nproportion_rounded = round(proportion)\n\n\nprint(f'Aproximadamente {proportion_rounded} de cada 10 publicaciones que mencionan a {USERNAME} son ataques')\n\n\nAproximadamente 2 de cada 10 publicaciones que mencionan a @JonatanViale son ataques\n\n\n\n\nRanking the tipos de ataques\n\n\nCode\nconditions = ['women', 'politics', 'appearance', 'racism', 'class', 'lgbti', 'criminal', 'calls']\nattacks_count = df_attacks[conditions].sum()\nattacks_count = attacks_count.sort_values(ascending=False)\nattacks_count\n\n\nappearance    229\nwomen          92\npolitics       36\nracism         15\ncriminal        6\nclass           5\nlgbti           3\ncalls           2\ndtype: int64\n\n\n\n\nNúmero de ataques por tipo de evento\n\n\nCode\ndf_attacks['event'].value_counts()\n\n\nevent\n2do debate    176\nelecciones    130\n1er debate     67\nName: count, dtype: int64\n\n\n\n\nPublicaciones por evento\n\n\nCode\njournalist_posts = df.loc[df['from_journalist'].isin([USERNAME])]\njournalist_posts = journalist_posts.dropna(subset=['from_journalist'])\n\neventos = ['1er debate', '2do debate', 'elecciones']\ncolors = ['green', 'purple', 'orange']\neventos_count = {}\n\nfig = px.line()\n\nfor i, evento in enumerate(eventos):\n    evento_data = journalist_posts.loc[journalist_posts['event'].isin([evento])]\n    evento_count = evento_data.groupby('dt_date').size().reset_index(name='count')\n    eventos_count[evento] = evento_count\n    fig.add_scatter(x=evento_count['dt_date'], y=evento_count['count'], name=evento, line=dict(color=colors[i]), hovertemplate='posts: %{y}')\n\nfig.update_layout(title=f'Publicaciones de {USERNAME}', width=600)\nfig.update_xaxes(type='category')\nfig.update_yaxes(range=[0, 100]) \nfig.show()\n\n\n\n                                                \n\n\n\n\nHashtags\n\n\nCode\ndf_attacks['hashtags'] = df_attacks['text'].apply(lambda x: np.nan if pd.isnull(x) or not isinstance(x, str) or len(re.findall(r'#\\w+', x)) == 0 else re.findall(r'#\\w+', x))\n\ndf_attacks['hashtags'] = df_attacks['hashtags'].apply(lambda x: ', '.join(x) if isinstance(x, list) else x)\n\n# convert dataframe column to list\nhashtags = df_attacks['hashtags'].unique()\n\n# remove nan items from list\nhashtags = [x for x in hashtags if not pd.isna(x)]\n\n# split items into a list based on a delimiter\nhashtags = [x.split(',') for x in hashtags]\n\n# flatten list of lists\nhashtags = [item for sublist in hashtags for item in sublist]\n\n# remove whitespaces\nhashtags = list(map(lambda x: x.replace(' ', ''), hashtags))\n\n# count items on list\nhashtags_count = pd.Series(hashtags).value_counts()\n\nhashtags_count\n\n\n#SeVanParaSiempre         1\n#MemoriaAlVotar           1\n#EsCorrupciónOJusticia    1\n#MassaPresidente          1\n#MassaPresidente2023      1\n#NoAMilei                 1\n#GORDITOLECHOSO           1\n#Gorditolechoso           1\n#Periodistaensobrado      1\nName: count, dtype: int64\n\n\n\n\nMenciones\n\n\nCode\ndf_attacks['mentions'] = df_attacks['text'].apply(lambda x: np.nan if pd.isnull(x) or not isinstance(x, str) or len(re.findall(r'@(\\w+)', x)) == 0 else re.findall(r'@(\\w+)', x))\n\ndf_attacks['mentions'] = df_attacks['mentions'].apply(lambda x: ', '.join(x) if isinstance(x, list) else x)\n\n# convert dataframe column to list\nmentions = df_attacks['mentions'].unique()\n\n# remove nan items from list\nmentions = [x for x in mentions if not pd.isna(x)]\n\n# split items into a list based on a delimiter\nmentions = [x.split(',') for x in mentions]\n\n# flatten list of lists\nmentions = [item for sublist in mentions for item in sublist]\n\n# remove whitespaces\nmentions = list(map(lambda x: x.replace(' ', ''), mentions))\n\n# count items on list\nmentions_count = pd.Series(mentions).value_counts()\n\nmentions_count\n\n\nvivicanosaok       1\nPatoBullrich       1\nJonatanViale       1\nMalenaGalmarini    1\nedufeiok           1\nKicillofok         1\nminsaurralde       1\nLANACION           1\nJMilei             1\nc0o0ni             1\nPontifex_es        1\nName: count, dtype: int64\n\n\n\n\nTokens\n\n\nCode\n# load the spacy model for Spanish\nnlp = spacy.load(\"es_core_news_sm\")\n\n# load stop words for Spanish\nSTOP_WORDS = nlp.Defaults.stop_words\n\n# Function to filter stop words\ndef filter_stopwords(text):\n    # lower text\n    doc = nlp(text.lower())\n    # filter tokens\n    tokens = [token.text for token in doc if not token.is_stop and token.text not in STOP_WORDS and token.is_alpha]\n    return ' '.join(tokens)\n\n# apply function to dataframe column\ndf_attacks['text_pre'] = df_attacks['text'].apply(filter_stopwords)\n\n# count items on column\ntoken_counts = df_attacks[\"text_pre\"].str.split(expand=True).stack().value_counts()[:20]\n\ntoken_counts\n\n\nlechoso       122\ngordito        81\ngordo          61\nvas            45\nvos            39\nsos            38\nq              30\nleche          21\nrodilleras     16\npija           15\nensobrado      13\npelotudo       13\nviejo          13\nmacri          12\nchupa          11\ncara           10\nmilei           9\nmierda          9\ntomar           9\nhijo            8\nName: count, dtype: int64"
  },
  {
    "objectID": "pages/11.@vivicanosaok.html",
    "href": "pages/11.@vivicanosaok.html",
    "title": "Análisis de tweets atacando a @vivicanosaok",
    "section": "",
    "text": "Datos\n\n\nCode\ndf_attacks = attacks.loc[attacks['to_journalist'].isin([USERNAME])]\nprint(f'Número de ataques: {len(df_attacks)}')\n\n\nNúmero de ataques: 81\n\n\n\n\nCode\njournalist_mentions = len(df.loc[df['to_journalist'].isin([USERNAME])])\njournalist_attacks = len(df_attacks)\n\npercentage_attacks = (journalist_attacks / journalist_mentions) * 100\n\nproportion = (percentage_attacks / 100) * 10\nproportion_rounded = round(proportion)\n\n\nprint(f'Aproximadamente {proportion_rounded} de cada 10 publicaciones que mencionan a {USERNAME} son ataques')\n\n\nAproximadamente 0 de cada 10 publicaciones que mencionan a @vivicanosaok son ataques\n\n\n\n\nRanking the tipos de ataques\n\n\nCode\nconditions = ['women', 'politics', 'appearance', 'racism', 'class', 'lgbti', 'criminal', 'calls']\nattacks_count = df_attacks[conditions].sum()\nattacks_count = attacks_count.sort_values(ascending=False)\nattacks_count\n\n\nwomen         49\nappearance    21\npolitics       8\nclass          2\nracism         1\nlgbti          1\ncriminal       0\ncalls          0\ndtype: int64\n\n\n\n\nNúmero de ataques por tipo de evento\n\n\nCode\ndf_attacks['event'].value_counts()\n\n\nevent\n1er debate    45\n2do debate    21\nelecciones    15\nName: count, dtype: int64\n\n\n\n\nPublicaciones por evento\n\n\nCode\njournalist_posts = df.loc[df['from_journalist'].isin([USERNAME])]\njournalist_posts = journalist_posts.dropna(subset=['from_journalist'])\n\neventos = ['1er debate', '2do debate', 'elecciones']\ncolors = ['green', 'purple', 'orange']\neventos_count = {}\n\nfig = px.line()\n\nfor i, evento in enumerate(eventos):\n    evento_data = journalist_posts.loc[journalist_posts['event'].isin([evento])]\n    evento_count = evento_data.groupby('dt_date').size().reset_index(name='count')\n    eventos_count[evento] = evento_count\n    fig.add_scatter(x=evento_count['dt_date'], y=evento_count['count'], name=evento, line=dict(color=colors[i]), hovertemplate='posts: %{y}')\n\nfig.update_layout(title=f'Publicaciones de {USERNAME}', width=600)\nfig.update_xaxes(type='category')\nfig.update_yaxes(range=[0, 100]) \nfig.show()\n\n\n\n                                                \n\n\n\n\nHashtags\n\n\nCode\ndf_attacks['hashtags'] = df_attacks['text'].apply(lambda x: np.nan if pd.isnull(x) or not isinstance(x, str) or len(re.findall(r'#\\w+', x)) == 0 else re.findall(r'#\\w+', x))\n\ndf_attacks['hashtags'] = df_attacks['hashtags'].apply(lambda x: ', '.join(x) if isinstance(x, list) else x)\n\n# convert dataframe column to list\nhashtags = df_attacks['hashtags'].unique()\n\n# remove nan items from list\nhashtags = [x for x in hashtags if not pd.isna(x)]\n\n# split items into a list based on a delimiter\nhashtags = [x.split(',') for x in hashtags]\n\n# flatten list of lists\nhashtags = [item for sublist in hashtags for item in sublist]\n\n# remove whitespaces\nhashtags = list(map(lambda x: x.replace(' ', ''), hashtags))\n\n# count items on list\nhashtags_count = pd.Series(hashtags).value_counts()\n\nhashtags_count\n\n\n#Milei               1\n#VotoContraMassa     1\n#SeVanParaSiempre    1\nName: count, dtype: int64\n\n\n\n\nMenciones\n\n\nCode\ndf_attacks['mentions'] = df_attacks['text'].apply(lambda x: np.nan if pd.isnull(x) or not isinstance(x, str) or len(re.findall(r'@(\\w+)', x)) == 0 else re.findall(r'@(\\w+)', x))\n\ndf_attacks['mentions'] = df_attacks['mentions'].apply(lambda x: ', '.join(x) if isinstance(x, list) else x)\n\n# convert dataframe column to list\nmentions = df_attacks['mentions'].unique()\n\n# remove nan items from list\nmentions = [x for x in mentions if not pd.isna(x)]\n\n# split items into a list based on a delimiter\nmentions = [x.split(',') for x in mentions]\n\n# flatten list of lists\nmentions = [item for sublist in mentions for item in sublist]\n\n# remove whitespaces\nmentions = list(map(lambda x: x.replace(' ', ''), mentions))\n\n# count items on list\nmentions_count = pd.Series(mentions).value_counts()\n\nmentions_count\n\n\nPatoBullrich    1\nvivicanosaok    1\nJMilei          1\nName: count, dtype: int64\n\n\n\n\nTokens\n\n\nCode\n# load the spacy model for Spanish\nnlp = spacy.load(\"es_core_news_sm\")\n\n# load stop words for Spanish\nSTOP_WORDS = nlp.Defaults.stop_words\n\n# Function to filter stop words\ndef filter_stopwords(text):\n    # lower text\n    doc = nlp(text.lower())\n    # filter tokens\n    tokens = [token.text for token in doc if not token.is_stop and token.text not in STOP_WORDS and token.is_alpha]\n    return ' '.join(tokens)\n\n# apply function to dataframe column\ndf_attacks['text_pre'] = df_attacks['text'].apply(filter_stopwords)\n\n# count items on column\ntoken_counts = df_attacks[\"text_pre\"].str.split(expand=True).stack().value_counts()[:20]\n\ntoken_counts\n\n\nmilei        11\nmassa        10\nviviana       7\npautosa       6\nsos           6\ndebate        5\ncanosa        5\nq             5\nmentiroso     4\nanda          4\nvos           4\nmina          4\nenseñarle     4\nviejo         4\npobre         3\ndas           3\nre            3\nvieja         3\nvivi          3\nfavor         3\nName: count, dtype: int64"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Análisis de tweets durante las elecciones generales 2023 en Argentina",
    "section": "",
    "text": "Para llevar acabo este análisis de datos, Data Crítica analizó los datos recolectados por Chequeado. El periodo de los tweets recolectados abarca desde 30-09-2023 hasta 20-11-2023.\nLos textos de los tweets fueron clasificados programáticamente utilizando un modelo de machine learning con la librería de Python transformers para generar etiquetas con tipos de discursos de odio.\nEl modelo utilizado para este etiquetado lleva por nombre beto-contextualized-hate-speech en Hugging Face y fue elegido ya que está entrenado con datos recolectados en el contexto de Argentina.\nEste modelo tiene 9 clasificaciones distintas:\n\n\n\nEtiqueta\nDescripción\n\n\n\n\nWOMEN\nEn contra de mujeres\n\n\nLGBTI\nEn contra LGBTI\n\n\nRACISM\nRacista\n\n\nCLASS\nClasista\n\n\nPOLITICS\nDebido a política\n\n\nDISABLED\nAbleista\n\n\nAPPEARANCE\nEn contra debido a su apariencia\n\n\nCRIMINAL\nEn contra de criminales\n\n\nCALLS\nLlamado a la violencia\n\n\n\n\nJupyter Notebooks creados por Fernanda Aguirre"
  },
  {
    "objectID": "index.html#metodología",
    "href": "index.html#metodología",
    "title": "Análisis de tweets durante las elecciones generales 2023 en Argentina",
    "section": "",
    "text": "Para llevar acabo este análisis de datos, Data Crítica analizó los datos recolectados por Chequeado. El periodo de los tweets recolectados abarca desde 30-09-2023 hasta 20-11-2023.\nLos textos de los tweets fueron clasificados programáticamente utilizando un modelo de machine learning con la librería de Python transformers para generar etiquetas con tipos de discursos de odio.\nEl modelo utilizado para este etiquetado lleva por nombre beto-contextualized-hate-speech en Hugging Face y fue elegido ya que está entrenado con datos recolectados en el contexto de Argentina.\nEste modelo tiene 9 clasificaciones distintas:\n\n\n\nEtiqueta\nDescripción\n\n\n\n\nWOMEN\nEn contra de mujeres\n\n\nLGBTI\nEn contra LGBTI\n\n\nRACISM\nRacista\n\n\nCLASS\nClasista\n\n\nPOLITICS\nDebido a política\n\n\nDISABLED\nAbleista\n\n\nAPPEARANCE\nEn contra debido a su apariencia\n\n\nCRIMINAL\nEn contra de criminales\n\n\nCALLS\nLlamado a la violencia\n\n\n\n\nJupyter Notebooks creados por Fernanda Aguirre"
  }
]