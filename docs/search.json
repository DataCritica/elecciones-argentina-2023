[
  {
    "objectID": "pages/analisis_general.html",
    "href": "pages/analisis_general.html",
    "title": "Análisis de tweets durante las elecciones generales 2023 en Argentina",
    "section": "",
    "text": "Datos\n\n\nCode\nprint(f'Número de tweets analizados: {len(df)}')\n\n\nNúmero de tweets analizados: 52476\n\n\n\n\nEventos monitoreados\nCantidad de tweets para cada uno de los eventos monitoreados:\n\n\nCode\ndf['event'].value_counts()\n\n\nevent\nelecciones    27448\n1er debate    12588\n2do debate    12440\nName: count, dtype: int64\n\n\n\n\nFechas de eventos\nPeriodo cubierto para cada evento\n\n\nCode\ndebate1 = df.loc[df['event'].isin(['1er debate'])]\ndebate1_min = debate1['dt_date'].min()\ndebate1_max = debate1['dt_date'].max()\nprint(f'El primer debate contempla tweets desde {debate1_min} hasta {debate1_max}')\n\ndebate2 = df.loc[df['event'].isin(['2do debate'])]\ndebate2_min = debate2['dt_date'].min()\ndebate2_max = debate2['dt_date'].max()\nprint(f'El segundo debate contempla tweets desde {debate2_min} hasta {debate2_max}')\n\nelecciones = df.loc[df['event'].isin(['elecciones'])]\nelecciones_min = elecciones['dt_date'].min()\nelecciones_max = elecciones['dt_date'].max()\nprint(f'Elecciones contempla tweets desde {elecciones_min} hasta {elecciones_max}')\n\n\nEl primer debate contempla tweets desde 2023-09-30 hasta 2023-10-02\nEl segundo debate contempla tweets desde 2023-11-11 hasta 2023-11-13\nElecciones contempla tweets desde 2023-11-16 hasta 2023-11-20\n\n\n\n\nAtaques identificados\n\nNOTA: Un tweet puede tener diversas etiquetas\n\n\n\nCode\nconditions = ['women', 'politics', 'appearance', 'racism', 'class', 'lgbti', 'criminal', 'calls']\nattacks = df.loc[df[conditions].isin([1]).any(axis=1)]\nprint(f'En los datos se identificaron {len(attacks)} publicaciones etiquetadas como ataques.')\n\n\nEn los datos se identificaron 3613 publicaciones etiquetadas como ataques.\n\n\n\n\nRanking the periodistas más atacados\n\n\nCode\nattacks['journalist_username'].value_counts()\n\n\njournalist_username\n@diegobranca        431\n@JonatanViale       408\n@Angelalerena       330\n@edufeiok           299\n@Cris_noticias      260\n@odonnellmaria      244\n@rialjorge          220\n@robdnavarro        175\n@vivicanosaok       135\n@luisnovaresio      132\n@guadavazquez       106\n@Gatosylvestre       91\n@majulluis           83\n@NANCYPAZOS          73\n@cyngarciaradio      66\n@mjolivan            62\n@fantinofantino      60\n@rominamanguel       58\n@nbg__               51\n@lucianageuna        48\n@ischargro           39\n@marialauratv        36\n@juliamengo          29\n@aleberco            26\n@anaecorrea          25\n@ertenembaum         19\n@VHMok               15\n@barilirodolfo       14\n@negropolisok        14\n@diegoleuco           9\n@hindelita            8\n@Sietecase            8\n@alfleuco             6\n@andykusnetzoff       6\n@wwnicolas            4\n@MercedesFunes        4\n@SANTIAGODELMORO      4\n@deboraplager         4\n@maclorena            3\n@soyingridbeck        3\n@Marcelitaojeda       2\n@SilvinaMolina        1\n@monigps              1\n@FlorHalfon           1\nName: count, dtype: int64\n\n\n\n\nRanking de periodistas atacados por género\n\nNOTA: Clasificación binaria\n\n\n\nCode\nattacks['journalist_genre'].value_counts()\n\n\njournalist_genre\nH    2049\nM    1564\nName: count, dtype: int64\n\n\n\n\nHombres periodistas más atacados\n\n\nCode\nattacks_men = attacks.loc[attacks['journalist_genre'].isin(['H'])]\nattacks_men['journalist_username'].value_counts()\n\n\njournalist_username\n@diegobranca        431\n@JonatanViale       408\n@edufeiok           299\n@rialjorge          220\n@robdnavarro        175\n@luisnovaresio      132\n@Gatosylvestre       91\n@majulluis           83\n@fantinofantino      60\n@ischargro           39\n@aleberco            26\n@ertenembaum         19\n@VHMok               15\n@barilirodolfo       14\n@diegoleuco           9\n@Sietecase            8\n@alfleuco             6\n@andykusnetzoff       6\n@SANTIAGODELMORO      4\n@wwnicolas            4\nName: count, dtype: int64\n\n\n\n\nMujeres periodistas más atacadas\n\n\nCode\nattacks_women = attacks.loc[attacks['journalist_genre'].isin(['M'])]\nattacks_women['journalist_username'].value_counts()\n\n\njournalist_username\n@Angelalerena      330\n@Cris_noticias     260\n@odonnellmaria     244\n@vivicanosaok      135\n@guadavazquez      106\n@NANCYPAZOS         73\n@cyngarciaradio     66\n@mjolivan           62\n@rominamanguel      58\n@nbg__              51\n@lucianageuna       48\n@marialauratv       36\n@juliamengo         29\n@anaecorrea         25\n@negropolisok       14\n@hindelita           8\n@deboraplager        4\n@MercedesFunes       4\n@maclorena           3\n@soyingridbeck       3\n@Marcelitaojeda      2\n@SilvinaMolina       1\n@monigps             1\n@FlorHalfon          1\nName: count, dtype: int64\n\n\n\n\nRanking the tipos de ataques para hombres\n\n\nCode\nconditions = ['women', 'politics', 'appearance', 'racism', 'class', 'lgbti', 'criminal', 'calls']\nattacks_men_count = attacks_men[conditions].sum()\nattacks_men_count\n\n\nwomen         518\npolitics      626\nappearance    800\nracism        124\nclass          73\nlgbti          98\ncriminal       37\ncalls          30\ndtype: int64\n\n\n\n\nRanking the tipos de ataques para mujeres\n\n\nCode\nconditions = ['women', 'politics', 'appearance', 'racism', 'class', 'lgbti', 'criminal', 'calls']\nattacks_women_count = attacks_women[conditions].sum()\nattacks_women_count\n\n\nwomen         751\npolitics      529\nappearance    312\nracism         90\nclass          76\nlgbti          30\ncriminal       12\ncalls          15\ndtype: int64\n\n\n\n\nNúmero de ataques por tipo de evento\n\n\nCode\nattacks['event'].value_counts()\n\n\nevent\nelecciones    2027\n2do debate     816\n1er debate     770\nName: count, dtype: int64\n\n\n\n\nRanking de eventos con más ataques para hombres\n\n\nCode\nattacks_men['event'].value_counts()\n\n\nevent\nelecciones    1061\n2do debate     547\n1er debate     441\nName: count, dtype: int64\n\n\n\n\nRanking de eventos con más ataques para mujeres\n\n\nCode\nattacks_women['event'].value_counts()\n\n\nevent\nelecciones    966\n1er debate    329\n2do debate    269\nName: count, dtype: int64\n\n\n\n\nHashtags\n20 hashtags más utilizados en los ataques:\n\n\nCode\nattacks['hashtags'] = attacks['text'].apply(lambda x: np.nan if pd.isnull(x) or not isinstance(x, str) or len(re.findall(r'#\\w+', x)) == 0 else re.findall(r'#\\w+', x))\n\nattacks['hashtags'] = attacks['hashtags'].apply(lambda x: ', '.join(x) if isinstance(x, list) else x)\n\n# convert dataframe column to list\nhashtags = attacks['hashtags'].unique()\n\n# remove nan items from list\nhashtags = [x for x in hashtags if not pd.isna(x)]\n\n# split items into a list based on a delimiter\nhashtags = [x.split(',') for x in hashtags]\n\n# flatten list of lists\nhashtags = [item for sublist in hashtags for item in sublist]\n\n# remove whitespaces\nhashtags = list(map(lambda x: x.replace(' ', ''), hashtags))\n\n# count items on list\nhashtags_count = pd.Series(hashtags).value_counts()\n\n# return first n rows in descending order\ntop_hashtags = hashtags_count.nlargest(20)\n\ntop_hashtags\n\n\n#SeVanParaSiempre                4\n#DebatePresidencial2023          3\n#KirchnerismoNuncaMas            3\n#Debate2023                      3\n#lasmargaritas                   2\n#VotoContraMassa                 2\n#MileiPresidente                 2\n#ElClubDelMoro                   2\n#iPhone15ProMax                  1\n#ElPuebloEnDefensaPropia         1\n#MileiBasuraVosSosLaDictadura    1\n#LameTujesK                      1\n#fraude                          1\n#Tenemos                         1\n#NoAMilei                        1\n#Hora17                          1\n#NoAl5toGobiernoK                1\n#NoVasASerPresidente             1\n#partidodelacosta                1\n#GORDITOLECHOSO                  1\nName: count, dtype: int64\n\n\n\n\nMenciones\n20 usuarios más mencionados en los ataques:\n\n\nCode\nattacks['mentions'] = attacks['text'].apply(lambda x: np.nan if pd.isnull(x) or not isinstance(x, str) or len(re.findall(r'@(\\w+)', x)) == 0 else re.findall(r'@(\\w+)', x))\n\nattacks['mentions'] = attacks['mentions'].apply(lambda x: ', '.join(x) if isinstance(x, list) else x)\n\n# convert dataframe column to list\nmentions = attacks['mentions'].unique()\n\n# remove nan items from list\nmentions = [x for x in mentions if not pd.isna(x)]\n\n# split items into a list based on a delimiter\nmentions = [x.split(',') for x in mentions]\n\n# flatten list of lists\nmentions = [item for sublist in mentions for item in sublist]\n\n# remove whitespaces\nmentions = list(map(lambda x: x.replace(' ', ''), mentions))\n\n# count items on list\nmentions_count = pd.Series(mentions).value_counts()\n\n# return first n rows in descending order\ntop_mentions = mentions_count.nlargest(20)\n\ntop_mentions\n\n\nJonatanViale      15\nedufeiok          12\nJMilei            12\nSergioMassa       12\nC5N               11\nvivicanosaok      11\nPatoBullrich      10\nlanacionmas        9\nGatosylvestre      9\nrialjorge          8\nNANCYPAZOS         8\nPRossiOficial      7\nmarialauratv       7\nmajulluis          6\ndiegobranca        6\nmyriambregman      6\nluisnovaresio      6\naleberco           4\nfantinofantino     4\nrobdnavarro        4\nName: count, dtype: int64\n\n\n\n\nTokens\nLista del top 20 de palabras más comunes y su frecuencia:\n\n\nCode\n# load the spacy model for Spanish\nnlp = spacy.load(\"es_core_news_sm\")\n\n# load stop words for Spanish\nSTOP_WORDS = nlp.Defaults.stop_words\n\n# Function to filter stop words\ndef filter_stopwords(text):\n    # lower text\n    doc = nlp(text.lower())\n    # filter tokens\n    tokens = [token.text for token in doc if not token.is_stop and token.text not in STOP_WORDS and token.is_alpha]\n    return ' '.join(tokens)\n\n# apply function to dataframe column\nattacks['text_pre'] = attacks['text'].apply(filter_stopwords)\n\n# count items on column\ntoken_counts = attacks[\"text_pre\"].str.split(expand=True).stack().value_counts()[:20]\n\ntoken_counts\n\n\nvos        421\nsos        353\nq          301\ngordo      212\nvas        156\nlechoso    136\nmierda     130\nmilei      123\ngordito    121\nviejo      111\nzurdos     103\ncara       101\nzurda       98\ntenes       97\nasco        91\ngato        90\nmassa       88\nanda        84\ngente       83\norto        76\nName: count, dtype: int64\n\n\n\n\nTópicos\nTécnica de modelado de tópicos con transformers y TF-IDF:\n\n\nCode\n# remove urls, mentions, hashtags and numbers\np.set_options(p.OPT.URL, p.OPT.MENTION, p.OPT.NUMBER)\nattacks['text_pre'] = attacks['text_pre'].apply(lambda x: p.clean(x))\n\n\n# filter column\ndocs = attacks['text_pre']\n\n# calculate topics and probabilities\ntopic_model = BERTopic(language=\"multilingual\", calculate_probabilities=True, verbose=True)\n\n# training\ntopics, probs = topic_model.fit_transform(docs)\n\n# visualize topics\ntopic_model.visualize_topics()\n\n\n\n                                                \n\n\n\n\nReducción de tópicos\nMapa con 20 tópicos del contenido de los tweets:\n\n\nCode\n# reduce the number of topics\ntopic_model.reduce_topics(docs, nr_topics=20)\n\n# visualize topics\ntopic_model.visualize_topics()\n\n\n\n                                                \n\n\n\n\nTérminos por tópico\n\n\nCode\ntopic_model.visualize_barchart(top_n_topics=20)\n\n\n\n                                                \n\n\n\n\nTópicos en el tiempo\n\n\nCode\n# convert column to list\ntweets = attacks['text_pre'].to_list()\ntimestamps = attacks['dt_date'].to_list()\n\ntopics_over_time = topic_model.topics_over_time(docs=tweets, \n                                                timestamps=timestamps, \n                                                global_tuning=True, \n                                                evolution_tuning=True, \n                                                nr_bins=20)\n\ntopic_model.visualize_topics_over_time(topics_over_time, top_n_topics=20)"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Análisis de tweets durante las elecciones generales 2023 en Argentina",
    "section": "",
    "text": "Para llevar acabo este análisis de datos, Data Crítica analizó los datos recolectados por Chequeado. El periodo de los tweets recolectados abarca desde 30-09-2023 hasta 20-11-2023.\nLos textos de los tweets fueron clasificados programáticamente utilizando un modelo de machine learning con la librería de Python transformers para generar etiquetas con tipos de discursos de odio.\nEl modelo utilizado para este etiquetado lleva por nombre beto-contextualized-hate-speech en Hugging Face y fue elegido ya que está entrenado con datos recolectados en el contexto de Argentina.\nEste modelo tiene 9 clasificaciones distintas:\n\n\n\nEtiqueta\nDescripción\n\n\n\n\nWOMEN\nEn contra de mujeres\n\n\nLGBTI\nEn contra LGBTI\n\n\nRACISM\nRacista\n\n\nCLASS\nClasista\n\n\nPOLITICS\nDebido a política\n\n\nDISABLED\nAbleista\n\n\nAPPEARANCE\nEn contra debido a su apariencia\n\n\nCRIMINAL\nEn contra de criminales\n\n\nCALLS\nLlamado a la violencia\n\n\n\n\nJupyter Notebooks creados por Fernanda Aguirre"
  },
  {
    "objectID": "index.html#metodología",
    "href": "index.html#metodología",
    "title": "Análisis de tweets durante las elecciones generales 2023 en Argentina",
    "section": "",
    "text": "Para llevar acabo este análisis de datos, Data Crítica analizó los datos recolectados por Chequeado. El periodo de los tweets recolectados abarca desde 30-09-2023 hasta 20-11-2023.\nLos textos de los tweets fueron clasificados programáticamente utilizando un modelo de machine learning con la librería de Python transformers para generar etiquetas con tipos de discursos de odio.\nEl modelo utilizado para este etiquetado lleva por nombre beto-contextualized-hate-speech en Hugging Face y fue elegido ya que está entrenado con datos recolectados en el contexto de Argentina.\nEste modelo tiene 9 clasificaciones distintas:\n\n\n\nEtiqueta\nDescripción\n\n\n\n\nWOMEN\nEn contra de mujeres\n\n\nLGBTI\nEn contra LGBTI\n\n\nRACISM\nRacista\n\n\nCLASS\nClasista\n\n\nPOLITICS\nDebido a política\n\n\nDISABLED\nAbleista\n\n\nAPPEARANCE\nEn contra debido a su apariencia\n\n\nCRIMINAL\nEn contra de criminales\n\n\nCALLS\nLlamado a la violencia\n\n\n\n\nJupyter Notebooks creados por Fernanda Aguirre"
  }
]