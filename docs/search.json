[
  {
    "objectID": "pages/10.@vivicanosaok.html",
    "href": "pages/10.@vivicanosaok.html",
    "title": "Análisis de tweets atacando a @vivicanosaok",
    "section": "",
    "text": "Datos\n\n\nCode\ndf_attacks = attacks.loc[attacks[\"to_journalist\"].isin([USERNAME])]\nprint(f\"Número de ataques: {len(df_attacks)}\")\n\n\nNúmero de ataques: 159\n\n\n\n\nFrecuencia de ataques\nProporción de ataques = (Número de ataques / Número de menciones) * 100\n\n\nCode\njournalist_mentions = len(df.loc[df[\"to_journalist\"].isin([USERNAME])])\njournalist_attacks = len(df_attacks)\n\npercentage_attacks = (journalist_attacks / journalist_mentions) * 100\n\nproportion = (percentage_attacks / 100) * 10\nproportion_rounded = round(proportion, 1)\n\n\nprint(\n    f\"Aproximadamente {proportion_rounded} de cada 10 publicaciones que mencionan a {USERNAME} son ataques\"\n)\n\n\nAproximadamente 0.6 de cada 10 publicaciones que mencionan a @vivicanosaok son ataques\n\n\n\n\nFrecuencia de los ataques en función del número de seguidores\nProporción de ataques por seguidor = Número de ataques / Número de seguidores\n\n\nCode\nproportion_followers = (len(df_attacks) / 742466) * 1000\nformatted_proportion = \"{:.2f}\".format(proportion_followers)\nprint(f\"Por cada 1K seguidores, hubo {formatted_proportion} ataques para {USERNAME}\")\n\n\nPor cada 1K seguidores, hubo 0.21 ataques para @vivicanosaok\n\n\n\n\nRanking de tipos de ataques\n\n\nCode\nconditions = [\n    \"women\",\n    \"politics\",\n    \"appearance\",\n    \"racism\",\n    \"class\",\n    \"lgbti\",\n    \"criminal\",\n    \"calls\",\n]\nattacks_count = df_attacks[conditions].sum()\nattacks_count = attacks_count.sort_values(ascending=False)\nattacks_count\n\n\nwomen         91\nappearance    50\npolitics      14\nracism         4\nclass          4\nlgbti          2\ncriminal       1\ncalls          0\ndtype: int64\n\n\n\n\nNúmero de ataques por tipo de evento\n\n\nCode\ndf_attacks[\"event\"].value_counts()\n\n\nevent\nelecciones generales    46\n1er debate              45\n2do debate              32\ndebate balotaje         21\nelecciones balotaje     15\nName: count, dtype: int64\n\n\n\n\nPublicaciones por evento\n\n\nCode\njournalist_posts = df.loc[df[\"from_journalist\"].isin([USERNAME])]\njournalist_posts = journalist_posts.dropna(subset=[\"from_journalist\"])\n\neventos = [\n    \"1er debate\",\n    \"2do debate\",\n    \"elecciones generales\",\n    \"debate balotaje\",\n    \"elecciones balotaje\",\n]\ncolors = [\"green\", \"purple\", \"orange\", \"red\", \"blue\"]\neventos_count = {}\n\nfig = px.line()\n\nfor i, evento in enumerate(eventos):\n    evento_data = journalist_posts.loc[journalist_posts[\"event\"].isin([evento])]\n    evento_count = evento_data.groupby(\"dt_date\").size().reset_index(name=\"count\")\n    eventos_count[evento] = evento_count\n    fig.add_scatter(\n        x=evento_count[\"dt_date\"],\n        y=evento_count[\"count\"],\n        name=evento,\n        line=dict(color=colors[i]),\n        hovertemplate=\"posts: %{y}\",\n    )\n\nfig.update_layout(title=f\"Publicaciones de {USERNAME}\", width=1000)\nfig.update_xaxes(type=\"category\")\nfig.update_yaxes(range=[0, 100])\nfig.show()\n\n\n\n                                                \n\n\n\n\nHashtags\n\n\nCode\ndf_attacks[\"hashtags\"] = df_attacks[\"text\"].apply(\n    lambda x: (\n        np.nan\n        if pd.isnull(x) or not isinstance(x, str) or len(re.findall(r\"#\\w+\", x)) == 0\n        else re.findall(r\"#\\w+\", x)\n    )\n)\n\ndf_attacks[\"hashtags\"] = df_attacks[\"hashtags\"].apply(\n    lambda x: \", \".join(x) if isinstance(x, list) else x\n)\n\n# convert dataframe column to list\nhashtags = df_attacks[\"hashtags\"].unique()\n\n# remove nan items from list\nhashtags = [x for x in hashtags if not pd.isna(x)]\n\n# split items into a list based on a delimiter\nhashtags = [x.split(\",\") for x in hashtags]\n\n# flatten list of lists\nhashtags = [item for sublist in hashtags for item in sublist]\n\n# remove whitespaces\nhashtags = list(map(lambda x: x.replace(\" \", \"\"), hashtags))\n\n# count items on list\nhashtags_count = pd.Series(hashtags).value_counts()\n\nhashtags_count\n\n\n#Milei               1\n#VotoContraMassa     1\n#SeVanParaSiempre    1\nName: count, dtype: int64\n\n\n\n\nMenciones\n\n\nCode\ndf_attacks[\"mentions\"] = df_attacks[\"text\"].apply(\n    lambda x: (\n        np.nan\n        if pd.isnull(x) or not isinstance(x, str) or len(re.findall(r\"@(\\w+)\", x)) == 0\n        else re.findall(r\"@(\\w+)\", x)\n    )\n)\n\ndf_attacks[\"mentions\"] = df_attacks[\"mentions\"].apply(\n    lambda x: \", \".join(x) if isinstance(x, list) else x\n)\n\n# convert dataframe column to list\nmentions = df_attacks[\"mentions\"].unique()\n\n# remove nan items from list\nmentions = [x for x in mentions if not pd.isna(x)]\n\n# split items into a list based on a delimiter\nmentions = [x.split(\",\") for x in mentions]\n\n# flatten list of lists\nmentions = [item for sublist in mentions for item in sublist]\n\n# remove whitespaces\nmentions = list(map(lambda x: x.replace(\" \", \"\"), mentions))\n\n# count items on list\nmentions_count = pd.Series(mentions).value_counts()\n\nmentions_count\n\n\nvivicanosaok    2\nPatoBullrich    1\nJonatanViale    1\nJMilei          1\nName: count, dtype: int64\n\n\n\n\nTokens\n\n\nCode\n# load the spacy model for Spanish\nnlp = spacy.load(\"es_core_news_sm\")\n\n# load stop words for Spanish\nSTOP_WORDS = nlp.Defaults.stop_words\n\n\n# Function to filter stop words\ndef filter_stopwords(text):\n    # lower text\n    doc = nlp(text.lower())\n    # filter tokens\n    tokens = [\n        token.text\n        for token in doc\n        if not token.is_stop and token.text not in STOP_WORDS and token.is_alpha\n    ]\n    return \" \".join(tokens)\n\n\n# apply function to dataframe column\ndf_attacks[\"text_pre\"] = df_attacks[\"text\"].apply(filter_stopwords)\n\n# count items on column\ntoken_counts = df_attacks[\"text_pre\"].str.split(expand=True).stack().value_counts()[:20]\n\ntoken_counts\n\n\nmassa        24\nmilei        20\nvieja        18\nsos          15\nq            15\npautosa      11\nviviana      10\nmeada        10\ncanosa        8\nvos           8\njajaja        7\nvas           7\nviejo         7\nensobrada     6\ndas           6\ngordo         6\nanda          6\nborracha      5\ndebate        5\nasco          5\nName: count, dtype: int64"
  },
  {
    "objectID": "pages/8.@guadavazquez.html",
    "href": "pages/8.@guadavazquez.html",
    "title": "Análisis de tweets atacando a @guadavazquez",
    "section": "",
    "text": "Datos\n\n\nCode\ndf_attacks = attacks.loc[attacks[\"to_journalist\"].isin([USERNAME])]\nprint(f\"Número de ataques: {len(df_attacks)}\")\n\n\nNúmero de ataques: 216\n\n\n\n\nFrecuencia de ataques\nProporción de ataques = (Número de ataques / Número de menciones) * 100\n\n\nCode\njournalist_mentions = len(df.loc[df[\"to_journalist\"].isin([USERNAME])])\njournalist_attacks = len(df_attacks)\n\npercentage_attacks = (journalist_attacks / journalist_mentions) * 100\n\nproportion = (percentage_attacks / 100) * 10\nproportion_rounded = round(proportion, 1)\n\n\nprint(\n    f\"Aproximadamente {proportion_rounded} de cada 10 publicaciones que mencionan a {USERNAME} son ataques\"\n)\n\n\nAproximadamente 0.6 de cada 10 publicaciones que mencionan a @guadavazquez son ataques\n\n\n\n\nFrecuencia de los ataques en función del número de seguidores\nProporción de ataques por seguidor = Número de ataques / Número de seguidores\n\n\nCode\nproportion_followers = (len(df_attacks) / 272752) * 1000\nformatted_proportion = \"{:.2f}\".format(proportion_followers)\nprint(f\"Por cada 1K seguidores, hubo {formatted_proportion} ataques para {USERNAME}\")\n\n\nPor cada 1K seguidores, hubo 0.79 ataques para @guadavazquez\n\n\n\n\nRanking de tipos de ataques\n\n\nCode\nconditions = [\n    \"women\",\n    \"politics\",\n    \"appearance\",\n    \"racism\",\n    \"class\",\n    \"lgbti\",\n    \"criminal\",\n    \"calls\",\n]\nattacks_count = df_attacks[conditions].sum()\nattacks_count = attacks_count.sort_values(ascending=False)\nattacks_count\n\n\nwomen         91\npolitics      46\nappearance    23\nracism        13\ncalls          7\nclass          6\nlgbti          6\ncriminal       2\ndtype: int64\n\n\n\n\nNúmero de ataques por tipo de evento\n\n\nCode\ndf_attacks[\"event\"].value_counts()\n\n\nevent\n1er debate              63\nelecciones balotaje     53\nelecciones generales    42\n2do debate              38\ndebate balotaje         20\nName: count, dtype: int64\n\n\n\n\nPublicaciones por evento\n\n\nCode\njournalist_posts = df.loc[df[\"from_journalist\"].isin([USERNAME])]\njournalist_posts = journalist_posts.dropna(subset=[\"from_journalist\"])\n\neventos = [\n    \"1er debate\",\n    \"2do debate\",\n    \"elecciones generales\",\n    \"debate balotaje\",\n    \"elecciones balotaje\",\n]\ncolors = [\"green\", \"purple\", \"orange\", \"red\", \"blue\"]\neventos_count = {}\n\nfig = px.line()\n\nfor i, evento in enumerate(eventos):\n    evento_data = journalist_posts.loc[journalist_posts[\"event\"].isin([evento])]\n    evento_count = evento_data.groupby(\"dt_date\").size().reset_index(name=\"count\")\n    eventos_count[evento] = evento_count\n    fig.add_scatter(\n        x=evento_count[\"dt_date\"],\n        y=evento_count[\"count\"],\n        name=evento,\n        line=dict(color=colors[i]),\n        hovertemplate=\"posts: %{y}\",\n    )\n\nfig.update_layout(title=f\"Publicaciones de {USERNAME}\", width=1000)\nfig.update_xaxes(type=\"category\")\nfig.update_yaxes(range=[0, 100])\nfig.show()\n\n\n\n                                                \n\n\n\n\nHashtags\n\n\nCode\ndf_attacks[\"hashtags\"] = df_attacks[\"text\"].apply(\n    lambda x: (\n        np.nan\n        if pd.isnull(x) or not isinstance(x, str) or len(re.findall(r\"#\\w+\", x)) == 0\n        else re.findall(r\"#\\w+\", x)\n    )\n)\n\ndf_attacks[\"hashtags\"] = df_attacks[\"hashtags\"].apply(\n    lambda x: \", \".join(x) if isinstance(x, list) else x\n)\n\n# convert dataframe column to list\nhashtags = df_attacks[\"hashtags\"].unique()\n\n# remove nan items from list\nhashtags = [x for x in hashtags if not pd.isna(x)]\n\n# split items into a list based on a delimiter\nhashtags = [x.split(\",\") for x in hashtags]\n\n# flatten list of lists\nhashtags = [item for sublist in hashtags for item in sublist]\n\n# remove whitespaces\nhashtags = list(map(lambda x: x.replace(\" \", \"\"), hashtags))\n\n# count items on list\nhashtags_count = pd.Series(hashtags).value_counts()\n\nhashtags_count\n\n\n#Tenemos    1\nName: count, dtype: int64\n\n\n\n\nMenciones\n\n\nCode\ndf_attacks[\"mentions\"] = df_attacks[\"text\"].apply(\n    lambda x: (\n        np.nan\n        if pd.isnull(x) or not isinstance(x, str) or len(re.findall(r\"@(\\w+)\", x)) == 0\n        else re.findall(r\"@(\\w+)\", x)\n    )\n)\n\ndf_attacks[\"mentions\"] = df_attacks[\"mentions\"].apply(\n    lambda x: \", \".join(x) if isinstance(x, list) else x\n)\n\n# convert dataframe column to list\nmentions = df_attacks[\"mentions\"].unique()\n\n# remove nan items from list\nmentions = [x for x in mentions if not pd.isna(x)]\n\n# split items into a list based on a delimiter\nmentions = [x.split(\",\") for x in mentions]\n\n# flatten list of lists\nmentions = [item for sublist in mentions for item in sublist]\n\n# remove whitespaces\nmentions = list(map(lambda x: x.replace(\" \", \"\"), mentions))\n\n# count items on list\nmentions_count = pd.Series(mentions).value_counts()\n\nmentions_count\n\n\nvivicanosaok      1\nguadavazquez      1\nedufeiok          1\nEsmeraldaMitre    1\nName: count, dtype: int64\n\n\n\n\nTokens\n\n\nCode\n# load the spacy model for Spanish\nnlp = spacy.load(\"es_core_news_sm\")\n\n# load stop words for Spanish\nSTOP_WORDS = nlp.Defaults.stop_words\n\n\n# Function to filter stop words\ndef filter_stopwords(text):\n    # lower text\n    doc = nlp(text.lower())\n    # filter tokens\n    tokens = [\n        token.text\n        for token in doc\n        if not token.is_stop and token.text not in STOP_WORDS and token.is_alpha\n    ]\n    return \" \".join(tokens)\n\n\n# apply function to dataframe column\ndf_attacks[\"text_pre\"] = df_attacks[\"text\"].apply(filter_stopwords)\n\n# count items on column\ntoken_counts = df_attacks[\"text_pre\"].str.split(expand=True).stack().value_counts()[:20]\n\ntoken_counts\n\n\ngato         25\nguada        17\nq            14\njajaja       13\nvos          10\nzurdos        8\nsos           8\ncara          7\nmilei         7\nmedicado      6\nabrazo        6\nperonchos     6\nentiendo      5\ngatos         5\nre            5\nfamilia       5\nacá           5\nbregman       5\nzurda         5\nasco          5\nName: count, dtype: int64"
  },
  {
    "objectID": "pages/1.@diegobranca.html",
    "href": "pages/1.@diegobranca.html",
    "title": "Análisis de tweets atacando a @diegobranca",
    "section": "",
    "text": "Datos\n\n\nCode\ndf_attacks = attacks.loc[attacks[\"to_journalist\"].isin([USERNAME])]\nprint(f\"Número de ataques: {len(df_attacks)}\")\n\n\nNúmero de ataques: 712\n\n\n\n\nFrecuencia de ataques\nProporción de ataques = (Número de ataques / Número de menciones) * 100\n\n\nCode\njournalist_mentions = len(df.loc[df[\"to_journalist\"].isin([USERNAME])])\njournalist_attacks = len(df_attacks)\n\npercentage_attacks = (journalist_attacks / journalist_mentions) * 100\n\nproportion = (percentage_attacks / 100) * 10\nproportion_rounded = round(proportion, 1)\n\n\nprint(\n    f\"Aproximadamente {proportion_rounded} de cada 10 publicaciones que mencionan a {USERNAME} son ataques\"\n)\n\n\nAproximadamente 1.0 de cada 10 publicaciones que mencionan a @diegobranca son ataques\n\n\n\n\nFrecuencia de los ataques en función del número de seguidores\nProporción de ataques por seguidor = Número de ataques / Número de seguidores\n\n\nCode\nproportion_followers = (len(df_attacks) / 401737) * 1000\nformatted_proportion = \"{:.2f}\".format(proportion_followers)\nprint(f\"Por cada 1K seguidores, hubo {formatted_proportion} ataques para {USERNAME}\")\n\n\nPor cada 1K seguidores, hubo 1.77 ataques para @diegobranca\n\n\n\n\nRanking de tipos de ataques\n\n\nCode\nconditions = [\n    \"women\",\n    \"politics\",\n    \"appearance\",\n    \"racism\",\n    \"class\",\n    \"lgbti\",\n    \"criminal\",\n    \"calls\",\n]\nattacks_count = df_attacks[conditions].sum()\nattacks_count = attacks_count.sort_values(ascending=False)\nattacks_count\n\n\nappearance    309\npolitics      222\nwomen         110\nclass          44\nlgbti          44\nracism         25\ncriminal       24\ncalls           6\ndtype: int64\n\n\n\n\nNúmero de ataques por tipo de evento\n\n\nCode\ndf_attacks[\"event\"].value_counts()\n\n\nevent\nelecciones generales    265\nelecciones balotaje     229\n1er debate              102\ndebate balotaje          87\n2do debate               29\nName: count, dtype: int64\n\n\n\n\nPublicaciones por evento\n\n\nCode\njournalist_posts = df.loc[df[\"from_journalist\"].isin([USERNAME])]\njournalist_posts = journalist_posts.dropna(subset=[\"from_journalist\"])\n\neventos = [\n    \"1er debate\",\n    \"2do debate\",\n    \"elecciones generales\",\n    \"debate balotaje\",\n    \"elecciones balotaje\",\n]\ncolors = [\"green\", \"purple\", \"orange\", \"red\", \"blue\"]\neventos_count = {}\n\nfig = px.line()\n\nfor i, evento in enumerate(eventos):\n    evento_data = journalist_posts.loc[journalist_posts[\"event\"].isin([evento])]\n    evento_count = evento_data.groupby(\"dt_date\").size().reset_index(name=\"count\")\n    eventos_count[evento] = evento_count\n    fig.add_scatter(\n        x=evento_count[\"dt_date\"],\n        y=evento_count[\"count\"],\n        name=evento,\n        line=dict(color=colors[i]),\n        hovertemplate=\"posts: %{y}\",\n    )\n\nfig.update_layout(title=f\"Publicaciones de {USERNAME}\", width=1000)\nfig.update_xaxes(type=\"category\")\nfig.update_yaxes(range=[0, 100])\nfig.show()\n\n\n\n                                                \n\n\n\n\nHashtags\n\n\nCode\ndf_attacks[\"hashtags\"] = df_attacks[\"text\"].apply(\n    lambda x: (\n        np.nan\n        if pd.isnull(x) or not isinstance(x, str) or len(re.findall(r\"#\\w+\", x)) == 0\n        else re.findall(r\"#\\w+\", x)\n    )\n)\n\ndf_attacks[\"hashtags\"] = df_attacks[\"hashtags\"].apply(\n    lambda x: \", \".join(x) if isinstance(x, list) else x\n)\n\n# convert dataframe column to list\nhashtags = df_attacks[\"hashtags\"].unique()\n\n# remove nan items from list\nhashtags = [x for x in hashtags if not pd.isna(x)]\n\n# split items into a list based on a delimiter\nhashtags = [x.split(\",\") for x in hashtags]\n\n# flatten list of lists\nhashtags = [item for sublist in hashtags for item in sublist]\n\n# remove whitespaces\nhashtags = list(map(lambda x: x.replace(\" \", \"\"), hashtags))\n\n# count items on list\nhashtags_count = pd.Series(hashtags).value_counts()\n\nhashtags_count\n\n\n#ElPeorGobiernoDeLaHistoria        2\n#KirchnerismoNuncaMas              2\n#SeVannnnnn                        1\n#EsAhoraYParaSiempre               1\n#NoVasASerPresidente               1\n#NoAl5toGobiernoK                  1\n#elsi                              1\n#Sellamaperiodista                 1\n#Milita60depobrezaydolara1200      1\n#Noquierequeseterminelapauta       1\n#Nolepaganconladeellos             1\n#RataInmunda                       1\n#SeVanParaSiempre                  1\n#Repugnante                        1\n#PatriciaBullrichPresidente2023    1\n#Chaukukas                         1\n#pelotudo                          1\n#gobiernodevagosycorruptos         1\n#Afip                              1\n#tugo                              1\n#MileiPresidente                   1\nName: count, dtype: int64\n\n\n\n\nMenciones\n\n\nCode\ndf_attacks[\"mentions\"] = df_attacks[\"text\"].apply(\n    lambda x: (\n        np.nan\n        if pd.isnull(x) or not isinstance(x, str) or len(re.findall(r\"@(\\w+)\", x)) == 0\n        else re.findall(r\"@(\\w+)\", x)\n    )\n)\n\ndf_attacks[\"mentions\"] = df_attacks[\"mentions\"].apply(\n    lambda x: \", \".join(x) if isinstance(x, list) else x\n)\n\n# convert dataframe column to list\nmentions = df_attacks[\"mentions\"].unique()\n\n# remove nan items from list\nmentions = [x for x in mentions if not pd.isna(x)]\n\n# split items into a list based on a delimiter\nmentions = [x.split(\",\") for x in mentions]\n\n# flatten list of lists\nmentions = [item for sublist in mentions for item in sublist]\n\n# remove whitespaces\nmentions = list(map(lambda x: x.replace(\" \", \"\"), mentions))\n\n# count items on list\nmentions_count = pd.Series(mentions).value_counts()\n\nmentions_count\n\n\nSergioMassa       2\nSergioChouza      1\nminsaurralde      1\nT                 1\nPatoBullrich      1\ndiegobranca       1\nrd                1\ns                 1\nJMilei            1\nherlombardi       1\nMunicipioPilar    1\nName: count, dtype: int64\n\n\n\n\nTokens\n\n\nCode\n# load the spacy model for Spanish\nnlp = spacy.load(\"es_core_news_sm\")\n\n# load stop words for Spanish\nSTOP_WORDS = nlp.Defaults.stop_words\n\n\n# Function to filter stop words\ndef filter_stopwords(text):\n    # lower text\n    doc = nlp(text.lower())\n    # filter tokens\n    tokens = [\n        token.text\n        for token in doc\n        if not token.is_stop and token.text not in STOP_WORDS and token.is_alpha\n    ]\n    return \" \".join(tokens)\n\n\n# apply function to dataframe column\ndf_attacks[\"text_pre\"] = df_attacks[\"text\"].apply(filter_stopwords)\n\n# count items on column\ntoken_counts = df_attacks[\"text_pre\"].str.split(expand=True).stack().value_counts()[:20]\n\ntoken_counts\n\n\ngordo        172\nvos          144\nsos           98\nq             71\nvas           39\ngordito       35\nk             32\nmierda        32\nmassa         27\npelotudo      26\ngente         24\ntenes         24\nperonchos     23\nbranca        21\nculo          21\nlaburar       19\nensobrado     17\nanda          17\nenano         17\norto          17\nName: count, dtype: int64"
  },
  {
    "objectID": "pages/2.@Cris_noticias.html",
    "href": "pages/2.@Cris_noticias.html",
    "title": "Análisis de tweets atacando a @Cris_noticias",
    "section": "",
    "text": "Datos\n\n\nCode\ndf_attacks = attacks.loc[attacks[\"to_journalist\"].isin([USERNAME])]\nprint(f\"Número de ataques: {len(df_attacks)}\")\n\n\nNúmero de ataques: 427\n\n\n\n\nFrecuencia de ataques\nProporción de ataques = (Número de ataques / Número de menciones) * 100\n\n\nCode\njournalist_mentions = len(df.loc[df[\"to_journalist\"].isin([USERNAME])])\njournalist_attacks = len(df_attacks)\n\npercentage_attacks = (journalist_attacks / journalist_mentions) * 100\n\nproportion = (percentage_attacks / 100) * 10\nproportion_rounded = round(proportion, 1)\n\n\nprint(\n    f\"Aproximadamente {proportion_rounded} de cada 10 publicaciones que mencionan a {USERNAME} son ataques\"\n)\n\n\nAproximadamente 0.9 de cada 10 publicaciones que mencionan a @Cris_noticias son ataques\n\n\n\n\nFrecuencia de los ataques en función del número de seguidores\nProporción de ataques por seguidor = Número de ataques / Número de seguidores\n\n\nCode\nproportion_followers = (len(df_attacks) / 979948) * 1000\nformatted_proportion = \"{:.2f}\".format(proportion_followers)\nprint(f\"Por cada 1K seguidores, hubo {formatted_proportion} ataques para {USERNAME}\")\n\n\nPor cada 1K seguidores, hubo 0.44 ataques para @Cris_noticias\n\n\n\n\nRanking de tipos de ataques\n\n\nCode\nconditions = [\n    \"women\",\n    \"politics\",\n    \"appearance\",\n    \"racism\",\n    \"class\",\n    \"lgbti\",\n    \"criminal\",\n    \"calls\",\n]\nattacks_count = df_attacks[conditions].sum()\nattacks_count = attacks_count.sort_values(ascending=False)\nattacks_count\n\n\nwomen         218\npolitics      115\nappearance     80\nracism         21\nclass          13\nlgbti           3\ncalls           2\ncriminal        0\ndtype: int64\n\n\n\n\nNúmero de ataques por tipo de evento\n\n\nCode\ndf_attacks[\"event\"].value_counts()\n\n\nevent\nelecciones balotaje     214\nelecciones generales    115\ndebate balotaje          52\n2do debate               46\nName: count, dtype: int64\n\n\n\n\nPublicaciones por evento\n\n\nCode\njournalist_posts = df.loc[df[\"from_journalist\"].isin([USERNAME])]\njournalist_posts = journalist_posts.dropna(subset=[\"from_journalist\"])\n\neventos = [\n    \"1er debate\",\n    \"2do debate\",\n    \"elecciones generales\",\n    \"debate balotaje\",\n    \"elecciones balotaje\",\n]\ncolors = [\"green\", \"purple\", \"orange\", \"red\", \"blue\"]\neventos_count = {}\n\nfig = px.line()\n\nfor i, evento in enumerate(eventos):\n    evento_data = journalist_posts.loc[journalist_posts[\"event\"].isin([evento])]\n    evento_count = evento_data.groupby(\"dt_date\").size().reset_index(name=\"count\")\n    eventos_count[evento] = evento_count\n    fig.add_scatter(\n        x=evento_count[\"dt_date\"],\n        y=evento_count[\"count\"],\n        name=evento,\n        line=dict(color=colors[i]),\n        hovertemplate=\"posts: %{y}\",\n    )\n\nfig.update_layout(title=f\"Publicaciones de {USERNAME}\", width=1000)\nfig.update_xaxes(type=\"category\")\nfig.update_yaxes(range=[0, 100])\nfig.show()\n\n\n\n                                                \n\n\n\n\nHashtags\n\n\nCode\ndf_attacks[\"hashtags\"] = df_attacks[\"text\"].apply(\n    lambda x: (\n        np.nan\n        if pd.isnull(x) or not isinstance(x, str) or len(re.findall(r\"#\\w+\", x)) == 0\n        else re.findall(r\"#\\w+\", x)\n    )\n)\n\ndf_attacks[\"hashtags\"] = df_attacks[\"hashtags\"].apply(\n    lambda x: \", \".join(x) if isinstance(x, list) else x\n)\n\n# convert dataframe column to list\nhashtags = df_attacks[\"hashtags\"].unique()\n\n# remove nan items from list\nhashtags = [x for x in hashtags if not pd.isna(x)]\n\n# split items into a list based on a delimiter\nhashtags = [x.split(\",\") for x in hashtags]\n\n# flatten list of lists\nhashtags = [item for sublist in hashtags for item in sublist]\n\n# remove whitespaces\nhashtags = list(map(lambda x: x.replace(\" \", \"\"), hashtags))\n\n# count items on list\nhashtags_count = pd.Series(hashtags).value_counts()\n\nhashtags_count\n\n\n#nuncamas               1\n#PalestinaLibre         1\n#YoVotoAMassa           1\n#Milei                  1\n#NuncaMilei             1\n#MassaPresidente2023    1\n#NuncaMas               1\n#MileiNo                1\nName: count, dtype: int64\n\n\n\n\nMenciones\n\n\nCode\ndf_attacks[\"mentions\"] = df_attacks[\"text\"].apply(\n    lambda x: (\n        np.nan\n        if pd.isnull(x) or not isinstance(x, str) or len(re.findall(r\"@(\\w+)\", x)) == 0\n        else re.findall(r\"@(\\w+)\", x)\n    )\n)\n\ndf_attacks[\"mentions\"] = df_attacks[\"mentions\"].apply(\n    lambda x: \", \".join(x) if isinstance(x, list) else x\n)\n\n# convert dataframe column to list\nmentions = df_attacks[\"mentions\"].unique()\n\n# remove nan items from list\nmentions = [x for x in mentions if not pd.isna(x)]\n\n# split items into a list based on a delimiter\nmentions = [x.split(\",\") for x in mentions]\n\n# flatten list of lists\nmentions = [item for sublist in mentions for item in sublist]\n\n# remove whitespaces\nmentions = list(map(lambda x: x.replace(\" \", \"\"), mentions))\n\n# count items on list\nmentions_count = pd.Series(mentions).value_counts()\n\nmentions_count\n\n\nCris_noticias      2\nmyriambregman      1\nSergioMassa        1\nJMilei             1\nPatoBullrich       1\nluispetri          1\nJorgeTelerman      1\nhoraciorlarreta    1\nName: count, dtype: int64\n\n\n\n\nTokens\n\n\nCode\n# load the spacy model for Spanish\nnlp = spacy.load(\"es_core_news_sm\")\n\n# load stop words for Spanish\nSTOP_WORDS = nlp.Defaults.stop_words\n\n\n# Function to filter stop words\ndef filter_stopwords(text):\n    # lower text\n    doc = nlp(text.lower())\n    # filter tokens\n    tokens = [\n        token.text\n        for token in doc\n        if not token.is_stop and token.text not in STOP_WORDS and token.is_alpha\n    ]\n    return \" \".join(tokens)\n\n\n# apply function to dataframe column\ndf_attacks[\"text_pre\"] = df_attacks[\"text\"].apply(filter_stopwords)\n\n# count items on column\ntoken_counts = df_attacks[\"text_pre\"].str.split(expand=True).stack().value_counts()[:20]\n\ntoken_counts\n\n\nvos          43\nsos          38\ngorila       34\nq            32\nmarido       30\nnovio        25\nbotox        23\nvieja        19\nmierda       19\ncara         17\nmilei        16\ngente        16\nvas          15\nzurdos       15\ntenes        14\ndictadura    10\nx            10\norto         10\nanda          9\nmassa         9\nName: count, dtype: int64"
  },
  {
    "objectID": "pages/11.@luisnovaresio.html",
    "href": "pages/11.@luisnovaresio.html",
    "title": "Análisis de tweets atacando a @luisnovaresio",
    "section": "",
    "text": "Datos\n\n\nCode\ndf_attacks = attacks.loc[attacks[\"to_journalist\"].isin([USERNAME])]\nprint(f\"Número de ataques: {len(df_attacks)}\")\n\n\nNúmero de ataques: 154\n\n\n\n\nFrecuencia de ataques\nProporción de ataques = (Número de ataques / Número de menciones) * 100\n\n\nCode\njournalist_mentions = len(df.loc[df[\"to_journalist\"].isin([USERNAME])])\njournalist_attacks = len(df_attacks)\n\npercentage_attacks = (journalist_attacks / journalist_mentions) * 100\n\nproportion = (percentage_attacks / 100) * 10\nproportion_rounded = round(proportion, 1)\n\n\nprint(\n    f\"Aproximadamente {proportion_rounded} de cada 10 publicaciones que mencionan a {USERNAME} son ataques\"\n)\n\n\nAproximadamente 0.8 de cada 10 publicaciones que mencionan a @luisnovaresio son ataques\n\n\n\n\nFrecuencia de los ataques en función del número de seguidores\nProporción de ataques por seguidor = (Número de ataques) / (Número de seguidores)\n\n\nCode\nproportion_followers = (len(df_attacks) / 1019016) * 1000\nformatted_proportion = \"{:.2f}\".format(proportion_followers)\nprint(f\"Por cada 1K seguidores, hubo {formatted_proportion} ataques para {USERNAME}\")\n\n\nPor cada 1K seguidores, hubo 0.15 ataques para @luisnovaresio\n\n\n\n\nRanking de tipos de ataques\n\n\nCode\nconditions = [\n    \"women\",\n    \"politics\",\n    \"appearance\",\n    \"racism\",\n    \"class\",\n    \"lgbti\",\n    \"criminal\",\n    \"calls\",\n]\nattacks_count = df_attacks[conditions].sum()\nattacks_count = attacks_count.sort_values(ascending=False)\nattacks_count\n\n\npolitics      68\nwomen         31\nappearance    28\nracism        20\nlgbti         16\nclass          5\ncalls          4\ncriminal       1\ndtype: int64\n\n\n\n\nNúmero de ataques por tipo de evento\n\n\nCode\ndf_attacks[\"event\"].value_counts()\n\n\nevent\n1er debate              64\n2do debate              51\nelecciones balotaje     26\ndebate balotaje          9\nelecciones generales     4\nName: count, dtype: int64\n\n\n\n\nPublicaciones por evento\n\n\nCode\njournalist_posts = df.loc[df[\"from_journalist\"].isin([USERNAME])]\njournalist_posts = journalist_posts.dropna(subset=[\"from_journalist\"])\n\neventos = [\n    \"1er debate\",\n    \"2do debate\",\n    \"elecciones generales\",\n    \"debate balotaje\",\n    \"elecciones balotaje\",\n]\ncolors = [\"green\", \"purple\", \"orange\", \"red\", \"blue\"]\neventos_count = {}\n\nfig = px.line()\n\nfor i, evento in enumerate(eventos):\n    evento_data = journalist_posts.loc[journalist_posts[\"event\"].isin([evento])]\n    evento_count = evento_data.groupby(\"dt_date\").size().reset_index(name=\"count\")\n    eventos_count[evento] = evento_count\n    fig.add_scatter(\n        x=evento_count[\"dt_date\"],\n        y=evento_count[\"count\"],\n        name=evento,\n        line=dict(color=colors[i]),\n        hovertemplate=\"posts: %{y}\",\n    )\n\nfig.update_layout(title=f\"Publicaciones de {USERNAME}\", width=1000)\nfig.update_xaxes(type=\"category\")\nfig.update_yaxes(range=[0, 100])\nfig.show()\n\n\n\n                                                \n\n\n\n\nHashtags\n\n\nCode\ndf_attacks[\"hashtags\"] = df_attacks[\"text\"].apply(\n    lambda x: (\n        np.nan\n        if pd.isnull(x) or not isinstance(x, str) or len(re.findall(r\"#\\w+\", x)) == 0\n        else re.findall(r\"#\\w+\", x)\n    )\n)\n\ndf_attacks[\"hashtags\"] = df_attacks[\"hashtags\"].apply(\n    lambda x: \", \".join(x) if isinstance(x, list) else x\n)\n\n# convert dataframe column to list\nhashtags = df_attacks[\"hashtags\"].unique()\n\n# remove nan items from list\nhashtags = [x for x in hashtags if not pd.isna(x)]\n\n# split items into a list based on a delimiter\nhashtags = [x.split(\",\") for x in hashtags]\n\n# flatten list of lists\nhashtags = [item for sublist in hashtags for item in sublist]\n\n# remove whitespaces\nhashtags = list(map(lambda x: x.replace(\" \", \"\"), hashtags))\n\n# count items on list\nhashtags_count = pd.Series(hashtags).value_counts()\n\nhashtags_count\n\n\n#Pato2023    1\nName: count, dtype: int64\n\n\n\n\nMenciones\n\n\nCode\ndf_attacks[\"mentions\"] = df_attacks[\"text\"].apply(\n    lambda x: (\n        np.nan\n        if pd.isnull(x) or not isinstance(x, str) or len(re.findall(r\"@(\\w+)\", x)) == 0\n        else re.findall(r\"@(\\w+)\", x)\n    )\n)\n\ndf_attacks[\"mentions\"] = df_attacks[\"mentions\"].apply(\n    lambda x: \", \".join(x) if isinstance(x, list) else x\n)\n\n# convert dataframe column to list\nmentions = df_attacks[\"mentions\"].unique()\n\n# remove nan items from list\nmentions = [x for x in mentions if not pd.isna(x)]\n\n# split items into a list based on a delimiter\nmentions = [x.split(\",\") for x in mentions]\n\n# flatten list of lists\nmentions = [item for sublist in mentions for item in sublist]\n\n# remove whitespaces\nmentions = list(map(lambda x: x.replace(\" \", \"\"), mentions))\n\n# count items on list\nmentions_count = pd.Series(mentions).value_counts()\n\nmentions_count\n\n\nPatoBullrich     1\nJMilei           1\nluisnovaresio    1\nName: count, dtype: int64\n\n\n\n\nTokens\n\n\nCode\n# load the spacy model for Spanish\nnlp = spacy.load(\"es_core_news_sm\")\n\n# load stop words for Spanish\nSTOP_WORDS = nlp.Defaults.stop_words\n\n\n# Function to filter stop words\ndef filter_stopwords(text):\n    # lower text\n    doc = nlp(text.lower())\n    # filter tokens\n    tokens = [\n        token.text\n        for token in doc\n        if not token.is_stop and token.text not in STOP_WORDS and token.is_alpha\n    ]\n    return \" \".join(tokens)\n\n\n# apply function to dataframe column\ndf_attacks[\"text_pre\"] = df_attacks[\"text\"].apply(filter_stopwords)\n\n# count items on column\ntoken_counts = df_attacks[\"text_pre\"].str.split(expand=True).stack().value_counts()[:20]\n\ntoken_counts\n\n\nvos         27\nsos         26\nzurda       14\ngorila      14\nq           11\nasco         7\nestás        7\nluis         6\naños         5\nmierda       5\npaís         5\ntrolo        5\nzurdo        5\nisrael       5\nd            5\ntenes        5\nmilei        4\nzurdos       4\nderechos     4\nbregman      4\nName: count, dtype: int64"
  },
  {
    "objectID": "pages/6.@rialjorge.html",
    "href": "pages/6.@rialjorge.html",
    "title": "Análisis de tweets atacando a @rialjorge",
    "section": "",
    "text": "Datos\n\n\nCode\ndf_attacks = attacks.loc[attacks[\"to_journalist\"].isin([USERNAME])]\nprint(f\"Número de ataques: {len(df_attacks)}\")\n\n\nNúmero de ataques: 261\n\n\n\n\nFrecuencia de ataques\nProporción de ataques = (Número de ataques / Número de menciones) * 100\n\n\nCode\njournalist_mentions = len(df.loc[df[\"to_journalist\"].isin([USERNAME])])\njournalist_attacks = len(df_attacks)\n\npercentage_attacks = (journalist_attacks / journalist_mentions) * 100\n\nproportion = (percentage_attacks / 100) * 10\nproportion_rounded = round(proportion, 1)\n\n\nprint(\n    f\"Aproximadamente {proportion_rounded} de cada 10 publicaciones que mencionan a {USERNAME} son ataques\"\n)\n\n\nAproximadamente 0.8 de cada 10 publicaciones que mencionan a @rialjorge son ataques\n\n\n\n\nFrecuencia de los ataques en función del número de seguidores\nProporción de ataques por seguidor = Número de ataques / Número de seguidores\n\n\nCode\nproportion_followers = (len(df_attacks) / 3342769) * 1000\nformatted_proportion = \"{:.2f}\".format(proportion_followers)\nprint(f\"Por cada 1K seguidores, hubo {formatted_proportion} ataques para {USERNAME}\")\n\n\nPor cada 1K seguidores, hubo 0.08 ataques para @rialjorge\n\n\n\n\nRanking de tipos de ataques\n\n\nCode\nconditions = [\n    \"women\",\n    \"politics\",\n    \"appearance\",\n    \"racism\",\n    \"class\",\n    \"lgbti\",\n    \"criminal\",\n    \"calls\",\n]\nattacks_count = df_attacks[conditions].sum()\nattacks_count = attacks_count.sort_values(ascending=False)\nattacks_count\n\n\nappearance    95\nwomen         78\npolitics      68\nracism        14\nclass          9\nlgbti          5\ncriminal       2\ncalls          1\ndtype: int64\n\n\n\n\nNúmero de ataques por tipo de evento\n\n\nCode\ndf_attacks[\"event\"].value_counts()\n\n\nevent\nelecciones balotaje     108\nelecciones generales     70\ndebate balotaje          39\n1er debate               28\n2do debate               16\nName: count, dtype: int64\n\n\n\n\nPublicaciones por evento\n\n\nCode\njournalist_posts = df.loc[df[\"from_journalist\"].isin([USERNAME])]\njournalist_posts = journalist_posts.dropna(subset=[\"from_journalist\"])\n\neventos = [\n    \"1er debate\",\n    \"2do debate\",\n    \"elecciones generales\",\n    \"debate balotaje\",\n    \"elecciones balotaje\",\n]\ncolors = [\"green\", \"purple\", \"orange\", \"red\", \"blue\"]\neventos_count = {}\n\nfig = px.line()\n\nfor i, evento in enumerate(eventos):\n    evento_data = journalist_posts.loc[journalist_posts[\"event\"].isin([evento])]\n    evento_count = evento_data.groupby(\"dt_date\").size().reset_index(name=\"count\")\n    eventos_count[evento] = evento_count\n    fig.add_scatter(\n        x=evento_count[\"dt_date\"],\n        y=evento_count[\"count\"],\n        name=evento,\n        line=dict(color=colors[i]),\n        hovertemplate=\"posts: %{y}\",\n    )\n\nfig.update_layout(title=f\"Publicaciones de {USERNAME}\", width=1000)\nfig.update_xaxes(type=\"category\")\nfig.update_yaxes(range=[0, 100])\nfig.show()\n\n\n\n                                                \n\n\n\n\nHashtags\n\n\nCode\ndf_attacks[\"hashtags\"] = df_attacks[\"text\"].apply(\n    lambda x: (\n        np.nan\n        if pd.isnull(x) or not isinstance(x, str) or len(re.findall(r\"#\\w+\", x)) == 0\n        else re.findall(r\"#\\w+\", x)\n    )\n)\n\ndf_attacks[\"hashtags\"] = df_attacks[\"hashtags\"].apply(\n    lambda x: \", \".join(x) if isinstance(x, list) else x\n)\n\n# convert dataframe column to list\nhashtags = df_attacks[\"hashtags\"].unique()\n\n# remove nan items from list\nhashtags = [x for x in hashtags if not pd.isna(x)]\n\n# split items into a list based on a delimiter\nhashtags = [x.split(\",\") for x in hashtags]\n\n# flatten list of lists\nhashtags = [item for sublist in hashtags for item in sublist]\n\n# remove whitespaces\nhashtags = list(map(lambda x: x.replace(\" \", \"\"), hashtags))\n\n# count items on list\nhashtags_count = pd.Series(hashtags).value_counts()\n\nhashtags_count\n\n\n#BrancatelliPelotudo    1\n#MileiPresidente        1\nName: count, dtype: int64\n\n\n\n\nMenciones\n\n\nCode\ndf_attacks[\"mentions\"] = df_attacks[\"text\"].apply(\n    lambda x: (\n        np.nan\n        if pd.isnull(x) or not isinstance(x, str) or len(re.findall(r\"@(\\w+)\", x)) == 0\n        else re.findall(r\"@(\\w+)\", x)\n    )\n)\n\ndf_attacks[\"mentions\"] = df_attacks[\"mentions\"].apply(\n    lambda x: \", \".join(x) if isinstance(x, list) else x\n)\n\n# convert dataframe column to list\nmentions = df_attacks[\"mentions\"].unique()\n\n# remove nan items from list\nmentions = [x for x in mentions if not pd.isna(x)]\n\n# split items into a list based on a delimiter\nmentions = [x.split(\",\") for x in mentions]\n\n# flatten list of lists\nmentions = [item for sublist in mentions for item in sublist]\n\n# remove whitespaces\nmentions = list(map(lambda x: x.replace(\" \", \"\"), mentions))\n\n# count items on list\nmentions_count = pd.Series(mentions).value_counts()\n\nmentions_count\n\n\nrialjorge         2\nSergioMassa       1\nJMilei            1\ndo                1\nJonatanViale      1\nPRossiOficial     1\nLuisNovaresio1    1\nName: count, dtype: int64\n\n\n\n\nTokens\n\n\nCode\n# load the spacy model for Spanish\nnlp = spacy.load(\"es_core_news_sm\")\n\n# load stop words for Spanish\nSTOP_WORDS = nlp.Defaults.stop_words\n\n\n# Function to filter stop words\ndef filter_stopwords(text):\n    # lower text\n    doc = nlp(text.lower())\n    # filter tokens\n    tokens = [\n        token.text\n        for token in doc\n        if not token.is_stop and token.text not in STOP_WORDS and token.is_alpha\n    ]\n    return \" \".join(tokens)\n\n\n# apply function to dataframe column\ndf_attacks[\"text_pre\"] = df_attacks[\"text\"].apply(filter_stopwords)\n\n# count items on column\ntoken_counts = df_attacks[\"text_pre\"].str.split(expand=True).stack().value_counts()[:20]\n\ntoken_counts\n\n\nvos       39\nq         35\nviejo     34\nsos       27\nhuevo     14\nvas       13\ngente     11\nvieja     11\ntenes      9\nrial       9\nduro       9\nasco       9\nzurdos     9\ncara       9\nbajate     8\nhuevos     7\nsorete     7\nojalá      7\nbájate     7\npaís       7\nName: count, dtype: int64"
  },
  {
    "objectID": "pages/4.@Angelalerena.html",
    "href": "pages/4.@Angelalerena.html",
    "title": "Análisis de tweets atacando a @Angelalerena",
    "section": "",
    "text": "Datos\n\n\nCode\ndf_attacks = attacks.loc[attacks[\"to_journalist\"].isin([USERNAME])]\nprint(f\"Número de ataques: {len(df_attacks)}\")\n\n\nNúmero de ataques: 409\n\n\n\n\nFrecuencia de ataques\nProporción de ataques = (Número de ataques / Número de menciones) * 100\n\n\nCode\njournalist_mentions = len(df.loc[df[\"to_journalist\"].isin([USERNAME])])\njournalist_attacks = len(df_attacks)\n\npercentage_attacks = (journalist_attacks / journalist_mentions) * 100\n\nproportion = (percentage_attacks / 100) * 10\nproportion_rounded = round(proportion, 1)\n\n\nprint(\n    f\"Aproximadamente {proportion_rounded} de cada 10 publicaciones que mencionan a {USERNAME} son ataques\"\n)\n\n\nAproximadamente 1.1 de cada 10 publicaciones que mencionan a @Angelalerena son ataques\n\n\n\n\nFrecuencia de los ataques en función del número de seguidores\nProporción de ataques por seguidor = Número de ataques / Número de seguidores\n\n\nCode\nproportion_followers = (len(df_attacks) / 297964) * 1000\nformatted_proportion = \"{:.2f}\".format(proportion_followers)\nprint(f\"Por cada 1K seguidores, hubo {formatted_proportion} ataques para {USERNAME}\")\n\n\nPor cada 1K seguidores, hubo 1.37 ataques para @Angelalerena\n\n\n\n\nRanking de tipos de ataques\n\n\nCode\nconditions = [\n    \"women\",\n    \"politics\",\n    \"appearance\",\n    \"racism\",\n    \"class\",\n    \"lgbti\",\n    \"criminal\",\n    \"calls\",\n]\nattacks_count = df_attacks[conditions].sum()\nattacks_count = attacks_count.sort_values(ascending=False)\nattacks_count\n\n\nwomen         191\npolitics      132\nappearance     69\nclass          54\nracism         14\nlgbti           9\ncriminal        4\ncalls           2\ndtype: int64\n\n\n\n\nNúmero de ataques por tipo de evento\n\n\nCode\ndf_attacks[\"event\"].value_counts()\n\n\nevent\nelecciones balotaje     308\nelecciones generales     83\n1er debate               10\ndebate balotaje           8\nName: count, dtype: int64\n\n\n\n\nPublicaciones por evento\n\n\nCode\njournalist_posts = df.loc[df[\"from_journalist\"].isin([USERNAME])]\njournalist_posts = journalist_posts.dropna(subset=[\"from_journalist\"])\n\neventos = [\n    \"1er debate\",\n    \"2do debate\",\n    \"elecciones generales\",\n    \"debate balotaje\",\n    \"elecciones balotaje\",\n]\ncolors = [\"green\", \"purple\", \"orange\", \"red\", \"blue\"]\neventos_count = {}\n\nfig = px.line()\n\nfor i, evento in enumerate(eventos):\n    evento_data = journalist_posts.loc[journalist_posts[\"event\"].isin([evento])]\n    evento_count = evento_data.groupby(\"dt_date\").size().reset_index(name=\"count\")\n    eventos_count[evento] = evento_count\n    fig.add_scatter(\n        x=evento_count[\"dt_date\"],\n        y=evento_count[\"count\"],\n        name=evento,\n        line=dict(color=colors[i]),\n        hovertemplate=\"posts: %{y}\",\n    )\n\nfig.update_layout(title=f\"Publicaciones de {USERNAME}\", width=1000)\nfig.update_xaxes(type=\"category\")\nfig.update_yaxes(range=[0, 100])\nfig.show()\n\n\n\n                                                \n\n\n\n\nHashtags\n\n\nCode\ndf_attacks[\"hashtags\"] = df_attacks[\"text\"].apply(\n    lambda x: (\n        np.nan\n        if pd.isnull(x) or not isinstance(x, str) or len(re.findall(r\"#\\w+\", x)) == 0\n        else re.findall(r\"#\\w+\", x)\n    )\n)\n\ndf_attacks[\"hashtags\"] = df_attacks[\"hashtags\"].apply(\n    lambda x: \", \".join(x) if isinstance(x, list) else x\n)\n\n# convert dataframe column to list\nhashtags = df_attacks[\"hashtags\"].unique()\n\n# remove nan items from list\nhashtags = [x for x in hashtags if not pd.isna(x)]\n\n# split items into a list based on a delimiter\nhashtags = [x.split(\",\") for x in hashtags]\n\n# flatten list of lists\nhashtags = [item for sublist in hashtags for item in sublist]\n\n# remove whitespaces\nhashtags = list(map(lambda x: x.replace(\" \", \"\"), hashtags))\n\n# count items on list\nhashtags_count = pd.Series(hashtags).value_counts()\n\nhashtags_count\n\n\n#viv    1\nName: count, dtype: int64\n\n\n\n\nMenciones\n\n\nCode\ndf_attacks[\"mentions\"] = df_attacks[\"text\"].apply(\n    lambda x: (\n        np.nan\n        if pd.isnull(x) or not isinstance(x, str) or len(re.findall(r\"@(\\w+)\", x)) == 0\n        else re.findall(r\"@(\\w+)\", x)\n    )\n)\n\ndf_attacks[\"mentions\"] = df_attacks[\"mentions\"].apply(\n    lambda x: \", \".join(x) if isinstance(x, list) else x\n)\n\n# convert dataframe column to list\nmentions = df_attacks[\"mentions\"].unique()\n\n# remove nan items from list\nmentions = [x for x in mentions if not pd.isna(x)]\n\n# split items into a list based on a delimiter\nmentions = [x.split(\",\") for x in mentions]\n\n# flatten list of lists\nmentions = [item for sublist in mentions for item in sublist]\n\n# remove whitespaces\nmentions = list(map(lambda x: x.replace(\" \", \"\"), mentions))\n\n# count items on list\nmentions_count = pd.Series(mentions).value_counts()\n\nmentions_count\n\n\nAngelalerena       1\ndiegobranca        1\nMalenaGalmarini    1\nJMilei             1\nName: count, dtype: int64\n\n\n\n\nTokens\n\n\nCode\n# load the spacy model for Spanish\nnlp = spacy.load(\"es_core_news_sm\")\n\n# load stop words for Spanish\nSTOP_WORDS = nlp.Defaults.stop_words\n\n\n# Function to filter stop words\ndef filter_stopwords(text):\n    # lower text\n    doc = nlp(text.lower())\n    # filter tokens\n    tokens = [\n        token.text\n        for token in doc\n        if not token.is_stop and token.text not in STOP_WORDS and token.is_alpha\n    ]\n    return \" \".join(tokens)\n\n\n# apply function to dataframe column\ndf_attacks[\"text_pre\"] = df_attacks[\"text\"].apply(filter_stopwords)\n\n# count items on column\ntoken_counts = df_attacks[\"text_pre\"].str.split(expand=True).stack().value_counts()[:20]\n\ntoken_counts\n\n\nsos        42\nvos        42\nq          36\nlaburo     31\nmierda     28\nvas        27\namor       20\nlaburar    19\norto       19\nbuscar     18\ncurro      16\nanda       16\nzurda      15\nputa       15\naños       14\nkuka       14\ngente      14\nvoto       14\ncara       13\ntrabajo    12\nName: count, dtype: int64"
  },
  {
    "objectID": "pages/5.@edufeiok.html",
    "href": "pages/5.@edufeiok.html",
    "title": "Análisis de tweets atacando a @edufeiok",
    "section": "",
    "text": "Datos\n\n\nCode\ndf_attacks = attacks.loc[attacks[\"to_journalist\"].isin([USERNAME])]\nprint(f\"Número de ataques: {len(df_attacks)}\")\n\n\nNúmero de ataques: 399\n\n\n\n\nFrecuencia de ataques\nProporción de ataques = (Número de ataques / Número de menciones) * 100\n\n\nCode\njournalist_mentions = len(df.loc[df[\"to_journalist\"].isin([USERNAME])])\njournalist_attacks = len(df_attacks)\n\npercentage_attacks = (journalist_attacks / journalist_mentions) * 100\n\nproportion = (percentage_attacks / 100) * 10\nproportion_rounded = round(proportion, 1)\n\n\nprint(\n    f\"Aproximadamente {proportion_rounded} de cada 10 publicaciones que mencionan a {USERNAME} son ataques\"\n)\n\n\nAproximadamente 0.9 de cada 10 publicaciones que mencionan a @edufeiok son ataques\n\n\n\n\nFrecuencia de los ataques en función del número de seguidores\nProporción de ataques por seguidor = Número de ataques / Número de seguidores\n\n\nCode\nproportion_followers = (len(df_attacks) / 1172661) * 1000\nformatted_proportion = \"{:.2f}\".format(proportion_followers)\nprint(f\"Por cada 1K seguidores, hubo {formatted_proportion} ataques para {USERNAME}\")\n\n\nPor cada 1K seguidores, hubo 0.34 ataques para @edufeiok\n\n\n\n\nRanking de tipos de ataques\n\n\nCode\nconditions = [\n    \"women\",\n    \"politics\",\n    \"appearance\",\n    \"racism\",\n    \"class\",\n    \"lgbti\",\n    \"criminal\",\n    \"calls\",\n]\nattacks_count = df_attacks[conditions].sum()\nattacks_count = attacks_count.sort_values(ascending=False)\nattacks_count\n\n\nappearance    115\nwomen         112\npolitics      108\nracism         48\nlgbti           9\ncalls           9\ncriminal        8\nclass           7\ndtype: int64\n\n\n\n\nNúmero de ataques por tipo de evento\n\n\nCode\ndf_attacks[\"event\"].value_counts()\n\n\nevent\nelecciones balotaje     190\nelecciones generales    115\n2do debate               40\ndebate balotaje          35\n1er debate               19\nName: count, dtype: int64\n\n\n\n\nPublicaciones por evento\n\n\nCode\njournalist_posts = df.loc[df[\"from_journalist\"].isin([USERNAME])]\njournalist_posts = journalist_posts.dropna(subset=[\"from_journalist\"])\n\neventos = [\n    \"1er debate\",\n    \"2do debate\",\n    \"elecciones generales\",\n    \"debate balotaje\",\n    \"elecciones balotaje\",\n]\ncolors = [\"green\", \"purple\", \"orange\", \"red\", \"blue\"]\neventos_count = {}\n\nfig = px.line()\n\nfor i, evento in enumerate(eventos):\n    evento_data = journalist_posts.loc[journalist_posts[\"event\"].isin([evento])]\n    evento_count = evento_data.groupby(\"dt_date\").size().reset_index(name=\"count\")\n    eventos_count[evento] = evento_count\n    fig.add_scatter(\n        x=evento_count[\"dt_date\"],\n        y=evento_count[\"count\"],\n        name=evento,\n        line=dict(color=colors[i]),\n        hovertemplate=\"posts: %{y}\",\n    )\n\nfig.update_layout(title=f\"Publicaciones de {USERNAME}\", width=1000)\nfig.update_xaxes(type=\"category\")\nfig.update_yaxes(range=[0, 100])\nfig.show()\n\n\n\n                                                \n\n\n\n\nHashtags\n\n\nCode\ndf_attacks[\"hashtags\"] = df_attacks[\"text\"].apply(\n    lambda x: (\n        np.nan\n        if pd.isnull(x) or not isinstance(x, str) or len(re.findall(r\"#\\w+\", x)) == 0\n        else re.findall(r\"#\\w+\", x)\n    )\n)\n\ndf_attacks[\"hashtags\"] = df_attacks[\"hashtags\"].apply(\n    lambda x: \", \".join(x) if isinstance(x, list) else x\n)\n\n# convert dataframe column to list\nhashtags = df_attacks[\"hashtags\"].unique()\n\n# remove nan items from list\nhashtags = [x for x in hashtags if not pd.isna(x)]\n\n# split items into a list based on a delimiter\nhashtags = [x.split(\",\") for x in hashtags]\n\n# flatten list of lists\nhashtags = [item for sublist in hashtags for item in sublist]\n\n# remove whitespaces\nhashtags = list(map(lambda x: x.replace(\" \", \"\"), hashtags))\n\n# count items on list\nhashtags_count = pd.Series(hashtags).value_counts()\n\nhashtags_count\n\n\n#PatoBullrichPresidente2023    1\n#PatoPresidente                1\n#PatriciaBullrich              1\n#ZurdosHijosDePuta             1\n#Colombia                      1\n#NegroFuturo                   1\n#bipolaridad                   1\n#argentina                     1\n#Son30Mil                      1\n#fraude                        1\nName: count, dtype: int64\n\n\n\n\nMenciones\n\n\nCode\ndf_attacks[\"mentions\"] = df_attacks[\"text\"].apply(\n    lambda x: (\n        np.nan\n        if pd.isnull(x) or not isinstance(x, str) or len(re.findall(r\"@(\\w+)\", x)) == 0\n        else re.findall(r\"@(\\w+)\", x)\n    )\n)\n\ndf_attacks[\"mentions\"] = df_attacks[\"mentions\"].apply(\n    lambda x: \", \".join(x) if isinstance(x, list) else x\n)\n\n# convert dataframe column to list\nmentions = df_attacks[\"mentions\"].unique()\n\n# remove nan items from list\nmentions = [x for x in mentions if not pd.isna(x)]\n\n# split items into a list based on a delimiter\nmentions = [x.split(\",\") for x in mentions]\n\n# flatten list of lists\nmentions = [item for sublist in mentions for item in sublist]\n\n# remove whitespaces\nmentions = list(map(lambda x: x.replace(\" \", \"\"), mentions))\n\n# count items on list\nmentions_count = pd.Series(mentions).value_counts()\n\nmentions_count\n\n\nedufeiok           1\nmyriambregman      1\nr                  1\nJonatanViale       1\nCarlosMaslaton     1\nQuintelaRicardo    1\nursuvargues        1\nName: count, dtype: int64\n\n\n\n\nTokens\n\n\nCode\n# load the spacy model for Spanish\nnlp = spacy.load(\"es_core_news_sm\")\n\n# load stop words for Spanish\nSTOP_WORDS = nlp.Defaults.stop_words\n\n\n# Function to filter stop words\ndef filter_stopwords(text):\n    # lower text\n    doc = nlp(text.lower())\n    # filter tokens\n    tokens = [\n        token.text\n        for token in doc\n        if not token.is_stop and token.text not in STOP_WORDS and token.is_alpha\n    ]\n    return \" \".join(tokens)\n\n\n# apply function to dataframe column\ndf_attacks[\"text_pre\"] = df_attacks[\"text\"].apply(filter_stopwords)\n\n# count items on column\ntoken_counts = df_attacks[\"text_pre\"].str.split(expand=True).stack().value_counts()[:20]\n\ntoken_counts\n\n\nvos          48\nq            45\nenano        32\nsos          28\nedu          24\nasco         22\ntrompas      20\nligó         17\nfacho        14\npaís         14\nmierda       14\nviejo        14\nmassa        13\ndas          12\nmilei        12\nvas          11\naños         10\nargentina    10\nvotar         9\nmujer         9\nName: count, dtype: int64"
  },
  {
    "objectID": "pages/3.@JonatanViale.html",
    "href": "pages/3.@JonatanViale.html",
    "title": "Análisis de tweets atacando a @JonatanViale",
    "section": "",
    "text": "Datos\n\n\nCode\ndf_attacks = attacks.loc[attacks[\"to_journalist\"].isin([USERNAME])]\nprint(f\"Número de ataques: {len(df_attacks)}\")\n\n\nNúmero de ataques: 421\n\n\n\n\nFrecuencia de ataques\nProporción de ataques = (Número de ataques / Número de menciones) * 100\n\n\nCode\njournalist_mentions = len(df.loc[df[\"to_journalist\"].isin([USERNAME])])\njournalist_attacks = len(df_attacks)\n\npercentage_attacks = (journalist_attacks / journalist_mentions) * 100\n\nproportion = (percentage_attacks / 100) * 10\nproportion_rounded = round(proportion, 1)\n\n\nprint(\n    f\"Aproximadamente {proportion_rounded} de cada 10 publicaciones que mencionan a {USERNAME} son ataques\"\n)\n\n\nAproximadamente 1.6 de cada 10 publicaciones que mencionan a @JonatanViale son ataques\n\n\n\n\nFrecuencia de los ataques en función del número de seguidores\nProporción de ataques por seguidor = Número de ataques / Número de seguidores\n\n\nCode\nproportion_followers = (len(df_attacks) / 1096113) * 1000\nformatted_proportion = \"{:.2f}\".format(proportion_followers)\nprint(f\"Por cada 1K seguidores, hubo {formatted_proportion} ataques para {USERNAME}\")\n\n\nPor cada 1K seguidores, hubo 0.38 ataques para @JonatanViale\n\n\n\n\nRanking de tipos de ataques\n\n\nCode\nconditions = [\n    \"women\",\n    \"politics\",\n    \"appearance\",\n    \"racism\",\n    \"class\",\n    \"lgbti\",\n    \"criminal\",\n    \"calls\",\n]\nattacks_count = df_attacks[conditions].sum()\nattacks_count = attacks_count.sort_values(ascending=False)\nattacks_count\n\n\nappearance    258\nwomen          97\npolitics       41\nracism         22\nclass           7\ncriminal        7\nlgbti           6\ncalls           4\ndtype: int64\n\n\n\n\nNúmero de ataques por tipo de evento\n\n\nCode\ndf_attacks[\"event\"].value_counts()\n\n\nevent\ndebate balotaje        176\nelecciones balotaje    130\n1er debate              67\n2do debate              48\nName: count, dtype: int64\n\n\n\n\nPublicaciones por evento\n\n\nCode\njournalist_posts = df.loc[df[\"from_journalist\"].isin([USERNAME])]\njournalist_posts = journalist_posts.dropna(subset=[\"from_journalist\"])\n\neventos = [\n    \"1er debate\",\n    \"2do debate\",\n    \"elecciones generales\",\n    \"debate balotaje\",\n    \"elecciones balotaje\",\n]\ncolors = [\"green\", \"purple\", \"orange\", \"red\", \"blue\"]\neventos_count = {}\n\nfig = px.line()\n\nfor i, evento in enumerate(eventos):\n    evento_data = journalist_posts.loc[journalist_posts[\"event\"].isin([evento])]\n    evento_count = evento_data.groupby(\"dt_date\").size().reset_index(name=\"count\")\n    eventos_count[evento] = evento_count\n    fig.add_scatter(\n        x=evento_count[\"dt_date\"],\n        y=evento_count[\"count\"],\n        name=evento,\n        line=dict(color=colors[i]),\n        hovertemplate=\"posts: %{y}\",\n    )\n\nfig.update_layout(title=f\"Publicaciones de {USERNAME}\", width=1000)\nfig.update_xaxes(type=\"category\")\nfig.update_yaxes(range=[0, 100])\nfig.show()\n\n\n\n                                                \n\n\n\n\nHashtags\n\n\nCode\ndf_attacks[\"hashtags\"] = df_attacks[\"text\"].apply(\n    lambda x: (\n        np.nan\n        if pd.isnull(x) or not isinstance(x, str) or len(re.findall(r\"#\\w+\", x)) == 0\n        else re.findall(r\"#\\w+\", x)\n    )\n)\n\ndf_attacks[\"hashtags\"] = df_attacks[\"hashtags\"].apply(\n    lambda x: \", \".join(x) if isinstance(x, list) else x\n)\n\n# convert dataframe column to list\nhashtags = df_attacks[\"hashtags\"].unique()\n\n# remove nan items from list\nhashtags = [x for x in hashtags if not pd.isna(x)]\n\n# split items into a list based on a delimiter\nhashtags = [x.split(\",\") for x in hashtags]\n\n# flatten list of lists\nhashtags = [item for sublist in hashtags for item in sublist]\n\n# remove whitespaces\nhashtags = list(map(lambda x: x.replace(\" \", \"\"), hashtags))\n\n# count items on list\nhashtags_count = pd.Series(hashtags).value_counts()\n\nhashtags_count\n\n\n#SeVanParaSiempre         1\n#MemoriaAlVotar           1\n#EsCorrupciónOJusticia    1\n#MassaPresidente          1\n#LaLibertadTransa         1\n#MassaPresidente2023      1\n#NoAMilei                 1\n#GORDITOLECHOSO           1\n#Gorditolechoso           1\n#Periodistaensobrado      1\nName: count, dtype: int64\n\n\n\n\nMenciones\n\n\nCode\ndf_attacks[\"mentions\"] = df_attacks[\"text\"].apply(\n    lambda x: (\n        np.nan\n        if pd.isnull(x) or not isinstance(x, str) or len(re.findall(r\"@(\\w+)\", x)) == 0\n        else re.findall(r\"@(\\w+)\", x)\n    )\n)\n\ndf_attacks[\"mentions\"] = df_attacks[\"mentions\"].apply(\n    lambda x: \", \".join(x) if isinstance(x, list) else x\n)\n\n# convert dataframe column to list\nmentions = df_attacks[\"mentions\"].unique()\n\n# remove nan items from list\nmentions = [x for x in mentions if not pd.isna(x)]\n\n# split items into a list based on a delimiter\nmentions = [x.split(\",\") for x in mentions]\n\n# flatten list of lists\nmentions = [item for sublist in mentions for item in sublist]\n\n# remove whitespaces\nmentions = list(map(lambda x: x.replace(\" \", \"\"), mentions))\n\n# count items on list\nmentions_count = pd.Series(mentions).value_counts()\n\nmentions_count\n\n\nvivicanosaok       1\nPatoBullrich       1\nJonatanViale       1\nMalenaGalmarini    1\nedufeiok           1\nKicillofok         1\nminsaurralde       1\nLANACION           1\nJMilei             1\nc0o0ni             1\nPontifex_es        1\nName: count, dtype: int64\n\n\n\n\nTokens\n\n\nCode\n# load the spacy model for Spanish\nnlp = spacy.load(\"es_core_news_sm\")\n\n# load stop words for Spanish\nSTOP_WORDS = nlp.Defaults.stop_words\n\n\n# Function to filter stop words\ndef filter_stopwords(text):\n    # lower text\n    doc = nlp(text.lower())\n    # filter tokens\n    tokens = [\n        token.text\n        for token in doc\n        if not token.is_stop and token.text not in STOP_WORDS and token.is_alpha\n    ]\n    return \" \".join(tokens)\n\n\n# apply function to dataframe column\ndf_attacks[\"text_pre\"] = df_attacks[\"text\"].apply(filter_stopwords)\n\n# count items on column\ntoken_counts = df_attacks[\"text_pre\"].str.split(expand=True).stack().value_counts()[:20]\n\ntoken_counts\n\n\nlechoso       136\ngordito        90\ngordo          68\nvos            53\nsos            46\nvas            45\nq              30\nleche          22\nrodilleras     16\npija           15\nensobrado      15\nmilei          15\npelotudo       15\nviejo          14\nmacri          12\ncara           12\nchupa          11\nmierda         10\nputa            9\ntomar           9\nName: count, dtype: int64"
  },
  {
    "objectID": "pages/0.analisis_general.html",
    "href": "pages/0.analisis_general.html",
    "title": "Análisis de tweets durante las elecciones generales 2023 en Argentina",
    "section": "",
    "text": "Datos\n\n\nCode\n# Print the number of tweets analyzed\nprint(f\"Número de tweets analizados: {len(df)}\")\n\n\nNúmero de tweets analizados: 79887\n\n\n\n\nEventos monitoreados\nCantidad de tweets para cada uno de los eventos monitoreados:\n\n\nCode\n# Get the value counts of the \"event\" column in the dataframe \"df\"\ndf[\"event\"].value_counts()\n\n\nevent\nelecciones balotaje     27448\nelecciones generales    19970\n1er debate              12588\ndebate balotaje         12440\n2do debate               7441\nName: count, dtype: int64\n\n\n\n\nFechas de eventos\nPeriodo cubierto para cada evento\n\n\nCode\n# Define a function to get the date range of a given event\ndef get_date_range(df, event):\n    event_data = df.loc[df[\"event\"] == event]\n    return event_data[\"dt_date\"].min(), event_data[\"dt_date\"].max()\n\n\n# Get the date ranges for each event\ndebate1_min, debate1_max = get_date_range(df, \"1er debate\")\ndebate2_min, debate2_max = get_date_range(df, \"2do debate\")\nelecciones_gen_min, elecciones_gen_max = get_date_range(df, \"elecciones generales\")\ndebate_balotaje_min, debate_balotaje_max = get_date_range(df, \"debate balotaje\")\nelecciones_balotaje_min, elecciones_balotaje_max = get_date_range(\n    df, \"elecciones balotaje\"\n)\n\n# Print the date ranges\nprint(f\"El primer debate contempla tweets desde {debate1_min} hasta {debate1_max}\")\nprint(f\"El segundo debate contempla tweets desde {debate2_min} hasta {debate2_max}\")\nprint(\n    f\"Elecciones generales contempla tweets desde {elecciones_gen_min} hasta {elecciones_gen_max}\"\n)\nprint(\n    f\"El debate del balotaje contempla tweets desde {debate_balotaje_min} hasta {debate_balotaje_max}\"\n)\nprint(\n    f\"Elecciones del balotaje contempla tweets desde {elecciones_balotaje_min} hasta {elecciones_balotaje_max}\"\n)\n\n\nEl primer debate contempla tweets desde 2023-09-30 hasta 2023-10-02\nEl segundo debate contempla tweets desde 2023-10-07 hasta 2023-10-09\nElecciones generales contempla tweets desde 2023-10-19 hasta 2023-10-23\nEl debate del balotaje contempla tweets desde 2023-11-11 hasta 2023-11-13\nElecciones del balotaje contempla tweets desde 2023-11-16 hasta 2023-11-20\n\n\n\n\nAtaques identificados\n\nNOTA: Un tweet puede tener diversas etiquetas\n\n\n\nCode\n# Subset of dataframe `df` containing only rows with non-null values in \"label\" and \"to_journalist\" columns\nattacks = df.dropna(subset=[\"label\", \"to_journalist\"])\n\n# Print the number of rows in `attacks` dataframe\nprint(\n    f\"En los datos se identificaron {len(attacks)} publicaciones etiquetadas como ataques.\"\n)\n\n\nEn los datos se identificaron 4319 publicaciones etiquetadas como ataques.\n\n\n\n\nRanking the periodistas más atacados\n\n\nCode\nattacks[\"to_journalist\"].value_counts()\n\n\nto_journalist\n@diegobranca       712\n@Cris_noticias     427\n@JonatanViale      421\n@Angelalerena      409\n@edufeiok          399\n@rialjorge         261\n@odonnellmaria     258\n@guadavazquez      216\n@robdnavarro       209\n@vivicanosaok      159\n@luisnovaresio     154\n@cyngarciaradio    152\n@rominamanguel      95\n@majulluis          85\n@mjolivan           72\n@Gatosylvestre      66\n@nbg__              59\n@NANCYPAZOS         58\n@ischargro          27\n@anaecorrea         21\n@ertenembaum        11\n@hindelita          10\n@juliamengo          7\n@aleberco            7\n@alfleuco            4\n@maclorena           4\n@Marcelitaojeda      3\n@MercedesFunes       3\n@Sietecase           3\n@negropolisok        2\n@wwnicolas           2\n@soyingridbeck       2\n@monigps             1\nName: count, dtype: int64\n\n\n\n\nRanking de periodistas atacados por género\n\nNOTA: Clasificación binaria\n\n\n\nCode\nattacks[\"journalist_genre\"].value_counts()\n\n\njournalist_genre\nH    2361\nM    1958\nName: count, dtype: int64\n\n\n\n\nHombres periodistas más atacados\n\n\nCode\nattacks_men = attacks.loc[attacks[\"journalist_genre\"].isin([\"H\"])]\nattacks_men[\"to_journalist\"].value_counts()\n\n\nto_journalist\n@diegobranca      712\n@JonatanViale     421\n@edufeiok         399\n@rialjorge        261\n@robdnavarro      209\n@luisnovaresio    154\n@majulluis         85\n@Gatosylvestre     66\n@ischargro         27\n@ertenembaum       11\n@aleberco           7\n@alfleuco           4\n@Sietecase          3\n@wwnicolas          2\nName: count, dtype: int64\n\n\n\n\nMujeres periodistas más atacadas\n\n\nCode\nattacks_women = attacks.loc[attacks[\"journalist_genre\"].isin([\"M\"])]\nattacks_women[\"to_journalist\"].value_counts()\n\n\nto_journalist\n@Cris_noticias     427\n@Angelalerena      409\n@odonnellmaria     258\n@guadavazquez      216\n@vivicanosaok      159\n@cyngarciaradio    152\n@rominamanguel      95\n@mjolivan           72\n@nbg__              59\n@NANCYPAZOS         58\n@anaecorrea         21\n@hindelita          10\n@juliamengo          7\n@maclorena           4\n@MercedesFunes       3\n@Marcelitaojeda      3\n@negropolisok        2\n@soyingridbeck       2\n@monigps             1\nName: count, dtype: int64\n\n\n\n\nRanking the tipos de ataques para hombres\n\n\nCode\nconditions = [\n    \"women\",\n    \"politics\",\n    \"appearance\",\n    \"racism\",\n    \"class\",\n    \"lgbti\",\n    \"criminal\",\n    \"calls\",\n]\nattacks_men_count = attacks_men[conditions].sum()\nattacks_men_count\n\n\nwomen         524\npolitics      658\nappearance    910\nracism        151\nclass          92\nlgbti          92\ncriminal       49\ncalls          33\ndtype: int64\n\n\n\n\nRanking the tipos de ataques para mujeres\n\n\nCode\nconditions = [\n    \"women\",\n    \"politics\",\n    \"appearance\",\n    \"racism\",\n    \"class\",\n    \"lgbti\",\n    \"criminal\",\n    \"calls\",\n]\nattacks_women_count = attacks_women[conditions].sum()\nattacks_women_count\n\n\nwomen         888\npolitics      569\nappearance    377\nracism        117\nclass         104\nlgbti          29\ncriminal       14\ncalls          19\ndtype: int64\n\n\n\n\nNúmero de ataques por tipo de evento\n\n\nCode\nattacks[\"event\"].value_counts()\n\n\nevent\nelecciones balotaje     1584\nelecciones generales     987\n1er debate               698\ndebate balotaje          668\n2do debate               382\nName: count, dtype: int64\n\n\n\n\nProporción de ataques por tipo de evento\nPorcentaje de ataques por tweets recolectados para cada evento\n\n\nCode\ncount_1er_debate = df[df[\"event\"] == \"1er debate\"].shape[0]\ncount_2do_debate = df[df[\"event\"] == \"2do debate\"].shape[0]\ncount_elecciones_gen = df[df[\"event\"] == \"elecciones generales\"].shape[0]\ncount_debate_balotaje = df[df[\"event\"] == \"debate balotaje\"].shape[0]\ncount_elecciones_balotaje = df[df[\"event\"] == \"elecciones balotaje\"].shape[0]\n\n\ncount_attacks_1er_debate = attacks[attacks[\"event\"] == \"1er debate\"].shape[0]\ncount_attacks_2do_debate = attacks[attacks[\"event\"] == \"2do debate\"].shape[0]\ncount_attacks_elecciones_gen = attacks[\n    attacks[\"event\"] == \"elecciones generales\"\n].shape[0]\ncount_attacks_debate_balotaje = attacks[attacks[\"event\"] == \"debate balotaje\"].shape[0]\ncount_attacks_elecciones_balotaje = attacks[\n    attacks[\"event\"] == \"elecciones balotaje\"\n].shape[0]\n\nprint(\n    \"El\",\n    round((count_attacks_1er_debate / count_1er_debate) * 100),\n    \"% del total de los tweets del 1er debate fueron ataques\",\n)\nprint(\n    \"El\",\n    round((count_attacks_2do_debate / count_2do_debate) * 100),\n    \"% del total de los tweets del 2do debate fueron ataques\",\n)\nprint(\n    \"El\",\n    round((count_attacks_elecciones_gen / count_elecciones_gen) * 100),\n    \"% del total de los tweets de las elecciones generales fueron ataques\",\n)\nprint(\n    \"El\",\n    round((count_attacks_debate_balotaje / count_debate_balotaje) * 100),\n    \"% del total de los tweets del debate del balotaje fueron ataques\",\n)\nprint(\n    \"El\",\n    round((count_attacks_elecciones_balotaje / count_elecciones_balotaje) * 100),\n    \"% del total de los tweets de las elecciones del balotaje fueron ataques\",\n)\n\n\nEl 6 % del total de los tweets del 1er debate fueron ataques\nEl 5 % del total de los tweets del 2do debate fueron ataques\nEl 5 % del total de los tweets de las elecciones generales fueron ataques\nEl 5 % del total de los tweets del debate del balotaje fueron ataques\nEl 6 % del total de los tweets de las elecciones del balotaje fueron ataques\n\n\n\n\nFrecuencia de los ataques en función del número de menciones\n\n\nCode\nmj_proportion_mentions = (1 + 1.6 + 0.9 + 0.8 + 0.6 + 0.8) / 6\nformatted_mj = \"{:.2f}\".format(mj_proportion_mentions)\n\nwj_proportion_mentions = (0.9 + 1.1 + 0.8 + 0.6 + 0.6) / 5\nformatted_wj = \"{:.2f}\".format(wj_proportion_mentions)\n\n\n\n\nCode\nprint(\n    f\"Por cada 10 menciones, los periodistas hombres recibieron {formatted_mj} ataques\"\n)\nprint(\n    f\"Por cada 10 menciones, las periodistas mujeres recibieron {formatted_wj} ataques\"\n)\n\n\nPor cada 10 menciones, los periodistas hombres recibieron 0.95 ataques\nPor cada 10 menciones, las periodistas mujeres recibieron 0.80 ataques\n\n\n\n\nFrecuencia de los ataques en función del número de seguidores\n\n\nCode\nmj_proportion_followers = (1.77 + 0.38 + 0.34 + 0.08 + 0.38 + 0.15) / 6\nformatted_mj = \"{:.2f}\".format(mj_proportion_followers)\n\nwj_proportion_followers = (0.44 + 1.37 + 0.67 + 0.79 + 0.21) / 5\nformatted_wj = \"{:.2f}\".format(wj_proportion_followers)\n\n\n\n\nCode\nprint(\n    f\"Por cada 1K seguidores, los periodistas hombres recibieron {formatted_mj} ataques\"\n)\nprint(\n    f\"Por cada 1K seguidores, las periodistas mujeres recibieron {formatted_wj} ataques\"\n)\n\n\nPor cada 1K seguidores, los periodistas hombres recibieron 0.52 ataques\nPor cada 1K seguidores, las periodistas mujeres recibieron 0.70 ataques\n\n\n\n\nActividad de los periodistas en Twitter por género\n\n\nCode\njournalist_posts = df.dropna(subset=[\"from_journalist\"])\nmen_journalist_posts = journalist_posts.loc[\n    journalist_posts[\"journalist_genre\"].isin([\"M\"])\n]\nwomen_journalist_posts = journalist_posts.loc[\n    journalist_posts[\"journalist_genre\"].isin([\"H\"])\n]\n\nprint(\n    f\"\"\"Tweets publicados por periodistas hombres: {len(men_journalist_posts)}\\nTweets publicados por periodistas mujeres: {len(women_journalist_posts)}\"\"\"\n)\n\n\nTweets publicados por periodistas hombres: 1223\nTweets publicados por periodistas mujeres: 489\n\n\n\n\nRanking de periodistas más activos\n\n\nCode\njournalist_activity = df[\"from_journalist\"].value_counts()\njournalist_activity\n\n\nfrom_journalist\n@anaecorrea         206\n@guadavazquez       127\n@rialjorge           99\n@diegobranca         86\n@SilvinaMolina       83\n@rominamanguel       80\n@Angelalerena        80\n@nbg__               71\n@NANCYPAZOS          70\n@hindelita           66\n@Cris_noticias       64\n@Marcelitaojeda      53\n@odonnellmaria       49\n@Gatosylvestre       49\n@soyingridbeck       48\n@luisnovaresio       47\n@edufeiok            46\n@monigps             44\n@mjolivan            39\n@majulluis           37\n@robdnavarro         31\n@vivicanosaok        20\n@cyngarciaradio      20\n@MercedesFunes       20\n@JonatanViale        20\n@maclorena           18\n@ertenembaum         16\n@aleberco            15\n@SANTIAGODELMORO     13\n@ischargro           13\n@juliamengo          13\n@mafito11            12\n@FlorHalfon          11\n@SoleVallejos        11\n@Sietecase           11\n@silviafbarrio        9\n@alfleuco             3\n@gabycociffi          3\n@negropolisok         2\n@wwnicolas            2\n@gabipellegrini3      1\n@GabrielaWeller       1\n@lucianageuna         1\n@barilirodolfo        1\n@deboraplager         1\nName: count, dtype: int64\n\n\n\n\nPublicaciones de periodistas por evento\n\n\nCode\nmen_debate1 = men_journalist_posts.loc[\n    men_journalist_posts[\"event\"].isin([\"1er debate\"])\n]\nmen_count = men_debate1.groupby(\"dt_date\").size().reset_index(name=\"count\")\n\nwomen_debate1 = women_journalist_posts.loc[\n    women_journalist_posts[\"event\"].isin([\"1er debate\"])\n]\nwomen_count = women_debate1.groupby(\"dt_date\").size().reset_index(name=\"count\")\n\nfig = px.line()\nfig.add_scatter(\n    x=men_count[\"dt_date\"],\n    y=men_count[\"count\"],\n    name=\"Hombres\",\n    line=dict(color=\"orange\"),\n    hovertemplate=\"posts: %{y}\",\n)\nfig.add_scatter(\n    x=women_count[\"dt_date\"],\n    y=women_count[\"count\"],\n    name=\"Mujeres\",\n    line=dict(color=\"purple\"),\n    hovertemplate=\"posts: %{y}\",\n)\nfig.update_layout(title=\"Publicaciones de periodistas durante el 1er debate\", width=600)\nfig.update_xaxes(type=\"category\")\nfig.show()\n\n\n\n                                                \n\n\n\n\nCode\ndef count_posts_by_gender(df, event):\n    \"\"\"\n    This function takes in a DataFrame of journalist posts and an event string,\n    and returns a new DataFrame with the count of posts by date for that event\n    and gender.\n    \"\"\"\n    debate_posts = df[df[\"event\"].eq(event)]  # filter posts by event\n    return (\n        debate_posts.groupby(\"dt_date\").size().reset_index(name=\"count\")\n    )  # group by date and count\n\n\n# get posts for the 2nd debate for male and female journalists\nmen_debate2 = count_posts_by_gender(men_journalist_posts, \"2do debate\")\nwomen_debate2 = count_posts_by_gender(women_journalist_posts, \"2do debate\")\n\n# create a line plot of post counts by date for male and female journalists\nfig = px.line()\nfig.add_scatter(\n    x=men_debate2[\"dt_date\"],\n    y=men_debate2[\"count\"],\n    name=\"Hombres\",\n    line=dict(color=\"orange\"),\n    hovertemplate=\"posts: %{y}\",\n)\nfig.add_scatter(\n    x=women_debate2[\"dt_date\"],\n    y=women_debate2[\"count\"],\n    name=\"Mujeres\",\n    line=dict(color=\"purple\"),\n    hovertemplate=\"posts: %{y}\",\n)\nfig.update_layout(title=\"Publicaciones de periodistas durante el 2do debate\", width=600)\nfig.update_xaxes(type=\"category\")\nfig.show()\n\n\n\n                                                \n\n\n\n\nCode\nmen_elecciones_gen = men_journalist_posts.loc[\n    men_journalist_posts[\"event\"].isin([\"elecciones generales\"])\n]\nmen_count = men_elecciones_gen.groupby(\"dt_date\").size().reset_index(name=\"count\")\n\nwomen_elecciones_gen = women_journalist_posts.loc[\n    women_journalist_posts[\"event\"].isin([\"elecciones generales\"])\n]\nwomen_count = women_elecciones_gen.groupby(\"dt_date\").size().reset_index(name=\"count\")\n\nfig = px.line()\nfig.add_scatter(\n    x=men_count[\"dt_date\"],\n    y=men_count[\"count\"],\n    name=\"Hombres\",\n    line=dict(color=\"orange\"),\n    hovertemplate=\"posts: %{y}\",\n)\nfig.add_scatter(\n    x=women_count[\"dt_date\"],\n    y=women_count[\"count\"],\n    name=\"Mujeres\",\n    line=dict(color=\"purple\"),\n    hovertemplate=\"posts: %{y}\",\n)\nfig.update_layout(\n    title=\"Publicaciones de periodistas durante las elecciones generales\", width=600\n)\nfig.update_xaxes(type=\"category\")\nfig.show()\n\n\n\n                                                \n\n\n\n\nCode\nmen_debate_balotaje = men_journalist_posts.loc[\n    men_journalist_posts[\"event\"].isin([\"debate balotaje\"])\n]\nmen_count = men_debate_balotaje.groupby(\"dt_date\").size().reset_index(name=\"count\")\n\nwomen_debate_balotaje = women_journalist_posts.loc[\n    women_journalist_posts[\"event\"].isin([\"debate balotaje\"])\n]\nwomen_count = women_debate_balotaje.groupby(\"dt_date\").size().reset_index(name=\"count\")\n\nfig = px.line()\nfig.add_scatter(\n    x=men_count[\"dt_date\"],\n    y=men_count[\"count\"],\n    name=\"Hombres\",\n    line=dict(color=\"orange\"),\n    hovertemplate=\"posts: %{y}\",\n)\nfig.add_scatter(\n    x=women_count[\"dt_date\"],\n    y=women_count[\"count\"],\n    name=\"Mujeres\",\n    line=dict(color=\"purple\"),\n    hovertemplate=\"posts: %{y}\",\n)\nfig.update_layout(\n    title=\"Publicaciones de periodistas durante el debate del balotaje\", width=600\n)\nfig.update_xaxes(type=\"category\")\nfig.show()\n\n\n\n                                                \n\n\n\n\nCode\nmen_elecciones_balotaje = men_journalist_posts.loc[\n    men_journalist_posts[\"event\"].isin([\"elecciones balotaje\"])\n]\nmen_count = men_elecciones_balotaje.groupby(\"dt_date\").size().reset_index(name=\"count\")\n\nwomen_elecciones_balotaje = women_journalist_posts.loc[\n    women_journalist_posts[\"event\"].isin([\"elecciones balotaje\"])\n]\nwomen_count = (\n    women_elecciones_balotaje.groupby(\"dt_date\").size().reset_index(name=\"count\")\n)\n\nfig = px.line()\nfig.add_scatter(\n    x=men_count[\"dt_date\"],\n    y=men_count[\"count\"],\n    name=\"Hombres\",\n    line=dict(color=\"orange\"),\n    hovertemplate=\"posts: %{y}\",\n)\nfig.add_scatter(\n    x=women_count[\"dt_date\"],\n    y=women_count[\"count\"],\n    name=\"Mujeres\",\n    line=dict(color=\"purple\"),\n    hovertemplate=\"posts: %{y}\",\n)\nfig.update_layout(\n    title=\"Publicaciones de periodistas durante las elecciones del balotaje\", width=600\n)\nfig.update_xaxes(type=\"category\")\nfig.show()\n\n\n\n                                                \n\n\n\n\nRanking de eventos con más ataques para hombres\n\n\nCode\nattacks_men[\"event\"].value_counts()\n\n\nevent\nelecciones balotaje     806\nelecciones generales    517\ndebate balotaje         435\n1er debate              381\n2do debate              222\nName: count, dtype: int64\n\n\n\n\nRanking de eventos con más ataques para mujeres\n\n\nCode\nattacks_women[\"event\"].value_counts()\n\n\nevent\nelecciones balotaje     778\nelecciones generales    470\n1er debate              317\ndebate balotaje         233\n2do debate              160\nName: count, dtype: int64\n\n\n\n\nHashtags\n20 hashtags más utilizados en los ataques:\n\n\nCode\nattacks[\"hashtags\"] = attacks[\"text\"].apply(\n    lambda x: (\n        np.nan\n        if pd.isnull(x) or not isinstance(x, str) or len(re.findall(r\"#\\w+\", x)) == 0\n        else re.findall(r\"#\\w+\", x)\n    )\n)\n\nattacks[\"hashtags\"] = attacks[\"hashtags\"].apply(\n    lambda x: \", \".join(x) if isinstance(x, list) else x\n)\n\n# convert dataframe column to list\nhashtags = attacks[\"hashtags\"].unique()\n\n# remove nan items from list\nhashtags = [x for x in hashtags if not pd.isna(x)]\n\n# split items into a list based on a delimiter\nhashtags = [x.split(\",\") for x in hashtags]\n\n# flatten list of lists\nhashtags = [item for sublist in hashtags for item in sublist]\n\n# remove whitespaces\nhashtags = list(map(lambda x: x.replace(\" \", \"\"), hashtags))\n\n# count items on list\nhashtags_count = pd.Series(hashtags).value_counts()\n\n# return first n rows in descending order\ntop_hashtags = hashtags_count.nlargest(20)\n\ntop_hashtags\n\n\n#SeVanParaSiempre                3\n#Milei                           3\n#MassaPresidente2023             2\n#ElPeorGobiernoDeLaHistoria      2\n#Bullrich                        2\n#MassaPresidente                 2\n#KirchnerismoNuncaMas            2\n#elsi                            1\n#VotoContraMassa                 1\n#argentina                       1\n#Son30Mil                        1\n#PalestinaLibre                  1\n#Sellamaperiodista               1\n#NoAMilei                        1\n#Milita60depobrezaydolara1200    1\n#GORDITOLECHOSO                  1\n#Noquierequeseterminelapauta     1\n#Nolepaganconladeellos           1\n#NoAl5toGobiernoK                1\n#SeVannnnnn                      1\nName: count, dtype: int64\n\n\n\n\nMenciones\n20 usuarios más mencionados en los ataques:\n\n\nCode\nattacks[\"mentions\"] = attacks[\"text\"].apply(\n    lambda x: (\n        np.nan\n        if pd.isnull(x) or not isinstance(x, str) or len(re.findall(r\"@(\\w+)\", x)) == 0\n        else re.findall(r\"@(\\w+)\", x)\n    )\n)\n\nattacks[\"mentions\"] = attacks[\"mentions\"].apply(\n    lambda x: \", \".join(x) if isinstance(x, list) else x\n)\n\n# convert dataframe column to list\nmentions = attacks[\"mentions\"].unique()\n\n# remove nan items from list\nmentions = [x for x in mentions if not pd.isna(x)]\n\n# split items into a list based on a delimiter\nmentions = [x.split(\",\") for x in mentions]\n\n# flatten list of lists\nmentions = [item for sublist in mentions for item in sublist]\n\n# remove whitespaces\nmentions = list(map(lambda x: x.replace(\" \", \"\"), mentions))\n\n# count items on list\nmentions_count = pd.Series(mentions).value_counts()\n\n# return first n rows in descending order\ntop_mentions = mentions_count.nlargest(20)\n\ntop_mentions\n\n\nPatoBullrich       5\nSergioMassa        4\nvivicanosaok       3\nminsaurralde       3\nJMilei             3\nJonatanViale       2\nCris_noticias      2\nKicillofok         2\nrialjorge          2\nQuintelaRicardo    1\nursuvargues        1\nPRossiOficial      1\nedugbonorino       1\nCarlosMaslaton     1\nluisnovaresio      1\nLANACION           1\nc0o0ni             1\nmajulluis          1\nrobnavarro         1\nherlombardi        1\nName: count, dtype: int64\n\n\n\n\nTokens\nLista del top 20 de palabras más comunes y su frecuencia:\n\n\nCode\n# load the spacy model for Spanish\nnlp = spacy.load(\"es_core_news_sm\")\n\n# load stop words for Spanish\nSTOP_WORDS = nlp.Defaults.stop_words\n\n\n# Function to filter stop words\ndef filter_stopwords(text):\n    # lower text\n    doc = nlp(text.lower())\n    # filter tokens\n    tokens = [\n        token.text\n        for token in doc\n        if not token.is_stop and token.text not in STOP_WORDS and token.is_alpha\n    ]\n    return \" \".join(tokens)\n\n\n# apply function to dataframe column\nattacks[\"text_pre\"] = attacks[\"text\"].apply(filter_stopwords)\n\n# count items on column\ntoken_counts = attacks[\"text_pre\"].str.split(expand=True).stack().value_counts()[:20]\n\ntoken_counts\n\n\nvos        544\nsos        440\nq          368\ngordo      268\nvas        189\nmierda     163\nmilei      144\nlechoso    140\ngordito    138\nmassa      125\ngente      115\nzurda      114\nviejo      108\ncara       105\nvieja      103\ntenes      102\nasco       102\norto        93\nzurdos      90\nputa        87\nName: count, dtype: int64\n\n\n\n\nTópicos\nTécnica de modelado de tópicos con transformers y TF-IDF:\n\n\nCode\n# remove urls, mentions, hashtags and numbers\np.set_options(p.OPT.URL, p.OPT.MENTION, p.OPT.NUMBER)\nattacks[\"text_pre\"] = attacks[\"text_pre\"].apply(lambda x: p.clean(x))\n\n\n# filter column\ndocs = attacks[\"text_pre\"]\n\n# calculate topics and probabilities\ntopic_model = BERTopic(\n    language=\"multilingual\", calculate_probabilities=True, verbose=True\n)\n\n# training\ntopics, probs = topic_model.fit_transform(docs)\n\n# visualize topics\ntopic_model.visualize_topics()\n\n\n\n                                                \n\n\n\n\nReducción de tópicos\nMapa con 20 tópicos del contenido de los tweets:\n\n\nCode\n# reduce the number of topics\ntopic_model.reduce_topics(docs, nr_topics=20)\n\n# visualize topics\ntopic_model.visualize_topics()\n\n\n\n                                                \n\n\n\n\nTérminos por tópico\n\n\nCode\ntopic_model.visualize_barchart(top_n_topics=20)\n\n\n\n                                                \n\n\n\n\nTópicos en el tiempo\n\n\nCode\n# convert column to list\ntweets = attacks[\"text_pre\"].to_list()\ntimestamps = attacks[\"dt_date\"].to_list()\n\ntopics_over_time = topic_model.topics_over_time(\n    docs=tweets,\n    timestamps=timestamps,\n    global_tuning=True,\n    evolution_tuning=True,\n    nr_bins=20,\n)\n\ntopic_model.visualize_topics_over_time(topics_over_time, top_n_topics=20)"
  },
  {
    "objectID": "pages/9.@robdnavarro.html",
    "href": "pages/9.@robdnavarro.html",
    "title": "Análisis de tweets atacando a @robdnavarro",
    "section": "",
    "text": "Datos\n\n\nCode\ndf_attacks = attacks.loc[attacks[\"to_journalist\"].isin([USERNAME])]\nprint(f\"Número de ataques: {len(df_attacks)}\")\n\n\nNúmero de ataques: 209\n\n\n\n\nFrecuencia de ataques\nProporción de ataques = (Número de ataques / Número de menciones) * 100\n\n\nCode\njournalist_mentions = len(df.loc[df[\"to_journalist\"].isin([USERNAME])])\njournalist_attacks = len(df_attacks)\n\npercentage_attacks = (journalist_attacks / journalist_mentions) * 100\n\nproportion = (percentage_attacks / 100) * 10\nproportion_rounded = round(proportion, 1)\n\n\nprint(\n    f\"Aproximadamente {proportion_rounded} de cada 10 publicaciones que mencionan a {USERNAME} son ataques\"\n)\n\n\nAproximadamente 0.6 de cada 10 publicaciones que mencionan a @robdnavarro son ataques\n\n\n\n\nFrecuencia de los ataques en función del número de seguidores\nProporción de ataques por seguidor = Número de ataques / Número de seguidores\n\n\nCode\nproportion_followers = (len(df_attacks) / 545782) * 1000\nformatted_proportion = \"{:.2f}\".format(proportion_followers)\nprint(f\"Por cada 1K seguidores, hubo {formatted_proportion} ataques para {USERNAME}\")\n\n\nPor cada 1K seguidores, hubo 0.38 ataques para @robdnavarro\n\n\n\n\nRanking de tipos de ataques\n\n\nCode\nconditions = [\n    \"women\",\n    \"politics\",\n    \"appearance\",\n    \"racism\",\n    \"class\",\n    \"lgbti\",\n    \"criminal\",\n    \"calls\",\n]\nattacks_count = df_attacks[conditions].sum()\nattacks_count = attacks_count.sort_values(ascending=False)\nattacks_count\n\n\npolitics      84\nappearance    56\nwomen         39\nracism        15\nclass         13\nlgbti          4\ncriminal       4\ncalls          4\ndtype: int64\n\n\n\n\nNúmero de ataques por tipo de evento\n\n\nCode\ndf_attacks[\"event\"].value_counts()\n\n\nevent\nelecciones balotaje     69\n1er debate              48\ndebate balotaje         42\nelecciones generales    29\n2do debate              21\nName: count, dtype: int64\n\n\n\n\nPublicaciones por evento\n\n\nCode\njournalist_posts = df.loc[df[\"from_journalist\"].isin([USERNAME])]\njournalist_posts = journalist_posts.dropna(subset=[\"from_journalist\"])\n\neventos = [\n    \"1er debate\",\n    \"2do debate\",\n    \"elecciones generales\",\n    \"debate balotaje\",\n    \"elecciones balotaje\",\n]\ncolors = [\"green\", \"purple\", \"orange\", \"red\", \"blue\"]\neventos_count = {}\n\nfig = px.line()\n\nfor i, evento in enumerate(eventos):\n    evento_data = journalist_posts.loc[journalist_posts[\"event\"].isin([evento])]\n    evento_count = evento_data.groupby(\"dt_date\").size().reset_index(name=\"count\")\n    eventos_count[evento] = evento_count\n    fig.add_scatter(\n        x=evento_count[\"dt_date\"],\n        y=evento_count[\"count\"],\n        name=evento,\n        line=dict(color=colors[i]),\n        hovertemplate=\"posts: %{y}\",\n    )\n\nfig.update_layout(title=f\"Publicaciones de {USERNAME}\", width=1000)\nfig.update_xaxes(type=\"category\")\nfig.update_yaxes(range=[0, 100])\nfig.show()\n\n\n\n                                                \n\n\n\n\nHashtags\n\n\nCode\ndf_attacks[\"hashtags\"] = df_attacks[\"text\"].apply(\n    lambda x: (\n        np.nan\n        if pd.isnull(x) or not isinstance(x, str) or len(re.findall(r\"#\\w+\", x)) == 0\n        else re.findall(r\"#\\w+\", x)\n    )\n)\n\ndf_attacks[\"hashtags\"] = df_attacks[\"hashtags\"].apply(\n    lambda x: \", \".join(x) if isinstance(x, list) else x\n)\n\n# convert dataframe column to list\nhashtags = df_attacks[\"hashtags\"].unique()\n\n# remove nan items from list\nhashtags = [x for x in hashtags if not pd.isna(x)]\n\n# split items into a list based on a delimiter\nhashtags = [x.split(\",\") for x in hashtags]\n\n# flatten list of lists\nhashtags = [item for sublist in hashtags for item in sublist]\n\n# remove whitespaces\nhashtags = list(map(lambda x: x.replace(\" \", \"\"), hashtags))\n\n# count items on list\nhashtags_count = pd.Series(hashtags).value_counts()\n\nhashtags_count\n\n\n#Paliza                      1\n#SeVan                       1\n#yonovoto                    1\n#MASSAQUISTAS                1\n#BastaDeMafiaKirchnerista    1\n#TeatroColon                 1\nName: count, dtype: int64\n\n\n\n\nMenciones\n\n\nCode\ndf_attacks[\"mentions\"] = df_attacks[\"text\"].apply(\n    lambda x: (\n        np.nan\n        if pd.isnull(x) or not isinstance(x, str) or len(re.findall(r\"@(\\w+)\", x)) == 0\n        else re.findall(r\"@(\\w+)\", x)\n    )\n)\n\ndf_attacks[\"mentions\"] = df_attacks[\"mentions\"].apply(\n    lambda x: \", \".join(x) if isinstance(x, list) else x\n)\n\n# convert dataframe column to list\nmentions = df_attacks[\"mentions\"].unique()\n\n# remove nan items from list\nmentions = [x for x in mentions if not pd.isna(x)]\n\n# split items into a list based on a delimiter\nmentions = [x.split(\",\") for x in mentions]\n\n# flatten list of lists\nmentions = [item for sublist in mentions for item in sublist]\n\n# remove whitespaces\nmentions = list(map(lambda x: x.replace(\" \", \"\"), mentions))\n\n# count items on list\nmentions_count = pd.Series(mentions).value_counts()\n\nmentions_count\n\n\nrobdnavarro      1\nrobnavarro       1\nJMilei           1\nChimi89606580    1\nedugbonorino     1\nName: count, dtype: int64\n\n\n\n\nTokens\n\n\nCode\n# load the spacy model for Spanish\nnlp = spacy.load(\"es_core_news_sm\")\n\n# load stop words for Spanish\nSTOP_WORDS = nlp.Defaults.stop_words\n\n\n# Function to filter stop words\ndef filter_stopwords(text):\n    # lower text\n    doc = nlp(text.lower())\n    # filter tokens\n    tokens = [\n        token.text\n        for token in doc\n        if not token.is_stop and token.text not in STOP_WORDS and token.is_alpha\n    ]\n    return \" \".join(tokens)\n\n\n# apply function to dataframe column\ndf_attacks[\"text_pre\"] = df_attacks[\"text\"].apply(filter_stopwords)\n\n# count items on column\ntoken_counts = df_attacks[\"text_pre\"].str.split(expand=True).stack().value_counts()[:20]\n\ntoken_counts\n\n\nvos           19\nviejo         18\nsos           14\nmilei         12\nperonchos     11\nk              9\nscioli         9\nculo           8\nasco           8\norto           7\nmierda         7\nkk             7\novacionado     7\nensobrado      6\nganó           6\nkukas          6\nanda           6\nmassa          6\nnavarro        6\nvas            6\nName: count, dtype: int64"
  },
  {
    "objectID": "pages/7.@odonnellmaria.html",
    "href": "pages/7.@odonnellmaria.html",
    "title": "Análisis de tweets atacando a @odonnellmaria",
    "section": "",
    "text": "Datos\n\n\nCode\ndf_attacks = attacks.loc[attacks[\"to_journalist\"].isin([USERNAME])]\nprint(f\"Número de ataques: {len(df_attacks)}\")\n\n\nNúmero de ataques: 258\n\n\n\n\nFrecuencia de ataques\nProporción de ataques = (Número de ataques / Número de menciones) * 100\n\n\nCode\njournalist_mentions = len(df.loc[df[\"to_journalist\"].isin([USERNAME])])\njournalist_attacks = len(df_attacks)\n\npercentage_attacks = (journalist_attacks / journalist_mentions) * 100\n\nproportion = (percentage_attacks / 100) * 10\nproportion_rounded = round(proportion, 1)\n\n\nprint(\n    f\"Aproximadamente {proportion_rounded} de cada 10 publicaciones que mencionan a {USERNAME} son ataques\"\n)\n\n\nAproximadamente 0.8 de cada 10 publicaciones que mencionan a @odonnellmaria son ataques\n\n\n\n\nFrecuencia de los ataques en función del número de seguidores\nProporción de ataques por seguidor = Número de ataques / Número de seguidores\n\n\nCode\nproportion_followers = (len(df_attacks) / 383772) * 1000\nformatted_proportion = \"{:.2f}\".format(proportion_followers)\nprint(f\"Por cada 1K seguidores, hubo {formatted_proportion} ataques para {USERNAME}\")\n\n\nPor cada 1K seguidores, hubo 0.67 ataques para @odonnellmaria\n\n\n\n\nRanking de tipos de ataques\n\n\nCode\nconditions = [\n    \"women\",\n    \"politics\",\n    \"appearance\",\n    \"racism\",\n    \"class\",\n    \"lgbti\",\n    \"criminal\",\n    \"calls\",\n]\nattacks_count = df_attacks[conditions].sum()\nattacks_count = attacks_count.sort_values(ascending=False)\nattacks_count\n\n\npolitics      116\nwomen         107\nappearance     51\nclass          13\nracism          8\nlgbti           0\ncriminal        0\ncalls           0\ndtype: int64\n\n\n\n\nNúmero de ataques por tipo de evento\n\n\nCode\ndf_attacks[\"event\"].value_counts()\n\n\nevent\n1er debate              113\ndebate balotaje          90\nelecciones balotaje      53\nelecciones generales      2\nName: count, dtype: int64\n\n\n\n\nPublicaciones por evento\n\n\nCode\njournalist_posts = df.loc[df[\"from_journalist\"].isin([USERNAME])]\njournalist_posts = journalist_posts.dropna(subset=[\"from_journalist\"])\n\neventos = [\n    \"1er debate\",\n    \"2do debate\",\n    \"elecciones generales\",\n    \"debate balotaje\",\n    \"elecciones balotaje\",\n]\ncolors = [\"green\", \"purple\", \"orange\", \"red\", \"blue\"]\neventos_count = {}\n\nfig = px.line()\n\nfor i, evento in enumerate(eventos):\n    evento_data = journalist_posts.loc[journalist_posts[\"event\"].isin([evento])]\n    evento_count = evento_data.groupby(\"dt_date\").size().reset_index(name=\"count\")\n    eventos_count[evento] = evento_count\n    fig.add_scatter(\n        x=evento_count[\"dt_date\"],\n        y=evento_count[\"count\"],\n        name=evento,\n        line=dict(color=colors[i]),\n        hovertemplate=\"posts: %{y}\",\n    )\n\nfig.update_layout(title=f\"Publicaciones de {USERNAME}\", width=1000)\nfig.update_xaxes(type=\"category\")\nfig.update_yaxes(range=[0, 100])\nfig.show()\n\n\n\n                                                \n\n\n\n\nHashtags\n\n\nCode\ndf_attacks[\"hashtags\"] = df_attacks[\"text\"].apply(\n    lambda x: (\n        np.nan\n        if pd.isnull(x) or not isinstance(x, str) or len(re.findall(r\"#\\w+\", x)) == 0\n        else re.findall(r\"#\\w+\", x)\n    )\n)\n\ndf_attacks[\"hashtags\"] = df_attacks[\"hashtags\"].apply(\n    lambda x: \", \".join(x) if isinstance(x, list) else x\n)\n\n# convert dataframe column to list\nhashtags = df_attacks[\"hashtags\"].unique()\n\n# remove nan items from list\nhashtags = [x for x in hashtags if not pd.isna(x)]\n\n# split items into a list based on a delimiter\nhashtags = [x.split(\",\") for x in hashtags]\n\n# flatten list of lists\nhashtags = [item for sublist in hashtags for item in sublist]\n\n# remove whitespaces\nhashtags = list(map(lambda x: x.replace(\" \", \"\"), hashtags))\n\n# count items on list\nhashtags_count = pd.Series(hashtags).value_counts()\n\nhashtags_count\n\n\n#Milei2023EnPrimeraVuelta    1\n#coreadelcentro              1\n#LameTujesK                  1\nName: count, dtype: int64\n\n\n\n\nMenciones\n\n\nCode\ndf_attacks[\"mentions\"] = df_attacks[\"text\"].apply(\n    lambda x: (\n        np.nan\n        if pd.isnull(x) or not isinstance(x, str) or len(re.findall(r\"@(\\w+)\", x)) == 0\n        else re.findall(r\"@(\\w+)\", x)\n    )\n)\n\ndf_attacks[\"mentions\"] = df_attacks[\"mentions\"].apply(\n    lambda x: \", \".join(x) if isinstance(x, list) else x\n)\n\n# convert dataframe column to list\nmentions = df_attacks[\"mentions\"].unique()\n\n# remove nan items from list\nmentions = [x for x in mentions if not pd.isna(x)]\n\n# split items into a list based on a delimiter\nmentions = [x.split(\",\") for x in mentions]\n\n# flatten list of lists\nmentions = [item for sublist in mentions for item in sublist]\n\n# remove whitespaces\nmentions = list(map(lambda x: x.replace(\" \", \"\"), mentions))\n\n# count items on list\nmentions_count = pd.Series(mentions).value_counts()\n\nmentions_count\n\n\nodonellmaria     1\nodonnellmaria    1\nSergioMassa      1\nertenembaum      1\nName: count, dtype: int64\n\n\n\n\nTokens\n\n\nCode\n# load the spacy model for Spanish\nnlp = spacy.load(\"es_core_news_sm\")\n\n# load stop words for Spanish\nSTOP_WORDS = nlp.Defaults.stop_words\n\n\n# Function to filter stop words\ndef filter_stopwords(text):\n    # lower text\n    doc = nlp(text.lower())\n    # filter tokens\n    tokens = [\n        token.text\n        for token in doc\n        if not token.is_stop and token.text not in STOP_WORDS and token.is_alpha\n    ]\n    return \" \".join(tokens)\n\n\n# apply function to dataframe column\ndf_attacks[\"text_pre\"] = df_attacks[\"text\"].apply(filter_stopwords)\n\n# count items on column\ntoken_counts = df_attacks[\"text_pre\"].str.split(expand=True).stack().value_counts()[:20]\n\ntoken_counts\n\n\nvos          44\nsos          41\nzurda        39\nq            20\nmaría        13\nensobrada    11\nanda          9\npauta         8\nmilei         8\nderecho       8\nkuka          8\nk             8\ngente         7\nputa          7\nvieja         7\nzurdos        7\nmujer         7\nvagos         7\norto          6\nnota          6\nName: count, dtype: int64"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Análisis de tweets durante las elecciones generales 2023 en Argentina",
    "section": "",
    "text": "Para llevar acabo este análisis de datos, Data Crítica analizó los datos recolectados por Chequeado. El periodo de los tweets recolectados abarca desde 30-09-2023 hasta 2023-11-20.\nLos textos de los tweets fueron clasificados programáticamente utilizando un modelo de machine learning con la librería de Python transformers para generar etiquetas con tipos de discursos de odio.\nEl modelo utilizado para este etiquetado lleva por nombre beto-contextualized-hate-speech en Hugging Face y fue elegido ya que está entrenado con datos recolectados en el contexto de Argentina.\nEste modelo tiene 9 clasificaciones distintas:\n\n\n\nEtiqueta\nDescripción\n\n\n\n\nWOMEN\nEn contra de mujeres\n\n\nLGBTI\nEn contra LGBTI\n\n\nRACISM\nRacista\n\n\nCLASS\nClasista\n\n\nPOLITICS\nDebido a política\n\n\nDISABLED\nAbleista\n\n\nAPPEARANCE\nEn contra debido a su apariencia\n\n\nCRIMINAL\nEn contra de criminales\n\n\nCALLS\nLlamado a la violencia\n\n\n\n\nJupyter Notebooks creados por Fernanda Aguirre"
  },
  {
    "objectID": "index.html#metodología",
    "href": "index.html#metodología",
    "title": "Análisis de tweets durante las elecciones generales 2023 en Argentina",
    "section": "",
    "text": "Para llevar acabo este análisis de datos, Data Crítica analizó los datos recolectados por Chequeado. El periodo de los tweets recolectados abarca desde 30-09-2023 hasta 2023-11-20.\nLos textos de los tweets fueron clasificados programáticamente utilizando un modelo de machine learning con la librería de Python transformers para generar etiquetas con tipos de discursos de odio.\nEl modelo utilizado para este etiquetado lleva por nombre beto-contextualized-hate-speech en Hugging Face y fue elegido ya que está entrenado con datos recolectados en el contexto de Argentina.\nEste modelo tiene 9 clasificaciones distintas:\n\n\n\nEtiqueta\nDescripción\n\n\n\n\nWOMEN\nEn contra de mujeres\n\n\nLGBTI\nEn contra LGBTI\n\n\nRACISM\nRacista\n\n\nCLASS\nClasista\n\n\nPOLITICS\nDebido a política\n\n\nDISABLED\nAbleista\n\n\nAPPEARANCE\nEn contra debido a su apariencia\n\n\nCRIMINAL\nEn contra de criminales\n\n\nCALLS\nLlamado a la violencia\n\n\n\n\nJupyter Notebooks creados por Fernanda Aguirre"
  }
]